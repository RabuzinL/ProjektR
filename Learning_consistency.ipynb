{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning_consistency.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk2SQDMhq5TQ"
      },
      "source": [
        "Konvolucijski model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBLbJG2q9Ma"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch.nn import functional\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class ConvolutionalModel(nn.Module):\r\n",
        "  \"\"\"A simple model for generating a convolutional neural network.\r\n",
        "  It contains two convolutional layers, two pooling layers, and three \r\n",
        "  fully connected layers. In constructor you can specify parameters\r\n",
        "  specific to your training set.\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, in_channels, conv1_width, fc1_width, class_count):\r\n",
        "    super(ConvolutionalModel, self).__init__()\r\n",
        "    self.conv1 = nn.Conv2d(in_channels, conv1_width, kernel_size=5, stride=1,  bias=True)\r\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\r\n",
        "    self.conv2 = nn.Conv2d(conv1_width, conv1_width * 2, kernel_size=5, stride=1,  bias=True)\r\n",
        "    self.pool2= nn.MaxPool2d(kernel_size=3, stride=2)\r\n",
        "    self.dropout = nn.Dropout2d(p=0.5)\r\n",
        "    self.fc1 = nn.Linear(fc1_width * 4, fc1_width * 2, bias=True)\r\n",
        "    self.fc2 = nn.Linear(fc1_width * 2, fc1_width, bias=True)\r\n",
        "    self.fc_logits = nn.Linear(fc1_width, class_count, bias=True)\r\n",
        "\r\n",
        "    # parametri su već inicijalizirani pozivima Conv2d i Linear\r\n",
        "    # ali možemo ih drugačije inicijalizirati\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    \"\"\"Forward propagation for training of the neural network.\r\n",
        "    Classifies the given batch of input tensors.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    self: ConvolutionalModel\r\n",
        "      For calling the needed layers.\r\n",
        "    x: torch.Tensor\r\n",
        "      Batch of tensors for classification.\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    logits\r\n",
        "      Predicitons of classes for the given batch of tensors\r\n",
        "    \"\"\"\r\n",
        "    h = self.conv1(x)\r\n",
        "    h = functional.relu(h)  \r\n",
        "    h = self.pool1(h)\r\n",
        "\r\n",
        "    h = self.conv2(h)\r\n",
        "    h = functional.relu(h)\r\n",
        "    h = self.pool2(h)\r\n",
        "    h = self.dropout(h)\r\n",
        "\r\n",
        "    h = h.view(h.shape[0], -1)\r\n",
        "\r\n",
        "    #print(h.size())\r\n",
        "\r\n",
        "    h = self.fc1(h)\r\n",
        "    h = functional.relu(h)\r\n",
        "\r\n",
        "    h = self.fc2(h)\r\n",
        "    h = functional.relu(h)\r\n",
        "    logits = self.fc_logits(h)\r\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXdu-ituv0X5"
      },
      "source": [
        "Priprema drivea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkpenF9vv5Yq",
        "outputId": "b14b9947-c8a1-4ad7-b917-702af726effa"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWrlwVFmraed"
      },
      "source": [
        "Učitavanje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iexU0aKLrdPU",
        "outputId": "1af81b58-1ede-4cde-faee-f4113de826a9"
      },
      "source": [
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "#Simple data loading for usage in\r\n",
        "#the rest of the training.\r\n",
        "#Before using for the first time set download to\r\n",
        "#true\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/data', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50,\r\n",
        "                                          shuffle=False, num_workers=0)\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/data', train=False,\r\n",
        "                                       download=True, transform=transform)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\r\n",
        "                                         shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "classes = ('plane', 'car', 'bird', 'cat',\r\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WLZB6LMhtVQ"
      },
      "source": [
        "labeledDataCount = 1000\r\n",
        "trainLabeled = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN1h-2h9t946"
      },
      "source": [
        "Evaluacija"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLxnle2luAdS"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "\r\n",
        "def evaluate(net, type):\r\n",
        "    \"\"\"\r\n",
        "    Performs the evaluation of the current performance of a\r\n",
        "    given convolutional network. It can perform the evaluation on \r\n",
        "    both training and testing sets. Standard evaluation metrics are\r\n",
        "    calcualted such as, accuracy and confusion matrix.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    net: ConvolutionalModel\r\n",
        "        ConvNet whose performance needs to be evaluated.\r\n",
        "    type: bool\r\n",
        "        True if eval is made on testing set, false otherwise\r\n",
        "    Return\r\n",
        "    ------\r\n",
        "    loss\r\n",
        "        Current loss on the chosen set\r\n",
        "    accuracy\r\n",
        "        Current acc on the chosen set\r\n",
        "    \"\"\"\r\n",
        "    device = torch.device('cuda')\r\n",
        "    f = open(\"/content/drive/MyDrive/results/rs_data\" + str(labeledDataCount) + \".txt\", \"a+\")\r\n",
        "    net.eval()\r\n",
        "    net.to(device=device)\r\n",
        "    total = 0\r\n",
        "    correct = 0\r\n",
        "    confMatrix = np.zeros((10, 10), int)\r\n",
        "    lossFunc = nn.CrossEntropyLoss()\r\n",
        "    accLoss = 0\r\n",
        "    if type:\r\n",
        "        with torch.no_grad():\r\n",
        "            for data in testloader:\r\n",
        "                images, labels = data\r\n",
        "                images = images.to(device=device)\r\n",
        "                labels = labels.to(device=device)\r\n",
        "\r\n",
        "                output = net.forward(images)\r\n",
        "                loss = lossFunc(output, labels)\r\n",
        "                _, predictions = torch.max(output.data, 1)\r\n",
        "                total += labels.size(0)\r\n",
        "                accLoss += loss.item()\r\n",
        "                correct += (predictions == labels).sum().item()\r\n",
        "                for j in range(labels.size(0)):\r\n",
        "                    confMatrix[predictions[j], labels[j]] += 1\r\n",
        "    else:\r\n",
        "        with torch.no_grad():\r\n",
        "            for data in trainloader:\r\n",
        "                images, labels = data\r\n",
        "                images = images.to(device=device)\r\n",
        "                labels = labels.to(device=device)\r\n",
        "\r\n",
        "                output = net.forward(images)\r\n",
        "                loss = lossFunc(output, labels)\r\n",
        "                _, predictions = torch.max(output.data, 1)\r\n",
        "                total += labels.size(0)\r\n",
        "                accLoss += loss.item()\r\n",
        "                correct += (predictions == labels).sum().item()\r\n",
        "                for j in range(labels.size(0)):\r\n",
        "                    confMatrix[predictions[j], labels[j]] += 1\r\n",
        "\r\n",
        "    print(\"Accuracy of the neural network on CIFAR_10 is: %.2f %%\" %((correct/total)*100))\r\n",
        "    #print(data_load.classes)\r\n",
        "    f.write(\"Accuracy: \" + str(((correct/total)*100)) + '\\n')\r\n",
        "    f.write(str(classes) + '\\n')\r\n",
        "    f.write(str(confMatrix) + '\\n')\r\n",
        "    #print(confMatrix)\r\n",
        "    prec, recall = specificMetrics(confMatrix)\r\n",
        "    f.write(str(prec) + '\\n')\r\n",
        "    f.write(str(recall) + '\\n')\r\n",
        "    f.close()\r\n",
        "    return (accLoss/(total/trainloader.batch_size)), (correct/total)\r\n",
        "\r\n",
        "def specificMetrics(confMatrix):\r\n",
        "    \"\"\"\r\n",
        "    Calculates precision and recall from a given confusion\r\n",
        "    matrix and returns calculated metrics.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    confMatrix: n x n numpy array\r\n",
        "        Made from the predictions and true labels of a\r\n",
        "        given set of data\r\n",
        "    Return\r\n",
        "    ------\r\n",
        "    precc\r\n",
        "        Precision on all classes\r\n",
        "    recal \r\n",
        "        Recall on all classes\r\n",
        "    \"\"\"\r\n",
        "    precc = np.zeros(np.size(confMatrix, 0))\r\n",
        "    recal = np.zeros(np.size(confMatrix, 0))\r\n",
        "    for i in range(np.size(confMatrix, 0)):\r\n",
        "        tp = 0\r\n",
        "        fp = 0\r\n",
        "        fn = 0\r\n",
        "        for j in range(np.size(confMatrix, 0)):\r\n",
        "            if i == j:\r\n",
        "                tp += confMatrix[i, j]\r\n",
        "            else:\r\n",
        "                fn += confMatrix[j, i]\r\n",
        "                fp += confMatrix[i, j]\r\n",
        "            \r\n",
        "        precc[i] += tp/(tp + fp)\r\n",
        "        recal[i] += tp/(tp + fn)\r\n",
        "\r\n",
        "    return precc, recal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvkV_qOAuWY2"
      },
      "source": [
        "Crtanje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPo5UkIduY0m"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "def plot_training_progress(save_dir, data):\r\n",
        "  fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16,8))\r\n",
        "\r\n",
        "  linewidth = 2\r\n",
        "  legend_size = 10\r\n",
        "  train_color = 'm'\r\n",
        "  val_color = 'c'\r\n",
        "\r\n",
        "  num_points = len(data['train_loss'])\r\n",
        "  x_data = np.linspace(1, num_points, num_points)\r\n",
        "  ax1.set_title('Cross-entropy loss')\r\n",
        "  ax1.plot(x_data, data['train_loss'], marker='o', color=train_color,\r\n",
        "           linewidth=linewidth, linestyle='-', label='train')\r\n",
        "  ax1.plot(x_data, data['valid_loss'], marker='o', color=val_color,\r\n",
        "           linewidth=linewidth, linestyle='-', label='validation')\r\n",
        "  ax1.legend(loc='upper right', fontsize=legend_size)\r\n",
        "  ax2.set_title('Average class accuracy')\r\n",
        "  ax2.plot(x_data, data['train_acc'], marker='o', color=train_color,\r\n",
        "           linewidth=linewidth, linestyle='-', label='train')\r\n",
        "  ax2.plot(x_data, data['valid_acc'], marker='o', color=val_color,\r\n",
        "           linewidth=linewidth, linestyle='-', label='validation')\r\n",
        "  ax2.legend(loc='upper left', fontsize=legend_size)\r\n",
        "  ax3.set_title('Learning rate')\r\n",
        "  ax3.plot(x_data, data['lr'], marker='o', color=train_color,\r\n",
        "           linewidth=linewidth, linestyle='-', label='learning_rate')\r\n",
        "  ax3.legend(loc='upper left', fontsize=legend_size)\r\n",
        "\r\n",
        "  save_path = os.path.join(save_dir, 'training_plot' + str(labeledDataCount) + '.png')\r\n",
        "  print('Plotting in: ', save_path)\r\n",
        "  plt.savefig(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf-uY8qYuyvd"
      },
      "source": [
        "Treniranje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Shart2izu0mV",
        "outputId": "f31c2b18-19c9-43ac-d8a6-293b251c77e8"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "from torch import nn\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import math\r\n",
        "from PIL import Image\r\n",
        "from torchvision.datasets import CIFAR10\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "#Simple data loading for usage in\r\n",
        "#the rest of the training.\r\n",
        "#Before using for the first time set download to\r\n",
        "#true\r\n",
        "\r\n",
        "trainTransform = transforms.Compose([\r\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\r\n",
        "    transforms.RandomRotation(degrees=10),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\r\n",
        "\r\n",
        "validTransform = transforms.Compose([    \r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\r\n",
        "\r\n",
        "class CifarDataset(CIFAR10):\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            index (int): Index\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            tuple: (image, target) where target is index of the target class.\r\n",
        "        \"\"\"\r\n",
        "        img, target = self.data[index], self.targets[index]\r\n",
        "\r\n",
        "        # doing this so that it is consistent with all other datasets\r\n",
        "        # to return a PIL Image\r\n",
        "        img = Image.fromarray(img)\r\n",
        "        img1 = img\r\n",
        "        img2 = img\r\n",
        "\r\n",
        "        if self.transform is not None:\r\n",
        "            img1 = self.transform(img)\r\n",
        "            img2 = self.transform(img)\r\n",
        "\r\n",
        "        if self.target_transform is not None:\r\n",
        "            target = self.target_transform(target)\r\n",
        "\r\n",
        "        return img1, img2, target\r\n",
        "\r\n",
        "def maskForTrain():\r\n",
        "    classLabels = np.zeros(10)\r\n",
        "    counter = 0\r\n",
        "    for i in range(len(trainSet)):\r\n",
        "        if counter == labeledDataCount:\r\n",
        "            trainSet.targets[i] = -1\r\n",
        "        else:\r\n",
        "            target = trainSet.targets[i]\r\n",
        "            if classLabels[target] < labeledDataCount / 10:\r\n",
        "                classLabels[target] += 1\r\n",
        "                counter += 1\r\n",
        "            else:\r\n",
        "                trainSet.targets[i] = -1\r\n",
        "\r\n",
        "    print(classLabels)\r\n",
        "\r\n",
        "trainSet = CifarDataset(root='/content/drive/MyDrive/data', train=True,\r\n",
        "                    download=True, transform=trainTransform)\r\n",
        "testSet = CIFAR10(root='/content/drive/MyDrive/data', train=False,\r\n",
        "                    download=True, transform=validTransform)\r\n",
        "\r\n",
        "if trainLabeled:\r\n",
        "    maskForTrain()\r\n",
        "    lista = []\r\n",
        "    for i in range(len(trainSet)):\r\n",
        "        if trainSet.targets[i] != -1:\r\n",
        "            lista.append(i)\r\n",
        "\r\n",
        "    subtrainset = torch.utils.data.Subset(trainSet, lista)\r\n",
        "\r\n",
        "    print(len(subtrainset))\r\n",
        "\r\n",
        "    trainLoader = torch.utils.data.DataLoader(subtrainset, batch_size=50,\r\n",
        "                                          shuffle=True, num_workers=0)\r\n",
        "else:\r\n",
        "    maskForTrain()\r\n",
        "    cnt = 0\r\n",
        "    for i in range(len(trainSet)):\r\n",
        "        if trainSet.targets[i] != -1:\r\n",
        "            cnt += 1\r\n",
        "    \r\n",
        "    print(cnt)\r\n",
        "    trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=50,\r\n",
        "                                          shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=50,\r\n",
        "                                         shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "classes = ('plane', 'car', 'bird', 'cat',\r\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\r\n",
        "\r\n",
        "def update_w_t(epoch, num_epochs):\r\n",
        "    if epoch < num_epochs:\r\n",
        "        p = max(0.0, float(epoch) / float(num_epochs))\r\n",
        "        p = 1.0 - p\r\n",
        "        return math.exp(-p * p * 5.0)\r\n",
        "    else:\r\n",
        "        return 1.0\r\n",
        "\r\n",
        "def trainNetwork():\r\n",
        "    \"\"\"Performs a standard procedure for training a neural network.\r\n",
        "    Training progress after each learning epoch is evaluated in order to\r\n",
        "    gain insigth into ConvNets continuous performance.\r\n",
        "    Important notes\r\n",
        "    ---------------\r\n",
        "    Loss function: Cross entropy loss\r\n",
        "\r\n",
        "    Optimizer: Adam\r\n",
        "    \r\n",
        "    Scheduler: ExponentialLR\r\n",
        "    \"\"\"\r\n",
        "    SAVE_DIR = '/content/drive/MyDrive/plots'\r\n",
        "    device = torch.device('cuda')\r\n",
        "    \r\n",
        "\r\n",
        "    epoch = 80\r\n",
        "    epoch_rampup = 50\r\n",
        "    epoch_rampdown = 30\r\n",
        "    \r\n",
        "    plot_data = {}\r\n",
        "    plot_data['train_loss'] = []\r\n",
        "    plot_data['valid_loss'] = []\r\n",
        "    plot_data['train_acc'] = []\r\n",
        "    plot_data['valid_acc'] = []\r\n",
        "    plot_data['lr'] = []\r\n",
        "    net = ConvolutionalModel(3, 16, 128, 10)\r\n",
        "    net.train()\r\n",
        "    net.to(device=device)\r\n",
        "    f = open(\"/content/drive/MyDrive/results/rs_data\" + str(labeledDataCount) +\".txt\", \"a+\")\r\n",
        "    f.close()\r\n",
        "    lossFunc = nn.CrossEntropyLoss(ignore_index=-1)\r\n",
        "    lossFuncUnsupervised = nn.MSELoss()\r\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)\r\n",
        "    scheduler_rampup = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.05)\r\n",
        "    scheduler_rampdown = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\r\n",
        "\r\n",
        "\r\n",
        "    for e in range(epoch):\r\n",
        "\r\n",
        "        accLoss = 0.0\r\n",
        "\r\n",
        "        w = update_w_t(e, epoch_rampup)\r\n",
        "        if trainLabeled:\r\n",
        "            for i, data in enumerate(trainLoader, 0):\r\n",
        "                input, input1, labels = data\r\n",
        "                input = input.to(device=device)\r\n",
        "                labels = labels.to(device=device)\r\n",
        "\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                outputs_supervised = net.forward(input)\r\n",
        "\r\n",
        "                loss = lossFunc(outputs_supervised, labels)\r\n",
        "                loss.backward()\r\n",
        "                optimizer.step()\r\n",
        "\r\n",
        "                accLoss += loss.item()\r\n",
        "\r\n",
        "                if i % 10 == 0:\r\n",
        "                    print(\"Epoch: %d, Iteration: %5d, Loss: %.3f\" % ((e + 1), (i * 50), loss.item()))\r\n",
        "\r\n",
        "        else:\r\n",
        "            for i, data in enumerate(trainLoader, 0):\r\n",
        "                input, input1, labels = data\r\n",
        "                input = input.to(device=device)\r\n",
        "                input1 = input1.to(device=device)\r\n",
        "                labels = labels.to(device=device)\r\n",
        "\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                outputs_supervised = net.forward(input)\r\n",
        "                outputs_unsupervised = net.forward(input1)\r\n",
        "\r\n",
        "                loss = lossFunc(outputs_supervised, labels) + (w * lossFuncUnsupervised(outputs_supervised, outputs_unsupervised) / 10)\r\n",
        "                loss.backward()\r\n",
        "                optimizer.step()\r\n",
        "\r\n",
        "                accLoss += loss.item()\r\n",
        "\r\n",
        "                if i % 10 == 0:\r\n",
        "                    print(\"Epoch: %d, Iteration: %5d, Loss: %.3f\" % ((e + 1), (i * 50), loss.item()))\r\n",
        "\r\n",
        "                \r\n",
        "    \r\n",
        "        train_loss, train_acc = evaluate(net, False)\r\n",
        "        val_loss, val_acc = evaluate(net, True)\r\n",
        "\r\n",
        "        plot_data['train_loss'] += [train_loss]\r\n",
        "        plot_data['valid_loss'] += [val_loss]\r\n",
        "        plot_data['train_acc'] += [train_acc]\r\n",
        "        plot_data['valid_acc'] += [val_acc]\r\n",
        "\r\n",
        "        print(\"w(T) = %.3f\" % w)\r\n",
        "\r\n",
        "        if e < epoch_rampup:\r\n",
        "            plot_data['lr'] += [scheduler_rampup.get_last_lr()]\r\n",
        "            scheduler_rampup.step()\r\n",
        "        else:\r\n",
        "          plot_data['lr'] += [scheduler_rampdown.get_last_lr()]\r\n",
        "          scheduler_rampdown.step()\r\n",
        "\r\n",
        "\r\n",
        "    plot_training_progress(SAVE_DIR, plot_data)\r\n",
        "    PATH = '/content/drive/MyDrive/cifar_netAdam' + str(labeledDataCount)'.pth'\r\n",
        "    torch.save(net.state_dict(), PATH)\r\n",
        "\r\n",
        "\r\n",
        "trainNetwork()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[100. 100. 100. 100. 100. 100. 100. 100. 100. 100.]\n",
            "1000\n",
            "Epoch: 1, Iteration:     0, Loss: 2.328\n",
            "Epoch: 1, Iteration:   500, Loss: 2.317\n",
            "Epoch: 1, Iteration:  1000, Loss: 2.276\n",
            "Epoch: 1, Iteration:  1500, Loss: 0.000\n",
            "Epoch: 1, Iteration:  2000, Loss: 2.347\n",
            "Epoch: 1, Iteration:  2500, Loss: 0.000\n",
            "Epoch: 1, Iteration:  3000, Loss: 2.274\n",
            "Epoch: 1, Iteration:  3500, Loss: 2.243\n",
            "Epoch: 1, Iteration:  4000, Loss: 2.327\n",
            "Epoch: 1, Iteration:  4500, Loss: 0.000\n",
            "Epoch: 1, Iteration:  5000, Loss: 2.321\n",
            "Epoch: 1, Iteration:  5500, Loss: 0.000\n",
            "Epoch: 1, Iteration:  6000, Loss: 0.000\n",
            "Epoch: 1, Iteration:  6500, Loss: 2.516\n",
            "Epoch: 1, Iteration:  7000, Loss: 2.250\n",
            "Epoch: 1, Iteration:  7500, Loss: 2.224\n",
            "Epoch: 1, Iteration:  8000, Loss: 0.000\n",
            "Epoch: 1, Iteration:  8500, Loss: 2.349\n",
            "Epoch: 1, Iteration:  9000, Loss: 2.280\n",
            "Epoch: 1, Iteration:  9500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 10000, Loss: 2.181\n",
            "Epoch: 1, Iteration: 10500, Loss: 2.105\n",
            "Epoch: 1, Iteration: 11000, Loss: 2.626\n",
            "Epoch: 1, Iteration: 11500, Loss: 1.827\n",
            "Epoch: 1, Iteration: 12000, Loss: 2.405\n",
            "Epoch: 1, Iteration: 12500, Loss: 2.453\n",
            "Epoch: 1, Iteration: 13000, Loss: 2.238\n",
            "Epoch: 1, Iteration: 13500, Loss: 2.359\n",
            "Epoch: 1, Iteration: 14000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 14500, Loss: 2.409\n",
            "Epoch: 1, Iteration: 15000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 15500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 16000, Loss: 2.406\n",
            "Epoch: 1, Iteration: 16500, Loss: 2.082\n",
            "Epoch: 1, Iteration: 17000, Loss: 2.352\n",
            "Epoch: 1, Iteration: 17500, Loss: 2.401\n",
            "Epoch: 1, Iteration: 18000, Loss: 2.545\n",
            "Epoch: 1, Iteration: 18500, Loss: 2.000\n",
            "Epoch: 1, Iteration: 19000, Loss: 2.275\n",
            "Epoch: 1, Iteration: 19500, Loss: 2.338\n",
            "Epoch: 1, Iteration: 20000, Loss: 2.322\n",
            "Epoch: 1, Iteration: 20500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 21000, Loss: 2.155\n",
            "Epoch: 1, Iteration: 21500, Loss: 2.131\n",
            "Epoch: 1, Iteration: 22000, Loss: 2.438\n",
            "Epoch: 1, Iteration: 22500, Loss: 2.197\n",
            "Epoch: 1, Iteration: 23000, Loss: 2.337\n",
            "Epoch: 1, Iteration: 23500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 24000, Loss: 2.307\n",
            "Epoch: 1, Iteration: 24500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 25000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 25500, Loss: 2.368\n",
            "Epoch: 1, Iteration: 26000, Loss: 2.066\n",
            "Epoch: 1, Iteration: 26500, Loss: 2.212\n",
            "Epoch: 1, Iteration: 27000, Loss: 2.288\n",
            "Epoch: 1, Iteration: 27500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 28000, Loss: 2.202\n",
            "Epoch: 1, Iteration: 28500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 29000, Loss: 2.218\n",
            "Epoch: 1, Iteration: 29500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 30000, Loss: 2.391\n",
            "Epoch: 1, Iteration: 30500, Loss: 2.225\n",
            "Epoch: 1, Iteration: 31000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 31500, Loss: 2.348\n",
            "Epoch: 1, Iteration: 32000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 32500, Loss: 2.165\n",
            "Epoch: 1, Iteration: 33000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 33500, Loss: 2.299\n",
            "Epoch: 1, Iteration: 34000, Loss: 2.290\n",
            "Epoch: 1, Iteration: 34500, Loss: 2.264\n",
            "Epoch: 1, Iteration: 35000, Loss: 2.438\n",
            "Epoch: 1, Iteration: 35500, Loss: 2.452\n",
            "Epoch: 1, Iteration: 36000, Loss: 2.448\n",
            "Epoch: 1, Iteration: 36500, Loss: 2.430\n",
            "Epoch: 1, Iteration: 37000, Loss: 2.392\n",
            "Epoch: 1, Iteration: 37500, Loss: 2.205\n",
            "Epoch: 1, Iteration: 38000, Loss: 2.249\n",
            "Epoch: 1, Iteration: 38500, Loss: 2.339\n",
            "Epoch: 1, Iteration: 39000, Loss: 2.348\n",
            "Epoch: 1, Iteration: 39500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 40000, Loss: 2.105\n",
            "Epoch: 1, Iteration: 40500, Loss: 2.813\n",
            "Epoch: 1, Iteration: 41000, Loss: 2.231\n",
            "Epoch: 1, Iteration: 41500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 42000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 42500, Loss: 2.416\n",
            "Epoch: 1, Iteration: 43000, Loss: 2.228\n",
            "Epoch: 1, Iteration: 43500, Loss: 2.177\n",
            "Epoch: 1, Iteration: 44000, Loss: 2.402\n",
            "Epoch: 1, Iteration: 44500, Loss: 2.391\n",
            "Epoch: 1, Iteration: 45000, Loss: 2.236\n",
            "Epoch: 1, Iteration: 45500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 46000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 46500, Loss: 2.067\n",
            "Epoch: 1, Iteration: 47000, Loss: 1.843\n",
            "Epoch: 1, Iteration: 47500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 48000, Loss: 2.145\n",
            "Epoch: 1, Iteration: 48500, Loss: 0.000\n",
            "Epoch: 1, Iteration: 49000, Loss: 0.000\n",
            "Epoch: 1, Iteration: 49500, Loss: 2.492\n",
            "Accuracy of the neural network on CIFAR_10 is: 16.33 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:106: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 32, Iteration: 24000, Loss: 0.888\n",
            "Epoch: 32, Iteration: 24500, Loss: 0.060\n",
            "Epoch: 32, Iteration: 25000, Loss: 0.801\n",
            "Epoch: 32, Iteration: 25500, Loss: 0.058\n",
            "Epoch: 32, Iteration: 26000, Loss: 0.641\n",
            "Epoch: 32, Iteration: 26500, Loss: 0.039\n",
            "Epoch: 32, Iteration: 27000, Loss: 0.050\n",
            "Epoch: 32, Iteration: 27500, Loss: 0.256\n",
            "Epoch: 32, Iteration: 28000, Loss: 0.044\n",
            "Epoch: 32, Iteration: 28500, Loss: 0.064\n",
            "Epoch: 32, Iteration: 29000, Loss: 1.302\n",
            "Epoch: 32, Iteration: 29500, Loss: 0.070\n",
            "Epoch: 32, Iteration: 30000, Loss: 0.063\n",
            "Epoch: 32, Iteration: 30500, Loss: 0.054\n",
            "Epoch: 32, Iteration: 31000, Loss: 1.166\n",
            "Epoch: 32, Iteration: 31500, Loss: 0.394\n",
            "Epoch: 32, Iteration: 32000, Loss: 0.072\n",
            "Epoch: 32, Iteration: 32500, Loss: 1.954\n",
            "Epoch: 32, Iteration: 33000, Loss: 0.143\n",
            "Epoch: 32, Iteration: 33500, Loss: 0.098\n",
            "Epoch: 32, Iteration: 34000, Loss: 0.478\n",
            "Epoch: 32, Iteration: 34500, Loss: 3.577\n",
            "Epoch: 32, Iteration: 35000, Loss: 0.076\n",
            "Epoch: 32, Iteration: 35500, Loss: 0.055\n",
            "Epoch: 32, Iteration: 36000, Loss: 3.301\n",
            "Epoch: 32, Iteration: 36500, Loss: 0.060\n",
            "Epoch: 32, Iteration: 37000, Loss: 1.496\n",
            "Epoch: 32, Iteration: 37500, Loss: 1.658\n",
            "Epoch: 32, Iteration: 38000, Loss: 0.364\n",
            "Epoch: 32, Iteration: 38500, Loss: 0.584\n",
            "Epoch: 32, Iteration: 39000, Loss: 0.045\n",
            "Epoch: 32, Iteration: 39500, Loss: 0.747\n",
            "Epoch: 32, Iteration: 40000, Loss: 1.266\n",
            "Epoch: 32, Iteration: 40500, Loss: 0.047\n",
            "Epoch: 32, Iteration: 41000, Loss: 0.183\n",
            "Epoch: 32, Iteration: 41500, Loss: 1.360\n",
            "Epoch: 32, Iteration: 42000, Loss: 1.731\n",
            "Epoch: 32, Iteration: 42500, Loss: 0.985\n",
            "Epoch: 32, Iteration: 43000, Loss: 0.069\n",
            "Epoch: 32, Iteration: 43500, Loss: 1.656\n",
            "Epoch: 32, Iteration: 44000, Loss: 0.242\n",
            "Epoch: 32, Iteration: 44500, Loss: 0.250\n",
            "Epoch: 32, Iteration: 45000, Loss: 1.663\n",
            "Epoch: 32, Iteration: 45500, Loss: 0.071\n",
            "Epoch: 32, Iteration: 46000, Loss: 0.459\n",
            "Epoch: 32, Iteration: 46500, Loss: 0.182\n",
            "Epoch: 32, Iteration: 47000, Loss: 0.061\n",
            "Epoch: 32, Iteration: 47500, Loss: 0.318\n",
            "Epoch: 32, Iteration: 48000, Loss: 0.060\n",
            "Epoch: 32, Iteration: 48500, Loss: 0.139\n",
            "Epoch: 32, Iteration: 49000, Loss: 0.816\n",
            "Epoch: 32, Iteration: 49500, Loss: 0.060\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.81 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.74 %\n",
            "w(T) = 0.486\n",
            "Epoch: 33, Iteration:     0, Loss: 1.713\n",
            "Epoch: 33, Iteration:   500, Loss: 0.171\n",
            "Epoch: 33, Iteration:  1000, Loss: 0.079\n",
            "Epoch: 33, Iteration:  1500, Loss: 0.054\n",
            "Epoch: 33, Iteration:  2000, Loss: 1.623\n",
            "Epoch: 33, Iteration:  2500, Loss: 1.212\n",
            "Epoch: 33, Iteration:  3000, Loss: 0.607\n",
            "Epoch: 33, Iteration:  3500, Loss: 0.055\n",
            "Epoch: 33, Iteration:  4000, Loss: 0.376\n",
            "Epoch: 33, Iteration:  4500, Loss: 2.265\n",
            "Epoch: 33, Iteration:  5000, Loss: 0.057\n",
            "Epoch: 33, Iteration:  5500, Loss: 0.052\n",
            "Epoch: 33, Iteration:  6000, Loss: 0.057\n",
            "Epoch: 33, Iteration:  6500, Loss: 0.093\n",
            "Epoch: 33, Iteration:  7000, Loss: 0.560\n",
            "Epoch: 33, Iteration:  7500, Loss: 0.988\n",
            "Epoch: 33, Iteration:  8000, Loss: 0.065\n",
            "Epoch: 33, Iteration:  8500, Loss: 0.104\n",
            "Epoch: 33, Iteration:  9000, Loss: 0.056\n",
            "Epoch: 33, Iteration:  9500, Loss: 3.183\n",
            "Epoch: 33, Iteration: 10000, Loss: 0.702\n",
            "Epoch: 33, Iteration: 10500, Loss: 0.778\n",
            "Epoch: 33, Iteration: 11000, Loss: 2.009\n",
            "Epoch: 33, Iteration: 11500, Loss: 0.836\n",
            "Epoch: 33, Iteration: 12000, Loss: 0.057\n",
            "Epoch: 33, Iteration: 12500, Loss: 0.185\n",
            "Epoch: 33, Iteration: 13000, Loss: 0.898\n",
            "Epoch: 33, Iteration: 13500, Loss: 0.065\n",
            "Epoch: 33, Iteration: 14000, Loss: 0.076\n",
            "Epoch: 33, Iteration: 14500, Loss: 1.694\n",
            "Epoch: 33, Iteration: 15000, Loss: 1.084\n",
            "Epoch: 33, Iteration: 15500, Loss: 0.512\n",
            "Epoch: 33, Iteration: 16000, Loss: 1.947\n",
            "Epoch: 33, Iteration: 16500, Loss: 0.079\n",
            "Epoch: 33, Iteration: 17000, Loss: 0.061\n",
            "Epoch: 33, Iteration: 17500, Loss: 3.568\n",
            "Epoch: 33, Iteration: 18000, Loss: 0.064\n",
            "Epoch: 33, Iteration: 18500, Loss: 0.253\n",
            "Epoch: 33, Iteration: 19000, Loss: 1.616\n",
            "Epoch: 33, Iteration: 19500, Loss: 0.783\n",
            "Epoch: 33, Iteration: 20000, Loss: 0.048\n",
            "Epoch: 33, Iteration: 20500, Loss: 0.068\n",
            "Epoch: 33, Iteration: 21000, Loss: 0.054\n",
            "Epoch: 33, Iteration: 21500, Loss: 0.078\n",
            "Epoch: 33, Iteration: 22000, Loss: 0.837\n",
            "Epoch: 33, Iteration: 22500, Loss: 0.064\n",
            "Epoch: 33, Iteration: 23000, Loss: 0.528\n",
            "Epoch: 33, Iteration: 23500, Loss: 0.065\n",
            "Epoch: 33, Iteration: 24000, Loss: 0.543\n",
            "Epoch: 33, Iteration: 24500, Loss: 0.048\n",
            "Epoch: 33, Iteration: 25000, Loss: 0.396\n",
            "Epoch: 33, Iteration: 25500, Loss: 0.046\n",
            "Epoch: 33, Iteration: 26000, Loss: 2.614\n",
            "Epoch: 33, Iteration: 26500, Loss: 0.042\n",
            "Epoch: 33, Iteration: 27000, Loss: 0.799\n",
            "Epoch: 33, Iteration: 27500, Loss: 2.218\n",
            "Epoch: 33, Iteration: 28000, Loss: 0.090\n",
            "Epoch: 33, Iteration: 28500, Loss: 0.074\n",
            "Epoch: 33, Iteration: 29000, Loss: 0.048\n",
            "Epoch: 33, Iteration: 29500, Loss: 0.044\n",
            "Epoch: 33, Iteration: 30000, Loss: 0.062\n",
            "Epoch: 33, Iteration: 30500, Loss: 0.042\n",
            "Epoch: 33, Iteration: 31000, Loss: 0.990\n",
            "Epoch: 33, Iteration: 31500, Loss: 0.044\n",
            "Epoch: 33, Iteration: 32000, Loss: 0.063\n",
            "Epoch: 33, Iteration: 32500, Loss: 2.303\n",
            "Epoch: 33, Iteration: 33000, Loss: 0.996\n",
            "Epoch: 33, Iteration: 33500, Loss: 0.053\n",
            "Epoch: 33, Iteration: 34000, Loss: 0.044\n",
            "Epoch: 33, Iteration: 34500, Loss: 0.055\n",
            "Epoch: 33, Iteration: 35000, Loss: 0.090\n",
            "Epoch: 33, Iteration: 35500, Loss: 0.040\n",
            "Epoch: 33, Iteration: 36000, Loss: 0.053\n",
            "Epoch: 33, Iteration: 36500, Loss: 0.485\n",
            "Epoch: 33, Iteration: 37000, Loss: 2.796\n",
            "Epoch: 33, Iteration: 37500, Loss: 1.491\n",
            "Epoch: 33, Iteration: 38000, Loss: 0.075\n",
            "Epoch: 33, Iteration: 38500, Loss: 1.762\n",
            "Epoch: 33, Iteration: 39000, Loss: 1.087\n",
            "Epoch: 33, Iteration: 39500, Loss: 0.087\n",
            "Epoch: 33, Iteration: 40000, Loss: 1.731\n",
            "Epoch: 33, Iteration: 40500, Loss: 0.133\n",
            "Epoch: 33, Iteration: 41000, Loss: 0.962\n",
            "Epoch: 33, Iteration: 41500, Loss: 0.799\n",
            "Epoch: 33, Iteration: 42000, Loss: 0.058\n",
            "Epoch: 33, Iteration: 42500, Loss: 1.871\n",
            "Epoch: 33, Iteration: 43000, Loss: 0.065\n",
            "Epoch: 33, Iteration: 43500, Loss: 0.050\n",
            "Epoch: 33, Iteration: 44000, Loss: 0.062\n",
            "Epoch: 33, Iteration: 44500, Loss: 0.065\n",
            "Epoch: 33, Iteration: 45000, Loss: 0.047\n",
            "Epoch: 33, Iteration: 45500, Loss: 0.650\n",
            "Epoch: 33, Iteration: 46000, Loss: 0.997\n",
            "Epoch: 33, Iteration: 46500, Loss: 0.076\n",
            "Epoch: 33, Iteration: 47000, Loss: 1.542\n",
            "Epoch: 33, Iteration: 47500, Loss: 1.082\n",
            "Epoch: 33, Iteration: 48000, Loss: 0.615\n",
            "Epoch: 33, Iteration: 48500, Loss: 0.068\n",
            "Epoch: 33, Iteration: 49000, Loss: 0.197\n",
            "Epoch: 33, Iteration: 49500, Loss: 0.094\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.45 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.46 %\n",
            "w(T) = 0.523\n",
            "Epoch: 34, Iteration:     0, Loss: 1.026\n",
            "Epoch: 34, Iteration:   500, Loss: 0.059\n",
            "Epoch: 34, Iteration:  1000, Loss: 1.234\n",
            "Epoch: 34, Iteration:  1500, Loss: 0.058\n",
            "Epoch: 34, Iteration:  2000, Loss: 0.042\n",
            "Epoch: 34, Iteration:  2500, Loss: 0.058\n",
            "Epoch: 34, Iteration:  3000, Loss: 0.906\n",
            "Epoch: 34, Iteration:  3500, Loss: 0.399\n",
            "Epoch: 34, Iteration:  4000, Loss: 1.999\n",
            "Epoch: 34, Iteration:  4500, Loss: 0.087\n",
            "Epoch: 34, Iteration:  5000, Loss: 0.072\n",
            "Epoch: 34, Iteration:  5500, Loss: 1.020\n",
            "Epoch: 34, Iteration:  6000, Loss: 0.048\n",
            "Epoch: 34, Iteration:  6500, Loss: 0.069\n",
            "Epoch: 34, Iteration:  7000, Loss: 0.063\n",
            "Epoch: 34, Iteration:  7500, Loss: 0.055\n",
            "Epoch: 34, Iteration:  8000, Loss: 0.779\n",
            "Epoch: 34, Iteration:  8500, Loss: 1.587\n",
            "Epoch: 34, Iteration:  9000, Loss: 7.083\n",
            "Epoch: 34, Iteration:  9500, Loss: 0.055\n",
            "Epoch: 34, Iteration: 10000, Loss: 1.051\n",
            "Epoch: 34, Iteration: 10500, Loss: 1.486\n",
            "Epoch: 34, Iteration: 11000, Loss: 0.073\n",
            "Epoch: 34, Iteration: 11500, Loss: 0.961\n",
            "Epoch: 34, Iteration: 12000, Loss: 1.226\n",
            "Epoch: 34, Iteration: 12500, Loss: 2.202\n",
            "Epoch: 34, Iteration: 13000, Loss: 1.604\n",
            "Epoch: 34, Iteration: 13500, Loss: 0.072\n",
            "Epoch: 34, Iteration: 14000, Loss: 0.181\n",
            "Epoch: 34, Iteration: 14500, Loss: 0.563\n",
            "Epoch: 34, Iteration: 15000, Loss: 0.107\n",
            "Epoch: 34, Iteration: 15500, Loss: 0.894\n",
            "Epoch: 34, Iteration: 16000, Loss: 1.006\n",
            "Epoch: 34, Iteration: 16500, Loss: 0.079\n",
            "Epoch: 34, Iteration: 17000, Loss: 0.062\n",
            "Epoch: 34, Iteration: 17500, Loss: 0.049\n",
            "Epoch: 34, Iteration: 18000, Loss: 0.061\n",
            "Epoch: 34, Iteration: 18500, Loss: 0.464\n",
            "Epoch: 34, Iteration: 19000, Loss: 0.078\n",
            "Epoch: 34, Iteration: 19500, Loss: 1.098\n",
            "Epoch: 34, Iteration: 20000, Loss: 1.609\n",
            "Epoch: 34, Iteration: 20500, Loss: 1.246\n",
            "Epoch: 34, Iteration: 21000, Loss: 1.984\n",
            "Epoch: 34, Iteration: 21500, Loss: 2.377\n",
            "Epoch: 34, Iteration: 22000, Loss: 0.072\n",
            "Epoch: 34, Iteration: 22500, Loss: 1.406\n",
            "Epoch: 34, Iteration: 23000, Loss: 0.038\n",
            "Epoch: 34, Iteration: 23500, Loss: 0.644\n",
            "Epoch: 34, Iteration: 24000, Loss: 1.604\n",
            "Epoch: 34, Iteration: 24500, Loss: 0.399\n",
            "Epoch: 34, Iteration: 25000, Loss: 2.234\n",
            "Epoch: 34, Iteration: 25500, Loss: 0.683\n",
            "Epoch: 34, Iteration: 26000, Loss: 1.445\n",
            "Epoch: 34, Iteration: 26500, Loss: 1.810\n",
            "Epoch: 34, Iteration: 27000, Loss: 0.450\n",
            "Epoch: 34, Iteration: 27500, Loss: 0.048\n",
            "Epoch: 34, Iteration: 28000, Loss: 0.065\n",
            "Epoch: 34, Iteration: 28500, Loss: 0.632\n",
            "Epoch: 34, Iteration: 29000, Loss: 0.901\n",
            "Epoch: 34, Iteration: 29500, Loss: 1.171\n",
            "Epoch: 34, Iteration: 30000, Loss: 0.402\n",
            "Epoch: 34, Iteration: 30500, Loss: 2.844\n",
            "Epoch: 34, Iteration: 31000, Loss: 0.067\n",
            "Epoch: 34, Iteration: 31500, Loss: 0.069\n",
            "Epoch: 34, Iteration: 32000, Loss: 0.056\n",
            "Epoch: 34, Iteration: 32500, Loss: 0.081\n",
            "Epoch: 34, Iteration: 33000, Loss: 0.222\n",
            "Epoch: 34, Iteration: 33500, Loss: 0.436\n",
            "Epoch: 34, Iteration: 34000, Loss: 0.768\n",
            "Epoch: 34, Iteration: 34500, Loss: 0.594\n",
            "Epoch: 34, Iteration: 35000, Loss: 0.472\n",
            "Epoch: 34, Iteration: 35500, Loss: 0.071\n",
            "Epoch: 34, Iteration: 36000, Loss: 1.536\n",
            "Epoch: 34, Iteration: 36500, Loss: 0.595\n",
            "Epoch: 34, Iteration: 37000, Loss: 0.063\n",
            "Epoch: 34, Iteration: 37500, Loss: 0.055\n",
            "Epoch: 34, Iteration: 38000, Loss: 0.346\n",
            "Epoch: 34, Iteration: 38500, Loss: 0.084\n",
            "Epoch: 34, Iteration: 39000, Loss: 0.079\n",
            "Epoch: 34, Iteration: 39500, Loss: 3.861\n",
            "Epoch: 34, Iteration: 40000, Loss: 0.732\n",
            "Epoch: 34, Iteration: 40500, Loss: 0.062\n",
            "Epoch: 34, Iteration: 41000, Loss: 0.058\n",
            "Epoch: 34, Iteration: 41500, Loss: 0.296\n",
            "Epoch: 34, Iteration: 42000, Loss: 0.060\n",
            "Epoch: 34, Iteration: 42500, Loss: 2.276\n",
            "Epoch: 34, Iteration: 43000, Loss: 0.080\n",
            "Epoch: 34, Iteration: 43500, Loss: 0.075\n",
            "Epoch: 34, Iteration: 44000, Loss: 0.116\n",
            "Epoch: 34, Iteration: 44500, Loss: 0.239\n",
            "Epoch: 34, Iteration: 45000, Loss: 1.030\n",
            "Epoch: 34, Iteration: 45500, Loss: 0.793\n",
            "Epoch: 34, Iteration: 46000, Loss: 0.681\n",
            "Epoch: 34, Iteration: 46500, Loss: 0.092\n",
            "Epoch: 34, Iteration: 47000, Loss: 2.644\n",
            "Epoch: 34, Iteration: 47500, Loss: 0.076\n",
            "Epoch: 34, Iteration: 48000, Loss: 1.892\n",
            "Epoch: 34, Iteration: 48500, Loss: 0.047\n",
            "Epoch: 34, Iteration: 49000, Loss: 0.063\n",
            "Epoch: 34, Iteration: 49500, Loss: 0.054\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.46 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.06 %\n",
            "w(T) = 0.561\n",
            "Epoch: 35, Iteration:     0, Loss: 0.324\n",
            "Epoch: 35, Iteration:   500, Loss: 0.051\n",
            "Epoch: 35, Iteration:  1000, Loss: 0.728\n",
            "Epoch: 35, Iteration:  1500, Loss: 0.092\n",
            "Epoch: 35, Iteration:  2000, Loss: 0.295\n",
            "Epoch: 35, Iteration:  2500, Loss: 0.691\n",
            "Epoch: 35, Iteration:  3000, Loss: 0.080\n",
            "Epoch: 35, Iteration:  3500, Loss: 0.067\n",
            "Epoch: 35, Iteration:  4000, Loss: 0.258\n",
            "Epoch: 35, Iteration:  4500, Loss: 1.094\n",
            "Epoch: 35, Iteration:  5000, Loss: 0.105\n",
            "Epoch: 35, Iteration:  5500, Loss: 0.918\n",
            "Epoch: 35, Iteration:  6000, Loss: 0.071\n",
            "Epoch: 35, Iteration:  6500, Loss: 0.079\n",
            "Epoch: 35, Iteration:  7000, Loss: 1.062\n",
            "Epoch: 35, Iteration:  7500, Loss: 1.135\n",
            "Epoch: 35, Iteration:  8000, Loss: 0.595\n",
            "Epoch: 35, Iteration:  8500, Loss: 0.587\n",
            "Epoch: 35, Iteration:  9000, Loss: 0.066\n",
            "Epoch: 35, Iteration:  9500, Loss: 0.513\n",
            "Epoch: 35, Iteration: 10000, Loss: 0.062\n",
            "Epoch: 35, Iteration: 10500, Loss: 0.678\n",
            "Epoch: 35, Iteration: 11000, Loss: 2.033\n",
            "Epoch: 35, Iteration: 11500, Loss: 0.411\n",
            "Epoch: 35, Iteration: 12000, Loss: 0.453\n",
            "Epoch: 35, Iteration: 12500, Loss: 0.311\n",
            "Epoch: 35, Iteration: 13000, Loss: 0.061\n",
            "Epoch: 35, Iteration: 13500, Loss: 0.077\n",
            "Epoch: 35, Iteration: 14000, Loss: 0.374\n",
            "Epoch: 35, Iteration: 14500, Loss: 0.125\n",
            "Epoch: 35, Iteration: 15000, Loss: 0.102\n",
            "Epoch: 35, Iteration: 15500, Loss: 0.105\n",
            "Epoch: 35, Iteration: 16000, Loss: 0.100\n",
            "Epoch: 35, Iteration: 16500, Loss: 0.087\n",
            "Epoch: 35, Iteration: 17000, Loss: 2.035\n",
            "Epoch: 35, Iteration: 17500, Loss: 0.086\n",
            "Epoch: 35, Iteration: 18000, Loss: 0.089\n",
            "Epoch: 35, Iteration: 18500, Loss: 0.084\n",
            "Epoch: 35, Iteration: 19000, Loss: 1.781\n",
            "Epoch: 35, Iteration: 19500, Loss: 0.974\n",
            "Epoch: 35, Iteration: 20000, Loss: 0.953\n",
            "Epoch: 35, Iteration: 20500, Loss: 0.095\n",
            "Epoch: 35, Iteration: 21000, Loss: 0.089\n",
            "Epoch: 35, Iteration: 21500, Loss: 0.281\n",
            "Epoch: 35, Iteration: 22000, Loss: 0.667\n",
            "Epoch: 35, Iteration: 22500, Loss: 0.763\n",
            "Epoch: 35, Iteration: 23000, Loss: 0.068\n",
            "Epoch: 35, Iteration: 23500, Loss: 0.075\n",
            "Epoch: 35, Iteration: 24000, Loss: 0.908\n",
            "Epoch: 35, Iteration: 24500, Loss: 0.122\n",
            "Epoch: 35, Iteration: 25000, Loss: 0.078\n",
            "Epoch: 35, Iteration: 25500, Loss: 1.330\n",
            "Epoch: 35, Iteration: 26000, Loss: 0.059\n",
            "Epoch: 35, Iteration: 26500, Loss: 0.061\n",
            "Epoch: 35, Iteration: 27000, Loss: 0.430\n",
            "Epoch: 35, Iteration: 27500, Loss: 0.076\n",
            "Epoch: 35, Iteration: 28000, Loss: 0.084\n",
            "Epoch: 35, Iteration: 28500, Loss: 0.087\n",
            "Epoch: 35, Iteration: 29000, Loss: 0.138\n",
            "Epoch: 35, Iteration: 29500, Loss: 1.753\n",
            "Epoch: 35, Iteration: 30000, Loss: 0.070\n",
            "Epoch: 35, Iteration: 30500, Loss: 0.845\n",
            "Epoch: 35, Iteration: 31000, Loss: 0.082\n",
            "Epoch: 35, Iteration: 31500, Loss: 0.063\n",
            "Epoch: 35, Iteration: 32000, Loss: 1.516\n",
            "Epoch: 35, Iteration: 32500, Loss: 0.072\n",
            "Epoch: 35, Iteration: 33000, Loss: 0.065\n",
            "Epoch: 35, Iteration: 33500, Loss: 1.425\n",
            "Epoch: 35, Iteration: 34000, Loss: 0.182\n",
            "Epoch: 35, Iteration: 34500, Loss: 1.315\n",
            "Epoch: 35, Iteration: 35000, Loss: 0.573\n",
            "Epoch: 35, Iteration: 35500, Loss: 0.837\n",
            "Epoch: 35, Iteration: 36000, Loss: 0.848\n",
            "Epoch: 35, Iteration: 36500, Loss: 0.137\n",
            "Epoch: 35, Iteration: 37000, Loss: 0.061\n",
            "Epoch: 35, Iteration: 37500, Loss: 0.995\n",
            "Epoch: 35, Iteration: 38000, Loss: 0.329\n",
            "Epoch: 35, Iteration: 38500, Loss: 0.207\n",
            "Epoch: 35, Iteration: 39000, Loss: 1.079\n",
            "Epoch: 35, Iteration: 39500, Loss: 0.449\n",
            "Epoch: 35, Iteration: 40000, Loss: 0.775\n",
            "Epoch: 35, Iteration: 40500, Loss: 0.053\n",
            "Epoch: 35, Iteration: 41000, Loss: 0.149\n",
            "Epoch: 35, Iteration: 41500, Loss: 1.194\n",
            "Epoch: 35, Iteration: 42000, Loss: 1.235\n",
            "Epoch: 35, Iteration: 42500, Loss: 0.144\n",
            "Epoch: 35, Iteration: 43000, Loss: 0.078\n",
            "Epoch: 35, Iteration: 43500, Loss: 0.908\n",
            "Epoch: 35, Iteration: 44000, Loss: 1.755\n",
            "Epoch: 35, Iteration: 44500, Loss: 0.063\n",
            "Epoch: 35, Iteration: 45000, Loss: 0.064\n",
            "Epoch: 35, Iteration: 45500, Loss: 0.091\n",
            "Epoch: 35, Iteration: 46000, Loss: 0.112\n",
            "Epoch: 35, Iteration: 46500, Loss: 0.352\n",
            "Epoch: 35, Iteration: 47000, Loss: 0.479\n",
            "Epoch: 35, Iteration: 47500, Loss: 0.064\n",
            "Epoch: 35, Iteration: 48000, Loss: 0.068\n",
            "Epoch: 35, Iteration: 48500, Loss: 0.066\n",
            "Epoch: 35, Iteration: 49000, Loss: 0.080\n",
            "Epoch: 35, Iteration: 49500, Loss: 1.194\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.87 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.81 %\n",
            "w(T) = 0.599\n",
            "Epoch: 36, Iteration:     0, Loss: 0.070\n",
            "Epoch: 36, Iteration:   500, Loss: 0.078\n",
            "Epoch: 36, Iteration:  1000, Loss: 0.054\n",
            "Epoch: 36, Iteration:  1500, Loss: 0.062\n",
            "Epoch: 36, Iteration:  2000, Loss: 0.619\n",
            "Epoch: 36, Iteration:  2500, Loss: 1.923\n",
            "Epoch: 36, Iteration:  3000, Loss: 0.088\n",
            "Epoch: 36, Iteration:  3500, Loss: 0.469\n",
            "Epoch: 36, Iteration:  4000, Loss: 0.084\n",
            "Epoch: 36, Iteration:  4500, Loss: 0.680\n",
            "Epoch: 36, Iteration:  5000, Loss: 0.845\n",
            "Epoch: 36, Iteration:  5500, Loss: 0.877\n",
            "Epoch: 36, Iteration:  6000, Loss: 0.081\n",
            "Epoch: 36, Iteration:  6500, Loss: 1.925\n",
            "Epoch: 36, Iteration:  7000, Loss: 1.116\n",
            "Epoch: 36, Iteration:  7500, Loss: 0.256\n",
            "Epoch: 36, Iteration:  8000, Loss: 0.066\n",
            "Epoch: 36, Iteration:  8500, Loss: 0.524\n",
            "Epoch: 36, Iteration:  9000, Loss: 4.193\n",
            "Epoch: 36, Iteration:  9500, Loss: 0.245\n",
            "Epoch: 36, Iteration: 10000, Loss: 0.060\n",
            "Epoch: 36, Iteration: 10500, Loss: 0.065\n",
            "Epoch: 36, Iteration: 11000, Loss: 0.058\n",
            "Epoch: 36, Iteration: 11500, Loss: 1.217\n",
            "Epoch: 36, Iteration: 12000, Loss: 0.056\n",
            "Epoch: 36, Iteration: 12500, Loss: 0.052\n",
            "Epoch: 36, Iteration: 13000, Loss: 0.574\n",
            "Epoch: 36, Iteration: 13500, Loss: 0.152\n",
            "Epoch: 36, Iteration: 14000, Loss: 0.587\n",
            "Epoch: 36, Iteration: 14500, Loss: 0.054\n",
            "Epoch: 36, Iteration: 15000, Loss: 0.087\n",
            "Epoch: 36, Iteration: 15500, Loss: 1.439\n",
            "Epoch: 36, Iteration: 16000, Loss: 0.197\n",
            "Epoch: 36, Iteration: 16500, Loss: 0.089\n",
            "Epoch: 36, Iteration: 17000, Loss: 0.138\n",
            "Epoch: 36, Iteration: 17500, Loss: 0.423\n",
            "Epoch: 36, Iteration: 18000, Loss: 1.529\n",
            "Epoch: 36, Iteration: 18500, Loss: 1.990\n",
            "Epoch: 36, Iteration: 19000, Loss: 0.260\n",
            "Epoch: 36, Iteration: 19500, Loss: 0.300\n",
            "Epoch: 36, Iteration: 20000, Loss: 0.062\n",
            "Epoch: 36, Iteration: 20500, Loss: 0.220\n",
            "Epoch: 36, Iteration: 21000, Loss: 0.058\n",
            "Epoch: 36, Iteration: 21500, Loss: 2.021\n",
            "Epoch: 36, Iteration: 22000, Loss: 0.615\n",
            "Epoch: 36, Iteration: 22500, Loss: 0.605\n",
            "Epoch: 36, Iteration: 23000, Loss: 0.098\n",
            "Epoch: 36, Iteration: 23500, Loss: 0.066\n",
            "Epoch: 36, Iteration: 24000, Loss: 0.057\n",
            "Epoch: 36, Iteration: 24500, Loss: 0.038\n",
            "Epoch: 36, Iteration: 25000, Loss: 1.900\n",
            "Epoch: 36, Iteration: 25500, Loss: 0.439\n",
            "Epoch: 36, Iteration: 26000, Loss: 1.594\n",
            "Epoch: 36, Iteration: 26500, Loss: 0.312\n",
            "Epoch: 36, Iteration: 27000, Loss: 0.874\n",
            "Epoch: 36, Iteration: 27500, Loss: 0.072\n",
            "Epoch: 36, Iteration: 28000, Loss: 1.512\n",
            "Epoch: 36, Iteration: 28500, Loss: 0.095\n",
            "Epoch: 36, Iteration: 29000, Loss: 0.594\n",
            "Epoch: 36, Iteration: 29500, Loss: 0.893\n",
            "Epoch: 36, Iteration: 30000, Loss: 0.425\n",
            "Epoch: 36, Iteration: 30500, Loss: 1.587\n",
            "Epoch: 36, Iteration: 31000, Loss: 1.240\n",
            "Epoch: 36, Iteration: 31500, Loss: 1.035\n",
            "Epoch: 36, Iteration: 32000, Loss: 0.141\n",
            "Epoch: 36, Iteration: 32500, Loss: 0.089\n",
            "Epoch: 36, Iteration: 33000, Loss: 0.072\n",
            "Epoch: 36, Iteration: 33500, Loss: 0.228\n",
            "Epoch: 36, Iteration: 34000, Loss: 1.261\n",
            "Epoch: 36, Iteration: 34500, Loss: 1.481\n",
            "Epoch: 36, Iteration: 35000, Loss: 0.350\n",
            "Epoch: 36, Iteration: 35500, Loss: 0.088\n",
            "Epoch: 36, Iteration: 36000, Loss: 1.973\n",
            "Epoch: 36, Iteration: 36500, Loss: 0.062\n",
            "Epoch: 36, Iteration: 37000, Loss: 0.074\n",
            "Epoch: 36, Iteration: 37500, Loss: 0.163\n",
            "Epoch: 36, Iteration: 38000, Loss: 0.059\n",
            "Epoch: 36, Iteration: 38500, Loss: 0.043\n",
            "Epoch: 36, Iteration: 39000, Loss: 0.107\n",
            "Epoch: 36, Iteration: 39500, Loss: 0.073\n",
            "Epoch: 36, Iteration: 40000, Loss: 0.488\n",
            "Epoch: 36, Iteration: 40500, Loss: 0.140\n",
            "Epoch: 36, Iteration: 41000, Loss: 0.129\n",
            "Epoch: 36, Iteration: 41500, Loss: 0.789\n",
            "Epoch: 36, Iteration: 42000, Loss: 1.025\n",
            "Epoch: 36, Iteration: 42500, Loss: 0.046\n",
            "Epoch: 36, Iteration: 43000, Loss: 0.058\n",
            "Epoch: 36, Iteration: 43500, Loss: 3.415\n",
            "Epoch: 36, Iteration: 44000, Loss: 1.822\n",
            "Epoch: 36, Iteration: 44500, Loss: 0.722\n",
            "Epoch: 36, Iteration: 45000, Loss: 1.119\n",
            "Epoch: 36, Iteration: 45500, Loss: 1.884\n",
            "Epoch: 36, Iteration: 46000, Loss: 0.396\n",
            "Epoch: 36, Iteration: 46500, Loss: 0.379\n",
            "Epoch: 36, Iteration: 47000, Loss: 0.085\n",
            "Epoch: 36, Iteration: 47500, Loss: 1.059\n",
            "Epoch: 36, Iteration: 48000, Loss: 0.800\n",
            "Epoch: 36, Iteration: 48500, Loss: 0.083\n",
            "Epoch: 36, Iteration: 49000, Loss: 0.114\n",
            "Epoch: 36, Iteration: 49500, Loss: 1.303\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.54 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.03 %\n",
            "w(T) = 0.638\n",
            "Epoch: 37, Iteration:     0, Loss: 1.515\n",
            "Epoch: 37, Iteration:   500, Loss: 0.073\n",
            "Epoch: 37, Iteration:  1000, Loss: 0.056\n",
            "Epoch: 37, Iteration:  1500, Loss: 1.860\n",
            "Epoch: 37, Iteration:  2000, Loss: 0.073\n",
            "Epoch: 37, Iteration:  2500, Loss: 0.088\n",
            "Epoch: 37, Iteration:  3000, Loss: 0.097\n",
            "Epoch: 37, Iteration:  3500, Loss: 0.349\n",
            "Epoch: 37, Iteration:  4000, Loss: 0.513\n",
            "Epoch: 37, Iteration:  4500, Loss: 0.089\n",
            "Epoch: 37, Iteration:  5000, Loss: 0.075\n",
            "Epoch: 37, Iteration:  5500, Loss: 1.585\n",
            "Epoch: 37, Iteration:  6000, Loss: 0.100\n",
            "Epoch: 37, Iteration:  6500, Loss: 1.592\n",
            "Epoch: 37, Iteration:  7000, Loss: 0.066\n",
            "Epoch: 37, Iteration:  7500, Loss: 0.300\n",
            "Epoch: 37, Iteration:  8000, Loss: 2.295\n",
            "Epoch: 37, Iteration:  8500, Loss: 1.685\n",
            "Epoch: 37, Iteration:  9000, Loss: 0.074\n",
            "Epoch: 37, Iteration:  9500, Loss: 0.603\n",
            "Epoch: 37, Iteration: 10000, Loss: 0.343\n",
            "Epoch: 37, Iteration: 10500, Loss: 0.071\n",
            "Epoch: 37, Iteration: 11000, Loss: 0.063\n",
            "Epoch: 37, Iteration: 11500, Loss: 0.107\n",
            "Epoch: 37, Iteration: 12000, Loss: 0.086\n",
            "Epoch: 37, Iteration: 12500, Loss: 2.076\n",
            "Epoch: 37, Iteration: 13000, Loss: 0.055\n",
            "Epoch: 37, Iteration: 13500, Loss: 0.677\n",
            "Epoch: 37, Iteration: 14000, Loss: 0.085\n",
            "Epoch: 37, Iteration: 14500, Loss: 0.100\n",
            "Epoch: 37, Iteration: 15000, Loss: 2.209\n",
            "Epoch: 37, Iteration: 15500, Loss: 3.053\n",
            "Epoch: 37, Iteration: 16000, Loss: 1.606\n",
            "Epoch: 37, Iteration: 16500, Loss: 0.078\n",
            "Epoch: 37, Iteration: 17000, Loss: 0.889\n",
            "Epoch: 37, Iteration: 17500, Loss: 0.996\n",
            "Epoch: 37, Iteration: 18000, Loss: 2.128\n",
            "Epoch: 37, Iteration: 18500, Loss: 0.962\n",
            "Epoch: 37, Iteration: 19000, Loss: 0.213\n",
            "Epoch: 37, Iteration: 19500, Loss: 1.513\n",
            "Epoch: 37, Iteration: 20000, Loss: 2.161\n",
            "Epoch: 37, Iteration: 20500, Loss: 1.780\n",
            "Epoch: 37, Iteration: 21000, Loss: 1.979\n",
            "Epoch: 37, Iteration: 21500, Loss: 1.434\n",
            "Epoch: 37, Iteration: 22000, Loss: 0.852\n",
            "Epoch: 37, Iteration: 22500, Loss: 0.080\n",
            "Epoch: 37, Iteration: 23000, Loss: 1.064\n",
            "Epoch: 37, Iteration: 23500, Loss: 0.942\n",
            "Epoch: 37, Iteration: 24000, Loss: 0.482\n",
            "Epoch: 37, Iteration: 24500, Loss: 1.047\n",
            "Epoch: 37, Iteration: 25000, Loss: 0.538\n",
            "Epoch: 37, Iteration: 25500, Loss: 0.138\n",
            "Epoch: 37, Iteration: 26000, Loss: 0.088\n",
            "Epoch: 37, Iteration: 26500, Loss: 0.061\n",
            "Epoch: 37, Iteration: 27000, Loss: 0.059\n",
            "Epoch: 37, Iteration: 27500, Loss: 0.071\n",
            "Epoch: 37, Iteration: 28000, Loss: 1.928\n",
            "Epoch: 37, Iteration: 28500, Loss: 0.556\n",
            "Epoch: 37, Iteration: 29000, Loss: 1.613\n",
            "Epoch: 37, Iteration: 29500, Loss: 1.287\n",
            "Epoch: 37, Iteration: 30000, Loss: 0.350\n",
            "Epoch: 37, Iteration: 30500, Loss: 0.523\n",
            "Epoch: 37, Iteration: 31000, Loss: 1.254\n",
            "Epoch: 37, Iteration: 31500, Loss: 1.875\n",
            "Epoch: 37, Iteration: 32000, Loss: 0.711\n",
            "Epoch: 37, Iteration: 32500, Loss: 0.606\n",
            "Epoch: 37, Iteration: 33000, Loss: 0.369\n",
            "Epoch: 37, Iteration: 33500, Loss: 0.077\n",
            "Epoch: 37, Iteration: 34000, Loss: 0.183\n",
            "Epoch: 37, Iteration: 34500, Loss: 2.005\n",
            "Epoch: 37, Iteration: 35000, Loss: 0.878\n",
            "Epoch: 37, Iteration: 35500, Loss: 0.047\n",
            "Epoch: 37, Iteration: 36000, Loss: 1.023\n",
            "Epoch: 37, Iteration: 36500, Loss: 0.116\n",
            "Epoch: 37, Iteration: 37000, Loss: 0.073\n",
            "Epoch: 37, Iteration: 37500, Loss: 0.073\n",
            "Epoch: 37, Iteration: 38000, Loss: 0.088\n",
            "Epoch: 37, Iteration: 38500, Loss: 0.063\n",
            "Epoch: 37, Iteration: 39000, Loss: 0.674\n",
            "Epoch: 37, Iteration: 39500, Loss: 0.317\n",
            "Epoch: 37, Iteration: 40000, Loss: 1.446\n",
            "Epoch: 37, Iteration: 40500, Loss: 0.049\n",
            "Epoch: 37, Iteration: 41000, Loss: 0.109\n",
            "Epoch: 37, Iteration: 41500, Loss: 0.410\n",
            "Epoch: 37, Iteration: 42000, Loss: 0.079\n",
            "Epoch: 37, Iteration: 42500, Loss: 0.058\n",
            "Epoch: 37, Iteration: 43000, Loss: 0.058\n",
            "Epoch: 37, Iteration: 43500, Loss: 0.077\n",
            "Epoch: 37, Iteration: 44000, Loss: 0.081\n",
            "Epoch: 37, Iteration: 44500, Loss: 1.319\n",
            "Epoch: 37, Iteration: 45000, Loss: 0.067\n",
            "Epoch: 37, Iteration: 45500, Loss: 0.069\n",
            "Epoch: 37, Iteration: 46000, Loss: 0.625\n",
            "Epoch: 37, Iteration: 46500, Loss: 1.906\n",
            "Epoch: 37, Iteration: 47000, Loss: 0.066\n",
            "Epoch: 37, Iteration: 47500, Loss: 1.561\n",
            "Epoch: 37, Iteration: 48000, Loss: 0.757\n",
            "Epoch: 37, Iteration: 48500, Loss: 0.084\n",
            "Epoch: 37, Iteration: 49000, Loss: 1.889\n",
            "Epoch: 37, Iteration: 49500, Loss: 0.054\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.29 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.39 %\n",
            "w(T) = 0.676\n",
            "Epoch: 38, Iteration:     0, Loss: 0.120\n",
            "Epoch: 38, Iteration:   500, Loss: 0.189\n",
            "Epoch: 38, Iteration:  1000, Loss: 0.139\n",
            "Epoch: 38, Iteration:  1500, Loss: 0.162\n",
            "Epoch: 38, Iteration:  2000, Loss: 0.071\n",
            "Epoch: 38, Iteration:  2500, Loss: 1.089\n",
            "Epoch: 38, Iteration:  3000, Loss: 0.770\n",
            "Epoch: 38, Iteration:  3500, Loss: 0.312\n",
            "Epoch: 38, Iteration:  4000, Loss: 0.047\n",
            "Epoch: 38, Iteration:  4500, Loss: 1.107\n",
            "Epoch: 38, Iteration:  5000, Loss: 0.256\n",
            "Epoch: 38, Iteration:  5500, Loss: 0.106\n",
            "Epoch: 38, Iteration:  6000, Loss: 0.103\n",
            "Epoch: 38, Iteration:  6500, Loss: 0.087\n",
            "Epoch: 38, Iteration:  7000, Loss: 1.552\n",
            "Epoch: 38, Iteration:  7500, Loss: 0.090\n",
            "Epoch: 38, Iteration:  8000, Loss: 2.170\n",
            "Epoch: 38, Iteration:  8500, Loss: 0.087\n",
            "Epoch: 38, Iteration:  9000, Loss: 0.824\n",
            "Epoch: 38, Iteration:  9500, Loss: 0.099\n",
            "Epoch: 38, Iteration: 10000, Loss: 1.375\n",
            "Epoch: 38, Iteration: 10500, Loss: 0.119\n",
            "Epoch: 38, Iteration: 11000, Loss: 0.314\n",
            "Epoch: 38, Iteration: 11500, Loss: 0.059\n",
            "Epoch: 38, Iteration: 12000, Loss: 0.063\n",
            "Epoch: 38, Iteration: 12500, Loss: 2.244\n",
            "Epoch: 38, Iteration: 13000, Loss: 0.087\n",
            "Epoch: 38, Iteration: 13500, Loss: 1.796\n",
            "Epoch: 38, Iteration: 14000, Loss: 1.954\n",
            "Epoch: 38, Iteration: 14500, Loss: 0.430\n",
            "Epoch: 38, Iteration: 15000, Loss: 0.065\n",
            "Epoch: 38, Iteration: 15500, Loss: 2.125\n",
            "Epoch: 38, Iteration: 16000, Loss: 2.995\n",
            "Epoch: 38, Iteration: 16500, Loss: 0.916\n",
            "Epoch: 38, Iteration: 17000, Loss: 0.184\n",
            "Epoch: 38, Iteration: 17500, Loss: 0.121\n",
            "Epoch: 38, Iteration: 18000, Loss: 1.045\n",
            "Epoch: 38, Iteration: 18500, Loss: 1.708\n",
            "Epoch: 38, Iteration: 19000, Loss: 0.095\n",
            "Epoch: 38, Iteration: 19500, Loss: 0.102\n",
            "Epoch: 38, Iteration: 20000, Loss: 0.083\n",
            "Epoch: 38, Iteration: 20500, Loss: 0.078\n",
            "Epoch: 38, Iteration: 21000, Loss: 0.105\n",
            "Epoch: 38, Iteration: 21500, Loss: 0.081\n",
            "Epoch: 38, Iteration: 22000, Loss: 0.115\n",
            "Epoch: 38, Iteration: 22500, Loss: 0.047\n",
            "Epoch: 38, Iteration: 23000, Loss: 0.397\n",
            "Epoch: 38, Iteration: 23500, Loss: 1.535\n",
            "Epoch: 38, Iteration: 24000, Loss: 0.295\n",
            "Epoch: 38, Iteration: 24500, Loss: 0.351\n",
            "Epoch: 38, Iteration: 25000, Loss: 0.473\n",
            "Epoch: 38, Iteration: 25500, Loss: 3.240\n",
            "Epoch: 38, Iteration: 26000, Loss: 0.067\n",
            "Epoch: 38, Iteration: 26500, Loss: 0.535\n",
            "Epoch: 38, Iteration: 27000, Loss: 1.061\n",
            "Epoch: 38, Iteration: 27500, Loss: 0.084\n",
            "Epoch: 38, Iteration: 28000, Loss: 0.058\n",
            "Epoch: 38, Iteration: 28500, Loss: 1.418\n",
            "Epoch: 38, Iteration: 29000, Loss: 1.428\n",
            "Epoch: 38, Iteration: 29500, Loss: 1.814\n",
            "Epoch: 38, Iteration: 30000, Loss: 1.439\n",
            "Epoch: 38, Iteration: 30500, Loss: 0.100\n",
            "Epoch: 38, Iteration: 31000, Loss: 1.089\n",
            "Epoch: 38, Iteration: 31500, Loss: 0.321\n",
            "Epoch: 38, Iteration: 32000, Loss: 0.218\n",
            "Epoch: 38, Iteration: 32500, Loss: 1.156\n",
            "Epoch: 38, Iteration: 33000, Loss: 0.869\n",
            "Epoch: 38, Iteration: 33500, Loss: 0.134\n",
            "Epoch: 38, Iteration: 34000, Loss: 0.107\n",
            "Epoch: 38, Iteration: 34500, Loss: 1.387\n",
            "Epoch: 38, Iteration: 35000, Loss: 0.331\n",
            "Epoch: 38, Iteration: 35500, Loss: 0.066\n",
            "Epoch: 38, Iteration: 36000, Loss: 0.089\n",
            "Epoch: 38, Iteration: 36500, Loss: 0.066\n",
            "Epoch: 38, Iteration: 37000, Loss: 0.072\n",
            "Epoch: 38, Iteration: 37500, Loss: 0.052\n",
            "Epoch: 38, Iteration: 38000, Loss: 1.522\n",
            "Epoch: 38, Iteration: 38500, Loss: 1.095\n",
            "Epoch: 38, Iteration: 39000, Loss: 2.734\n",
            "Epoch: 38, Iteration: 39500, Loss: 1.775\n",
            "Epoch: 38, Iteration: 40000, Loss: 0.749\n",
            "Epoch: 38, Iteration: 40500, Loss: 0.435\n",
            "Epoch: 38, Iteration: 41000, Loss: 3.524\n",
            "Epoch: 38, Iteration: 41500, Loss: 0.245\n",
            "Epoch: 38, Iteration: 42000, Loss: 0.065\n",
            "Epoch: 38, Iteration: 42500, Loss: 1.901\n",
            "Epoch: 38, Iteration: 43000, Loss: 0.149\n",
            "Epoch: 38, Iteration: 43500, Loss: 0.960\n",
            "Epoch: 38, Iteration: 44000, Loss: 1.277\n",
            "Epoch: 38, Iteration: 44500, Loss: 1.212\n",
            "Epoch: 38, Iteration: 45000, Loss: 1.232\n",
            "Epoch: 38, Iteration: 45500, Loss: 2.139\n",
            "Epoch: 38, Iteration: 46000, Loss: 0.081\n",
            "Epoch: 38, Iteration: 46500, Loss: 0.058\n",
            "Epoch: 38, Iteration: 47000, Loss: 2.552\n",
            "Epoch: 38, Iteration: 47500, Loss: 0.379\n",
            "Epoch: 38, Iteration: 48000, Loss: 1.296\n",
            "Epoch: 38, Iteration: 48500, Loss: 0.095\n",
            "Epoch: 38, Iteration: 49000, Loss: 3.150\n",
            "Epoch: 38, Iteration: 49500, Loss: 0.192\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.36 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.53 %\n",
            "w(T) = 0.713\n",
            "Epoch: 39, Iteration:     0, Loss: 0.314\n",
            "Epoch: 39, Iteration:   500, Loss: 3.013\n",
            "Epoch: 39, Iteration:  1000, Loss: 0.062\n",
            "Epoch: 39, Iteration:  1500, Loss: 0.056\n",
            "Epoch: 39, Iteration:  2000, Loss: 0.348\n",
            "Epoch: 39, Iteration:  2500, Loss: 0.083\n",
            "Epoch: 39, Iteration:  3000, Loss: 0.082\n",
            "Epoch: 39, Iteration:  3500, Loss: 1.342\n",
            "Epoch: 39, Iteration:  4000, Loss: 0.366\n",
            "Epoch: 39, Iteration:  4500, Loss: 0.913\n",
            "Epoch: 39, Iteration:  5000, Loss: 0.461\n",
            "Epoch: 39, Iteration:  5500, Loss: 0.122\n",
            "Epoch: 39, Iteration:  6000, Loss: 0.070\n",
            "Epoch: 39, Iteration:  6500, Loss: 0.086\n",
            "Epoch: 39, Iteration:  7000, Loss: 1.103\n",
            "Epoch: 39, Iteration:  7500, Loss: 0.105\n",
            "Epoch: 39, Iteration:  8000, Loss: 2.218\n",
            "Epoch: 39, Iteration:  8500, Loss: 0.605\n",
            "Epoch: 39, Iteration:  9000, Loss: 0.069\n",
            "Epoch: 39, Iteration:  9500, Loss: 0.085\n",
            "Epoch: 39, Iteration: 10000, Loss: 0.559\n",
            "Epoch: 39, Iteration: 10500, Loss: 0.121\n",
            "Epoch: 39, Iteration: 11000, Loss: 0.358\n",
            "Epoch: 39, Iteration: 11500, Loss: 0.289\n",
            "Epoch: 39, Iteration: 12000, Loss: 0.657\n",
            "Epoch: 39, Iteration: 12500, Loss: 1.738\n",
            "Epoch: 39, Iteration: 13000, Loss: 0.108\n",
            "Epoch: 39, Iteration: 13500, Loss: 0.309\n",
            "Epoch: 39, Iteration: 14000, Loss: 1.157\n",
            "Epoch: 39, Iteration: 14500, Loss: 0.109\n",
            "Epoch: 39, Iteration: 15000, Loss: 2.595\n",
            "Epoch: 39, Iteration: 15500, Loss: 1.429\n",
            "Epoch: 39, Iteration: 16000, Loss: 1.626\n",
            "Epoch: 39, Iteration: 16500, Loss: 2.034\n",
            "Epoch: 39, Iteration: 17000, Loss: 0.221\n",
            "Epoch: 39, Iteration: 17500, Loss: 0.409\n",
            "Epoch: 39, Iteration: 18000, Loss: 1.051\n",
            "Epoch: 39, Iteration: 18500, Loss: 0.084\n",
            "Epoch: 39, Iteration: 19000, Loss: 0.067\n",
            "Epoch: 39, Iteration: 19500, Loss: 0.115\n",
            "Epoch: 39, Iteration: 20000, Loss: 1.573\n",
            "Epoch: 39, Iteration: 20500, Loss: 0.067\n",
            "Epoch: 39, Iteration: 21000, Loss: 0.060\n",
            "Epoch: 39, Iteration: 21500, Loss: 0.117\n",
            "Epoch: 39, Iteration: 22000, Loss: 2.404\n",
            "Epoch: 39, Iteration: 22500, Loss: 0.054\n",
            "Epoch: 39, Iteration: 23000, Loss: 0.478\n",
            "Epoch: 39, Iteration: 23500, Loss: 0.066\n",
            "Epoch: 39, Iteration: 24000, Loss: 1.164\n",
            "Epoch: 39, Iteration: 24500, Loss: 0.292\n",
            "Epoch: 39, Iteration: 25000, Loss: 0.066\n",
            "Epoch: 39, Iteration: 25500, Loss: 0.874\n",
            "Epoch: 39, Iteration: 26000, Loss: 2.420\n",
            "Epoch: 39, Iteration: 26500, Loss: 1.016\n",
            "Epoch: 39, Iteration: 27000, Loss: 0.209\n",
            "Epoch: 39, Iteration: 27500, Loss: 0.096\n",
            "Epoch: 39, Iteration: 28000, Loss: 0.160\n",
            "Epoch: 39, Iteration: 28500, Loss: 0.089\n",
            "Epoch: 39, Iteration: 29000, Loss: 0.957\n",
            "Epoch: 39, Iteration: 29500, Loss: 1.271\n",
            "Epoch: 39, Iteration: 30000, Loss: 1.196\n",
            "Epoch: 39, Iteration: 30500, Loss: 0.188\n",
            "Epoch: 39, Iteration: 31000, Loss: 1.519\n",
            "Epoch: 39, Iteration: 31500, Loss: 0.098\n",
            "Epoch: 39, Iteration: 32000, Loss: 4.094\n",
            "Epoch: 39, Iteration: 32500, Loss: 0.059\n",
            "Epoch: 39, Iteration: 33000, Loss: 0.085\n",
            "Epoch: 39, Iteration: 33500, Loss: 0.059\n",
            "Epoch: 39, Iteration: 34000, Loss: 0.068\n",
            "Epoch: 39, Iteration: 34500, Loss: 0.905\n",
            "Epoch: 39, Iteration: 35000, Loss: 2.042\n",
            "Epoch: 39, Iteration: 35500, Loss: 0.438\n",
            "Epoch: 39, Iteration: 36000, Loss: 0.097\n",
            "Epoch: 39, Iteration: 36500, Loss: 0.120\n",
            "Epoch: 39, Iteration: 37000, Loss: 0.362\n",
            "Epoch: 39, Iteration: 37500, Loss: 0.077\n",
            "Epoch: 39, Iteration: 38000, Loss: 1.803\n",
            "Epoch: 39, Iteration: 38500, Loss: 0.077\n",
            "Epoch: 39, Iteration: 39000, Loss: 2.223\n",
            "Epoch: 39, Iteration: 39500, Loss: 0.282\n",
            "Epoch: 39, Iteration: 40000, Loss: 0.750\n",
            "Epoch: 39, Iteration: 40500, Loss: 2.144\n",
            "Epoch: 39, Iteration: 41000, Loss: 3.736\n",
            "Epoch: 39, Iteration: 41500, Loss: 0.092\n",
            "Epoch: 39, Iteration: 42000, Loss: 0.080\n",
            "Epoch: 39, Iteration: 42500, Loss: 0.940\n",
            "Epoch: 39, Iteration: 43000, Loss: 0.956\n",
            "Epoch: 39, Iteration: 43500, Loss: 0.754\n",
            "Epoch: 39, Iteration: 44000, Loss: 0.146\n",
            "Epoch: 39, Iteration: 44500, Loss: 0.104\n",
            "Epoch: 39, Iteration: 45000, Loss: 0.076\n",
            "Epoch: 39, Iteration: 45500, Loss: 0.107\n",
            "Epoch: 39, Iteration: 46000, Loss: 0.095\n",
            "Epoch: 39, Iteration: 46500, Loss: 0.084\n",
            "Epoch: 39, Iteration: 47000, Loss: 1.983\n",
            "Epoch: 39, Iteration: 47500, Loss: 1.858\n",
            "Epoch: 39, Iteration: 48000, Loss: 0.090\n",
            "Epoch: 39, Iteration: 48500, Loss: 0.086\n",
            "Epoch: 39, Iteration: 49000, Loss: 0.241\n",
            "Epoch: 39, Iteration: 49500, Loss: 0.156\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.68 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.01 %\n",
            "w(T) = 0.750\n",
            "Epoch: 40, Iteration:     0, Loss: 1.016\n",
            "Epoch: 40, Iteration:   500, Loss: 0.842\n",
            "Epoch: 40, Iteration:  1000, Loss: 0.823\n",
            "Epoch: 40, Iteration:  1500, Loss: 0.097\n",
            "Epoch: 40, Iteration:  2000, Loss: 0.095\n",
            "Epoch: 40, Iteration:  2500, Loss: 0.094\n",
            "Epoch: 40, Iteration:  3000, Loss: 0.291\n",
            "Epoch: 40, Iteration:  3500, Loss: 0.084\n",
            "Epoch: 40, Iteration:  4000, Loss: 0.606\n",
            "Epoch: 40, Iteration:  4500, Loss: 0.116\n",
            "Epoch: 40, Iteration:  5000, Loss: 0.343\n",
            "Epoch: 40, Iteration:  5500, Loss: 0.325\n",
            "Epoch: 40, Iteration:  6000, Loss: 0.069\n",
            "Epoch: 40, Iteration:  6500, Loss: 0.185\n",
            "Epoch: 40, Iteration:  7000, Loss: 0.097\n",
            "Epoch: 40, Iteration:  7500, Loss: 0.078\n",
            "Epoch: 40, Iteration:  8000, Loss: 0.746\n",
            "Epoch: 40, Iteration:  8500, Loss: 0.417\n",
            "Epoch: 40, Iteration:  9000, Loss: 0.164\n",
            "Epoch: 40, Iteration:  9500, Loss: 0.721\n",
            "Epoch: 40, Iteration: 10000, Loss: 0.564\n",
            "Epoch: 40, Iteration: 10500, Loss: 1.219\n",
            "Epoch: 40, Iteration: 11000, Loss: 1.034\n",
            "Epoch: 40, Iteration: 11500, Loss: 0.090\n",
            "Epoch: 40, Iteration: 12000, Loss: 0.960\n",
            "Epoch: 40, Iteration: 12500, Loss: 0.081\n",
            "Epoch: 40, Iteration: 13000, Loss: 0.079\n",
            "Epoch: 40, Iteration: 13500, Loss: 2.392\n",
            "Epoch: 40, Iteration: 14000, Loss: 0.078\n",
            "Epoch: 40, Iteration: 14500, Loss: 0.119\n",
            "Epoch: 40, Iteration: 15000, Loss: 0.146\n",
            "Epoch: 40, Iteration: 15500, Loss: 0.099\n",
            "Epoch: 40, Iteration: 16000, Loss: 0.084\n",
            "Epoch: 40, Iteration: 16500, Loss: 0.073\n",
            "Epoch: 40, Iteration: 17000, Loss: 1.874\n",
            "Epoch: 40, Iteration: 17500, Loss: 0.083\n",
            "Epoch: 40, Iteration: 18000, Loss: 0.759\n",
            "Epoch: 40, Iteration: 18500, Loss: 0.980\n",
            "Epoch: 40, Iteration: 19000, Loss: 0.137\n",
            "Epoch: 40, Iteration: 19500, Loss: 0.071\n",
            "Epoch: 40, Iteration: 20000, Loss: 2.188\n",
            "Epoch: 40, Iteration: 20500, Loss: 0.064\n",
            "Epoch: 40, Iteration: 21000, Loss: 0.293\n",
            "Epoch: 40, Iteration: 21500, Loss: 1.091\n",
            "Epoch: 40, Iteration: 22000, Loss: 0.109\n",
            "Epoch: 40, Iteration: 22500, Loss: 0.248\n",
            "Epoch: 40, Iteration: 23000, Loss: 4.427\n",
            "Epoch: 40, Iteration: 23500, Loss: 0.084\n",
            "Epoch: 40, Iteration: 24000, Loss: 0.079\n",
            "Epoch: 40, Iteration: 24500, Loss: 0.796\n",
            "Epoch: 40, Iteration: 25000, Loss: 0.084\n",
            "Epoch: 40, Iteration: 25500, Loss: 0.102\n",
            "Epoch: 40, Iteration: 26000, Loss: 0.116\n",
            "Epoch: 40, Iteration: 26500, Loss: 1.046\n",
            "Epoch: 40, Iteration: 27000, Loss: 0.090\n",
            "Epoch: 40, Iteration: 27500, Loss: 0.105\n",
            "Epoch: 40, Iteration: 28000, Loss: 0.220\n",
            "Epoch: 40, Iteration: 28500, Loss: 2.192\n",
            "Epoch: 40, Iteration: 29000, Loss: 0.083\n",
            "Epoch: 40, Iteration: 29500, Loss: 3.009\n",
            "Epoch: 40, Iteration: 30000, Loss: 1.736\n",
            "Epoch: 40, Iteration: 30500, Loss: 0.289\n",
            "Epoch: 40, Iteration: 31000, Loss: 0.862\n",
            "Epoch: 40, Iteration: 31500, Loss: 2.469\n",
            "Epoch: 40, Iteration: 32000, Loss: 0.064\n",
            "Epoch: 40, Iteration: 32500, Loss: 1.045\n",
            "Epoch: 40, Iteration: 33000, Loss: 0.080\n",
            "Epoch: 40, Iteration: 33500, Loss: 0.440\n",
            "Epoch: 40, Iteration: 34000, Loss: 0.079\n",
            "Epoch: 40, Iteration: 34500, Loss: 0.066\n",
            "Epoch: 40, Iteration: 35000, Loss: 0.050\n",
            "Epoch: 40, Iteration: 35500, Loss: 0.890\n",
            "Epoch: 40, Iteration: 36000, Loss: 0.055\n",
            "Epoch: 40, Iteration: 36500, Loss: 2.043\n",
            "Epoch: 40, Iteration: 37000, Loss: 0.097\n",
            "Epoch: 40, Iteration: 37500, Loss: 1.737\n",
            "Epoch: 40, Iteration: 38000, Loss: 0.069\n",
            "Epoch: 40, Iteration: 38500, Loss: 0.436\n",
            "Epoch: 40, Iteration: 39000, Loss: 0.082\n",
            "Epoch: 40, Iteration: 39500, Loss: 0.079\n",
            "Epoch: 40, Iteration: 40000, Loss: 0.463\n",
            "Epoch: 40, Iteration: 40500, Loss: 0.112\n",
            "Epoch: 40, Iteration: 41000, Loss: 1.205\n",
            "Epoch: 40, Iteration: 41500, Loss: 0.110\n",
            "Epoch: 40, Iteration: 42000, Loss: 0.065\n",
            "Epoch: 40, Iteration: 42500, Loss: 0.295\n",
            "Epoch: 40, Iteration: 43000, Loss: 0.154\n",
            "Epoch: 40, Iteration: 43500, Loss: 1.999\n",
            "Epoch: 40, Iteration: 44000, Loss: 1.433\n",
            "Epoch: 40, Iteration: 44500, Loss: 0.079\n",
            "Epoch: 40, Iteration: 45000, Loss: 0.911\n",
            "Epoch: 40, Iteration: 45500, Loss: 0.375\n",
            "Epoch: 40, Iteration: 46000, Loss: 0.745\n",
            "Epoch: 40, Iteration: 46500, Loss: 1.155\n",
            "Epoch: 40, Iteration: 47000, Loss: 1.367\n",
            "Epoch: 40, Iteration: 47500, Loss: 0.794\n",
            "Epoch: 40, Iteration: 48000, Loss: 0.083\n",
            "Epoch: 40, Iteration: 48500, Loss: 0.123\n",
            "Epoch: 40, Iteration: 49000, Loss: 0.085\n",
            "Epoch: 40, Iteration: 49500, Loss: 0.063\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.60 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.01 %\n",
            "w(T) = 0.785\n",
            "Epoch: 41, Iteration:     0, Loss: 0.204\n",
            "Epoch: 41, Iteration:   500, Loss: 1.426\n",
            "Epoch: 41, Iteration:  1000, Loss: 0.593\n",
            "Epoch: 41, Iteration:  1500, Loss: 0.654\n",
            "Epoch: 41, Iteration:  2000, Loss: 1.867\n",
            "Epoch: 41, Iteration:  2500, Loss: 0.124\n",
            "Epoch: 41, Iteration:  3000, Loss: 0.078\n",
            "Epoch: 41, Iteration:  3500, Loss: 0.127\n",
            "Epoch: 41, Iteration:  4000, Loss: 0.123\n",
            "Epoch: 41, Iteration:  4500, Loss: 0.140\n",
            "Epoch: 41, Iteration:  5000, Loss: 1.247\n",
            "Epoch: 41, Iteration:  5500, Loss: 1.530\n",
            "Epoch: 41, Iteration:  6000, Loss: 0.177\n",
            "Epoch: 41, Iteration:  6500, Loss: 0.905\n",
            "Epoch: 41, Iteration:  7000, Loss: 0.070\n",
            "Epoch: 41, Iteration:  7500, Loss: 0.062\n",
            "Epoch: 41, Iteration:  8000, Loss: 0.694\n",
            "Epoch: 41, Iteration:  8500, Loss: 3.182\n",
            "Epoch: 41, Iteration:  9000, Loss: 0.113\n",
            "Epoch: 41, Iteration:  9500, Loss: 0.083\n",
            "Epoch: 41, Iteration: 10000, Loss: 0.058\n",
            "Epoch: 41, Iteration: 10500, Loss: 2.087\n",
            "Epoch: 41, Iteration: 11000, Loss: 1.284\n",
            "Epoch: 41, Iteration: 11500, Loss: 0.302\n",
            "Epoch: 41, Iteration: 12000, Loss: 0.448\n",
            "Epoch: 41, Iteration: 12500, Loss: 0.095\n",
            "Epoch: 41, Iteration: 13000, Loss: 1.109\n",
            "Epoch: 41, Iteration: 13500, Loss: 0.153\n",
            "Epoch: 41, Iteration: 14000, Loss: 0.098\n",
            "Epoch: 41, Iteration: 14500, Loss: 3.963\n",
            "Epoch: 41, Iteration: 15000, Loss: 2.174\n",
            "Epoch: 41, Iteration: 15500, Loss: 0.061\n",
            "Epoch: 41, Iteration: 16000, Loss: 0.175\n",
            "Epoch: 41, Iteration: 16500, Loss: 3.317\n",
            "Epoch: 41, Iteration: 17000, Loss: 0.340\n",
            "Epoch: 41, Iteration: 17500, Loss: 0.103\n",
            "Epoch: 41, Iteration: 18000, Loss: 0.098\n",
            "Epoch: 41, Iteration: 18500, Loss: 0.086\n",
            "Epoch: 41, Iteration: 19000, Loss: 0.438\n",
            "Epoch: 41, Iteration: 19500, Loss: 0.101\n",
            "Epoch: 41, Iteration: 20000, Loss: 2.715\n",
            "Epoch: 41, Iteration: 20500, Loss: 0.143\n",
            "Epoch: 41, Iteration: 21000, Loss: 0.576\n",
            "Epoch: 41, Iteration: 21500, Loss: 1.386\n",
            "Epoch: 41, Iteration: 22000, Loss: 0.083\n",
            "Epoch: 41, Iteration: 22500, Loss: 5.643\n",
            "Epoch: 41, Iteration: 23000, Loss: 0.100\n",
            "Epoch: 41, Iteration: 23500, Loss: 0.051\n",
            "Epoch: 41, Iteration: 24000, Loss: 0.196\n",
            "Epoch: 41, Iteration: 24500, Loss: 0.065\n",
            "Epoch: 41, Iteration: 25000, Loss: 0.767\n",
            "Epoch: 41, Iteration: 25500, Loss: 0.083\n",
            "Epoch: 41, Iteration: 26000, Loss: 0.058\n",
            "Epoch: 41, Iteration: 26500, Loss: 1.909\n",
            "Epoch: 41, Iteration: 27000, Loss: 0.264\n",
            "Epoch: 41, Iteration: 27500, Loss: 0.088\n",
            "Epoch: 41, Iteration: 28000, Loss: 0.900\n",
            "Epoch: 41, Iteration: 28500, Loss: 0.060\n",
            "Epoch: 41, Iteration: 29000, Loss: 0.067\n",
            "Epoch: 41, Iteration: 29500, Loss: 1.344\n",
            "Epoch: 41, Iteration: 30000, Loss: 0.120\n",
            "Epoch: 41, Iteration: 30500, Loss: 0.060\n",
            "Epoch: 41, Iteration: 31000, Loss: 0.091\n",
            "Epoch: 41, Iteration: 31500, Loss: 3.475\n",
            "Epoch: 41, Iteration: 32000, Loss: 0.972\n",
            "Epoch: 41, Iteration: 32500, Loss: 0.099\n",
            "Epoch: 41, Iteration: 33000, Loss: 2.189\n",
            "Epoch: 41, Iteration: 33500, Loss: 0.090\n",
            "Epoch: 41, Iteration: 34000, Loss: 0.064\n",
            "Epoch: 41, Iteration: 34500, Loss: 0.886\n",
            "Epoch: 41, Iteration: 35000, Loss: 1.478\n",
            "Epoch: 41, Iteration: 35500, Loss: 0.056\n",
            "Epoch: 41, Iteration: 36000, Loss: 0.076\n",
            "Epoch: 41, Iteration: 36500, Loss: 0.432\n",
            "Epoch: 41, Iteration: 37000, Loss: 0.076\n",
            "Epoch: 41, Iteration: 37500, Loss: 0.099\n",
            "Epoch: 41, Iteration: 38000, Loss: 0.883\n",
            "Epoch: 41, Iteration: 38500, Loss: 0.743\n",
            "Epoch: 41, Iteration: 39000, Loss: 0.079\n",
            "Epoch: 41, Iteration: 39500, Loss: 3.446\n",
            "Epoch: 41, Iteration: 40000, Loss: 0.841\n",
            "Epoch: 41, Iteration: 40500, Loss: 0.403\n",
            "Epoch: 41, Iteration: 41000, Loss: 0.183\n",
            "Epoch: 41, Iteration: 41500, Loss: 0.106\n",
            "Epoch: 41, Iteration: 42000, Loss: 1.444\n",
            "Epoch: 41, Iteration: 42500, Loss: 1.378\n",
            "Epoch: 41, Iteration: 43000, Loss: 0.057\n",
            "Epoch: 41, Iteration: 43500, Loss: 0.080\n",
            "Epoch: 41, Iteration: 44000, Loss: 0.094\n",
            "Epoch: 41, Iteration: 44500, Loss: 0.101\n",
            "Epoch: 41, Iteration: 45000, Loss: 0.044\n",
            "Epoch: 41, Iteration: 45500, Loss: 0.098\n",
            "Epoch: 41, Iteration: 46000, Loss: 0.421\n",
            "Epoch: 41, Iteration: 46500, Loss: 1.414\n",
            "Epoch: 41, Iteration: 47000, Loss: 1.193\n",
            "Epoch: 41, Iteration: 47500, Loss: 2.259\n",
            "Epoch: 41, Iteration: 48000, Loss: 1.683\n",
            "Epoch: 41, Iteration: 48500, Loss: 0.089\n",
            "Epoch: 41, Iteration: 49000, Loss: 0.898\n",
            "Epoch: 41, Iteration: 49500, Loss: 0.151\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.81 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 36.84 %\n",
            "w(T) = 0.819\n",
            "Epoch: 42, Iteration:     0, Loss: 0.264\n",
            "Epoch: 42, Iteration:   500, Loss: 0.122\n",
            "Epoch: 42, Iteration:  1000, Loss: 0.115\n",
            "Epoch: 42, Iteration:  1500, Loss: 0.120\n",
            "Epoch: 42, Iteration:  2000, Loss: 0.098\n",
            "Epoch: 42, Iteration:  2500, Loss: 1.259\n",
            "Epoch: 42, Iteration:  3000, Loss: 0.095\n",
            "Epoch: 42, Iteration:  3500, Loss: 0.638\n",
            "Epoch: 42, Iteration:  4000, Loss: 0.602\n",
            "Epoch: 42, Iteration:  4500, Loss: 0.685\n",
            "Epoch: 42, Iteration:  5000, Loss: 0.089\n",
            "Epoch: 42, Iteration:  5500, Loss: 3.368\n",
            "Epoch: 42, Iteration:  6000, Loss: 1.211\n",
            "Epoch: 42, Iteration:  6500, Loss: 0.616\n",
            "Epoch: 42, Iteration:  7000, Loss: 0.079\n",
            "Epoch: 42, Iteration:  7500, Loss: 1.427\n",
            "Epoch: 42, Iteration:  8000, Loss: 0.105\n",
            "Epoch: 42, Iteration:  8500, Loss: 4.445\n",
            "Epoch: 42, Iteration:  9000, Loss: 0.364\n",
            "Epoch: 42, Iteration:  9500, Loss: 0.085\n",
            "Epoch: 42, Iteration: 10000, Loss: 0.773\n",
            "Epoch: 42, Iteration: 10500, Loss: 0.816\n",
            "Epoch: 42, Iteration: 11000, Loss: 0.590\n",
            "Epoch: 42, Iteration: 11500, Loss: 1.041\n",
            "Epoch: 42, Iteration: 12000, Loss: 0.095\n",
            "Epoch: 42, Iteration: 12500, Loss: 0.120\n",
            "Epoch: 42, Iteration: 13000, Loss: 0.475\n",
            "Epoch: 42, Iteration: 13500, Loss: 0.548\n",
            "Epoch: 42, Iteration: 14000, Loss: 0.062\n",
            "Epoch: 42, Iteration: 14500, Loss: 0.109\n",
            "Epoch: 42, Iteration: 15000, Loss: 0.062\n",
            "Epoch: 42, Iteration: 15500, Loss: 0.105\n",
            "Epoch: 42, Iteration: 16000, Loss: 0.391\n",
            "Epoch: 42, Iteration: 16500, Loss: 2.029\n",
            "Epoch: 42, Iteration: 17000, Loss: 0.154\n",
            "Epoch: 42, Iteration: 17500, Loss: 0.067\n",
            "Epoch: 42, Iteration: 18000, Loss: 0.726\n",
            "Epoch: 42, Iteration: 18500, Loss: 0.076\n",
            "Epoch: 42, Iteration: 19000, Loss: 0.166\n",
            "Epoch: 42, Iteration: 19500, Loss: 0.725\n",
            "Epoch: 42, Iteration: 20000, Loss: 0.259\n",
            "Epoch: 42, Iteration: 20500, Loss: 0.083\n",
            "Epoch: 42, Iteration: 21000, Loss: 0.496\n",
            "Epoch: 42, Iteration: 21500, Loss: 0.972\n",
            "Epoch: 42, Iteration: 22000, Loss: 0.838\n",
            "Epoch: 42, Iteration: 22500, Loss: 1.709\n",
            "Epoch: 42, Iteration: 23000, Loss: 0.070\n",
            "Epoch: 42, Iteration: 23500, Loss: 0.092\n",
            "Epoch: 42, Iteration: 24000, Loss: 0.651\n",
            "Epoch: 42, Iteration: 24500, Loss: 0.660\n",
            "Epoch: 42, Iteration: 25000, Loss: 0.123\n",
            "Epoch: 42, Iteration: 25500, Loss: 0.641\n",
            "Epoch: 42, Iteration: 26000, Loss: 0.428\n",
            "Epoch: 42, Iteration: 26500, Loss: 0.084\n",
            "Epoch: 42, Iteration: 27000, Loss: 0.082\n",
            "Epoch: 42, Iteration: 27500, Loss: 0.079\n",
            "Epoch: 42, Iteration: 28000, Loss: 0.071\n",
            "Epoch: 42, Iteration: 28500, Loss: 0.225\n",
            "Epoch: 42, Iteration: 29000, Loss: 0.988\n",
            "Epoch: 42, Iteration: 29500, Loss: 0.095\n",
            "Epoch: 42, Iteration: 30000, Loss: 0.080\n",
            "Epoch: 42, Iteration: 30500, Loss: 0.091\n",
            "Epoch: 42, Iteration: 31000, Loss: 0.950\n",
            "Epoch: 42, Iteration: 31500, Loss: 0.078\n",
            "Epoch: 42, Iteration: 32000, Loss: 0.121\n",
            "Epoch: 42, Iteration: 32500, Loss: 0.092\n",
            "Epoch: 42, Iteration: 33000, Loss: 0.110\n",
            "Epoch: 42, Iteration: 33500, Loss: 0.355\n",
            "Epoch: 42, Iteration: 34000, Loss: 0.075\n",
            "Epoch: 42, Iteration: 34500, Loss: 1.530\n",
            "Epoch: 42, Iteration: 35000, Loss: 4.626\n",
            "Epoch: 42, Iteration: 35500, Loss: 1.032\n",
            "Epoch: 42, Iteration: 36000, Loss: 0.201\n",
            "Epoch: 42, Iteration: 36500, Loss: 0.063\n",
            "Epoch: 42, Iteration: 37000, Loss: 1.911\n",
            "Epoch: 42, Iteration: 37500, Loss: 0.080\n",
            "Epoch: 42, Iteration: 38000, Loss: 0.084\n",
            "Epoch: 42, Iteration: 38500, Loss: 0.468\n",
            "Epoch: 42, Iteration: 39000, Loss: 2.001\n",
            "Epoch: 42, Iteration: 39500, Loss: 0.176\n",
            "Epoch: 42, Iteration: 40000, Loss: 0.082\n",
            "Epoch: 42, Iteration: 40500, Loss: 0.047\n",
            "Epoch: 42, Iteration: 41000, Loss: 0.120\n",
            "Epoch: 42, Iteration: 41500, Loss: 0.772\n",
            "Epoch: 42, Iteration: 42000, Loss: 0.072\n",
            "Epoch: 42, Iteration: 42500, Loss: 0.461\n",
            "Epoch: 42, Iteration: 43000, Loss: 0.077\n",
            "Epoch: 42, Iteration: 43500, Loss: 0.749\n",
            "Epoch: 42, Iteration: 44000, Loss: 1.036\n",
            "Epoch: 42, Iteration: 44500, Loss: 0.127\n",
            "Epoch: 42, Iteration: 45000, Loss: 2.650\n",
            "Epoch: 42, Iteration: 45500, Loss: 0.073\n",
            "Epoch: 42, Iteration: 46000, Loss: 0.129\n",
            "Epoch: 42, Iteration: 46500, Loss: 5.416\n",
            "Epoch: 42, Iteration: 47000, Loss: 0.076\n",
            "Epoch: 42, Iteration: 47500, Loss: 0.262\n",
            "Epoch: 42, Iteration: 48000, Loss: 1.566\n",
            "Epoch: 42, Iteration: 48500, Loss: 3.412\n",
            "Epoch: 42, Iteration: 49000, Loss: 0.435\n",
            "Epoch: 42, Iteration: 49500, Loss: 1.333\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.22 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.87 %\n",
            "w(T) = 0.850\n",
            "Epoch: 43, Iteration:     0, Loss: 0.444\n",
            "Epoch: 43, Iteration:   500, Loss: 1.548\n",
            "Epoch: 43, Iteration:  1000, Loss: 0.075\n",
            "Epoch: 43, Iteration:  1500, Loss: 2.505\n",
            "Epoch: 43, Iteration:  2000, Loss: 2.019\n",
            "Epoch: 43, Iteration:  2500, Loss: 2.203\n",
            "Epoch: 43, Iteration:  3000, Loss: 0.143\n",
            "Epoch: 43, Iteration:  3500, Loss: 0.780\n",
            "Epoch: 43, Iteration:  4000, Loss: 1.706\n",
            "Epoch: 43, Iteration:  4500, Loss: 1.487\n",
            "Epoch: 43, Iteration:  5000, Loss: 0.119\n",
            "Epoch: 43, Iteration:  5500, Loss: 0.525\n",
            "Epoch: 43, Iteration:  6000, Loss: 0.390\n",
            "Epoch: 43, Iteration:  6500, Loss: 1.344\n",
            "Epoch: 43, Iteration:  7000, Loss: 0.081\n",
            "Epoch: 43, Iteration:  7500, Loss: 1.624\n",
            "Epoch: 43, Iteration:  8000, Loss: 0.099\n",
            "Epoch: 43, Iteration:  8500, Loss: 0.086\n",
            "Epoch: 43, Iteration:  9000, Loss: 0.094\n",
            "Epoch: 43, Iteration:  9500, Loss: 0.123\n",
            "Epoch: 43, Iteration: 10000, Loss: 0.216\n",
            "Epoch: 43, Iteration: 10500, Loss: 0.099\n",
            "Epoch: 43, Iteration: 11000, Loss: 0.094\n",
            "Epoch: 43, Iteration: 11500, Loss: 2.238\n",
            "Epoch: 43, Iteration: 12000, Loss: 0.066\n",
            "Epoch: 43, Iteration: 12500, Loss: 1.443\n",
            "Epoch: 43, Iteration: 13000, Loss: 0.084\n",
            "Epoch: 43, Iteration: 13500, Loss: 0.079\n",
            "Epoch: 43, Iteration: 14000, Loss: 1.149\n",
            "Epoch: 43, Iteration: 14500, Loss: 0.198\n",
            "Epoch: 43, Iteration: 15000, Loss: 1.149\n",
            "Epoch: 43, Iteration: 15500, Loss: 0.228\n",
            "Epoch: 43, Iteration: 16000, Loss: 0.107\n",
            "Epoch: 43, Iteration: 16500, Loss: 0.121\n",
            "Epoch: 43, Iteration: 17000, Loss: 0.081\n",
            "Epoch: 43, Iteration: 17500, Loss: 0.105\n",
            "Epoch: 43, Iteration: 18000, Loss: 0.107\n",
            "Epoch: 43, Iteration: 18500, Loss: 0.091\n",
            "Epoch: 43, Iteration: 19000, Loss: 0.086\n",
            "Epoch: 43, Iteration: 19500, Loss: 0.083\n",
            "Epoch: 43, Iteration: 20000, Loss: 0.538\n",
            "Epoch: 43, Iteration: 20500, Loss: 1.378\n",
            "Epoch: 43, Iteration: 21000, Loss: 0.096\n",
            "Epoch: 43, Iteration: 21500, Loss: 0.186\n",
            "Epoch: 43, Iteration: 22000, Loss: 0.073\n",
            "Epoch: 43, Iteration: 22500, Loss: 0.910\n",
            "Epoch: 43, Iteration: 23000, Loss: 0.074\n",
            "Epoch: 43, Iteration: 23500, Loss: 0.564\n",
            "Epoch: 43, Iteration: 24000, Loss: 0.200\n",
            "Epoch: 43, Iteration: 24500, Loss: 3.548\n",
            "Epoch: 43, Iteration: 25000, Loss: 0.110\n",
            "Epoch: 43, Iteration: 25500, Loss: 1.005\n",
            "Epoch: 43, Iteration: 26000, Loss: 0.122\n",
            "Epoch: 43, Iteration: 26500, Loss: 1.478\n",
            "Epoch: 43, Iteration: 27000, Loss: 2.434\n",
            "Epoch: 43, Iteration: 27500, Loss: 0.831\n",
            "Epoch: 43, Iteration: 28000, Loss: 1.365\n",
            "Epoch: 43, Iteration: 28500, Loss: 0.766\n",
            "Epoch: 43, Iteration: 29000, Loss: 0.134\n",
            "Epoch: 43, Iteration: 29500, Loss: 1.160\n",
            "Epoch: 43, Iteration: 30000, Loss: 2.576\n",
            "Epoch: 43, Iteration: 30500, Loss: 1.523\n",
            "Epoch: 43, Iteration: 31000, Loss: 2.113\n",
            "Epoch: 43, Iteration: 31500, Loss: 0.152\n",
            "Epoch: 43, Iteration: 32000, Loss: 3.043\n",
            "Epoch: 43, Iteration: 32500, Loss: 0.060\n",
            "Epoch: 43, Iteration: 33000, Loss: 0.185\n",
            "Epoch: 43, Iteration: 33500, Loss: 0.054\n",
            "Epoch: 43, Iteration: 34000, Loss: 1.799\n",
            "Epoch: 43, Iteration: 34500, Loss: 0.073\n",
            "Epoch: 43, Iteration: 35000, Loss: 0.116\n",
            "Epoch: 43, Iteration: 35500, Loss: 0.247\n",
            "Epoch: 43, Iteration: 36000, Loss: 0.401\n",
            "Epoch: 43, Iteration: 36500, Loss: 0.847\n",
            "Epoch: 43, Iteration: 37000, Loss: 1.253\n",
            "Epoch: 43, Iteration: 37500, Loss: 0.372\n",
            "Epoch: 43, Iteration: 38000, Loss: 1.109\n",
            "Epoch: 43, Iteration: 38500, Loss: 0.394\n",
            "Epoch: 43, Iteration: 39000, Loss: 0.067\n",
            "Epoch: 43, Iteration: 39500, Loss: 1.241\n",
            "Epoch: 43, Iteration: 40000, Loss: 0.048\n",
            "Epoch: 43, Iteration: 40500, Loss: 0.210\n",
            "Epoch: 43, Iteration: 41000, Loss: 0.068\n",
            "Epoch: 43, Iteration: 41500, Loss: 1.504\n",
            "Epoch: 43, Iteration: 42000, Loss: 0.093\n",
            "Epoch: 43, Iteration: 42500, Loss: 0.225\n",
            "Epoch: 43, Iteration: 43000, Loss: 0.075\n",
            "Epoch: 43, Iteration: 43500, Loss: 0.972\n",
            "Epoch: 43, Iteration: 44000, Loss: 0.091\n",
            "Epoch: 43, Iteration: 44500, Loss: 0.359\n",
            "Epoch: 43, Iteration: 45000, Loss: 0.185\n",
            "Epoch: 43, Iteration: 45500, Loss: 2.476\n",
            "Epoch: 43, Iteration: 46000, Loss: 0.100\n",
            "Epoch: 43, Iteration: 46500, Loss: 2.383\n",
            "Epoch: 43, Iteration: 47000, Loss: 0.073\n",
            "Epoch: 43, Iteration: 47500, Loss: 1.592\n",
            "Epoch: 43, Iteration: 48000, Loss: 0.299\n",
            "Epoch: 43, Iteration: 48500, Loss: 0.840\n",
            "Epoch: 43, Iteration: 49000, Loss: 1.011\n",
            "Epoch: 43, Iteration: 49500, Loss: 0.281\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.62 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.83 %\n",
            "w(T) = 0.880\n",
            "Epoch: 44, Iteration:     0, Loss: 0.127\n",
            "Epoch: 44, Iteration:   500, Loss: 0.133\n",
            "Epoch: 44, Iteration:  1000, Loss: 3.234\n",
            "Epoch: 44, Iteration:  1500, Loss: 1.594\n",
            "Epoch: 44, Iteration:  2000, Loss: 0.097\n",
            "Epoch: 44, Iteration:  2500, Loss: 0.151\n",
            "Epoch: 44, Iteration:  3000, Loss: 0.137\n",
            "Epoch: 44, Iteration:  3500, Loss: 0.548\n",
            "Epoch: 44, Iteration:  4000, Loss: 1.193\n",
            "Epoch: 44, Iteration:  4500, Loss: 0.353\n",
            "Epoch: 44, Iteration:  5000, Loss: 0.974\n",
            "Epoch: 44, Iteration:  5500, Loss: 0.057\n",
            "Epoch: 44, Iteration:  6000, Loss: 1.402\n",
            "Epoch: 44, Iteration:  6500, Loss: 0.788\n",
            "Epoch: 44, Iteration:  7000, Loss: 0.116\n",
            "Epoch: 44, Iteration:  7500, Loss: 0.075\n",
            "Epoch: 44, Iteration:  8000, Loss: 0.594\n",
            "Epoch: 44, Iteration:  8500, Loss: 1.909\n",
            "Epoch: 44, Iteration:  9000, Loss: 1.256\n",
            "Epoch: 44, Iteration:  9500, Loss: 2.264\n",
            "Epoch: 44, Iteration: 10000, Loss: 0.087\n",
            "Epoch: 44, Iteration: 10500, Loss: 0.605\n",
            "Epoch: 44, Iteration: 11000, Loss: 0.173\n",
            "Epoch: 44, Iteration: 11500, Loss: 0.233\n",
            "Epoch: 44, Iteration: 12000, Loss: 0.821\n",
            "Epoch: 44, Iteration: 12500, Loss: 0.153\n",
            "Epoch: 44, Iteration: 13000, Loss: 0.153\n",
            "Epoch: 44, Iteration: 13500, Loss: 1.146\n",
            "Epoch: 44, Iteration: 14000, Loss: 0.128\n",
            "Epoch: 44, Iteration: 14500, Loss: 0.554\n",
            "Epoch: 44, Iteration: 15000, Loss: 0.895\n",
            "Epoch: 44, Iteration: 15500, Loss: 1.478\n",
            "Epoch: 44, Iteration: 16000, Loss: 0.134\n",
            "Epoch: 44, Iteration: 16500, Loss: 2.120\n",
            "Epoch: 44, Iteration: 17000, Loss: 0.459\n",
            "Epoch: 44, Iteration: 17500, Loss: 0.124\n",
            "Epoch: 44, Iteration: 18000, Loss: 1.265\n",
            "Epoch: 44, Iteration: 18500, Loss: 0.665\n",
            "Epoch: 44, Iteration: 19000, Loss: 0.540\n",
            "Epoch: 44, Iteration: 19500, Loss: 0.083\n",
            "Epoch: 44, Iteration: 20000, Loss: 0.115\n",
            "Epoch: 44, Iteration: 20500, Loss: 0.134\n",
            "Epoch: 44, Iteration: 21000, Loss: 1.147\n",
            "Epoch: 44, Iteration: 21500, Loss: 0.174\n",
            "Epoch: 44, Iteration: 22000, Loss: 0.094\n",
            "Epoch: 44, Iteration: 22500, Loss: 2.677\n",
            "Epoch: 44, Iteration: 23000, Loss: 0.063\n",
            "Epoch: 44, Iteration: 23500, Loss: 0.102\n",
            "Epoch: 44, Iteration: 24000, Loss: 1.270\n",
            "Epoch: 44, Iteration: 24500, Loss: 0.151\n",
            "Epoch: 44, Iteration: 25000, Loss: 0.874\n",
            "Epoch: 44, Iteration: 25500, Loss: 1.754\n",
            "Epoch: 44, Iteration: 26000, Loss: 0.069\n",
            "Epoch: 44, Iteration: 26500, Loss: 3.051\n",
            "Epoch: 44, Iteration: 27000, Loss: 1.906\n",
            "Epoch: 44, Iteration: 27500, Loss: 1.077\n",
            "Epoch: 44, Iteration: 28000, Loss: 0.645\n",
            "Epoch: 44, Iteration: 28500, Loss: 0.093\n",
            "Epoch: 44, Iteration: 29000, Loss: 0.074\n",
            "Epoch: 44, Iteration: 29500, Loss: 0.960\n",
            "Epoch: 44, Iteration: 30000, Loss: 0.113\n",
            "Epoch: 44, Iteration: 30500, Loss: 0.180\n",
            "Epoch: 44, Iteration: 31000, Loss: 0.093\n",
            "Epoch: 44, Iteration: 31500, Loss: 2.077\n",
            "Epoch: 44, Iteration: 32000, Loss: 0.805\n",
            "Epoch: 44, Iteration: 32500, Loss: 0.098\n",
            "Epoch: 44, Iteration: 33000, Loss: 0.087\n",
            "Epoch: 44, Iteration: 33500, Loss: 0.895\n",
            "Epoch: 44, Iteration: 34000, Loss: 1.607\n",
            "Epoch: 44, Iteration: 34500, Loss: 0.174\n",
            "Epoch: 44, Iteration: 35000, Loss: 0.451\n",
            "Epoch: 44, Iteration: 35500, Loss: 0.291\n",
            "Epoch: 44, Iteration: 36000, Loss: 1.996\n",
            "Epoch: 44, Iteration: 36500, Loss: 0.105\n",
            "Epoch: 44, Iteration: 37000, Loss: 0.900\n",
            "Epoch: 44, Iteration: 37500, Loss: 0.067\n",
            "Epoch: 44, Iteration: 38000, Loss: 0.779\n",
            "Epoch: 44, Iteration: 38500, Loss: 0.094\n",
            "Epoch: 44, Iteration: 39000, Loss: 0.750\n",
            "Epoch: 44, Iteration: 39500, Loss: 0.981\n",
            "Epoch: 44, Iteration: 40000, Loss: 2.386\n",
            "Epoch: 44, Iteration: 40500, Loss: 0.097\n",
            "Epoch: 44, Iteration: 41000, Loss: 0.529\n",
            "Epoch: 44, Iteration: 41500, Loss: 1.473\n",
            "Epoch: 44, Iteration: 42000, Loss: 1.222\n",
            "Epoch: 44, Iteration: 42500, Loss: 4.289\n",
            "Epoch: 44, Iteration: 43000, Loss: 2.438\n",
            "Epoch: 44, Iteration: 43500, Loss: 0.272\n",
            "Epoch: 44, Iteration: 44000, Loss: 0.090\n",
            "Epoch: 44, Iteration: 44500, Loss: 0.676\n",
            "Epoch: 44, Iteration: 45000, Loss: 0.092\n",
            "Epoch: 44, Iteration: 45500, Loss: 0.109\n",
            "Epoch: 44, Iteration: 46000, Loss: 0.105\n",
            "Epoch: 44, Iteration: 46500, Loss: 0.118\n",
            "Epoch: 44, Iteration: 47000, Loss: 1.262\n",
            "Epoch: 44, Iteration: 47500, Loss: 0.406\n",
            "Epoch: 44, Iteration: 48000, Loss: 1.998\n",
            "Epoch: 44, Iteration: 48500, Loss: 1.129\n",
            "Epoch: 44, Iteration: 49000, Loss: 0.299\n",
            "Epoch: 44, Iteration: 49500, Loss: 0.751\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.91 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.86 %\n",
            "w(T) = 0.907\n",
            "Epoch: 45, Iteration:     0, Loss: 0.114\n",
            "Epoch: 45, Iteration:   500, Loss: 0.319\n",
            "Epoch: 45, Iteration:  1000, Loss: 0.090\n",
            "Epoch: 45, Iteration:  1500, Loss: 0.129\n",
            "Epoch: 45, Iteration:  2000, Loss: 0.817\n",
            "Epoch: 45, Iteration:  2500, Loss: 0.663\n",
            "Epoch: 45, Iteration:  3000, Loss: 0.112\n",
            "Epoch: 45, Iteration:  3500, Loss: 0.125\n",
            "Epoch: 45, Iteration:  4000, Loss: 0.469\n",
            "Epoch: 45, Iteration:  4500, Loss: 0.429\n",
            "Epoch: 45, Iteration:  5000, Loss: 0.094\n",
            "Epoch: 45, Iteration:  5500, Loss: 0.939\n",
            "Epoch: 45, Iteration:  6000, Loss: 0.132\n",
            "Epoch: 45, Iteration:  6500, Loss: 2.632\n",
            "Epoch: 45, Iteration:  7000, Loss: 0.770\n",
            "Epoch: 45, Iteration:  7500, Loss: 0.147\n",
            "Epoch: 45, Iteration:  8000, Loss: 1.206\n",
            "Epoch: 45, Iteration:  8500, Loss: 0.110\n",
            "Epoch: 45, Iteration:  9000, Loss: 2.767\n",
            "Epoch: 45, Iteration:  9500, Loss: 0.318\n",
            "Epoch: 45, Iteration: 10000, Loss: 0.081\n",
            "Epoch: 45, Iteration: 10500, Loss: 0.603\n",
            "Epoch: 45, Iteration: 11000, Loss: 0.102\n",
            "Epoch: 45, Iteration: 11500, Loss: 0.079\n",
            "Epoch: 45, Iteration: 12000, Loss: 0.099\n",
            "Epoch: 45, Iteration: 12500, Loss: 0.073\n",
            "Epoch: 45, Iteration: 13000, Loss: 0.242\n",
            "Epoch: 45, Iteration: 13500, Loss: 0.092\n",
            "Epoch: 45, Iteration: 14000, Loss: 0.064\n",
            "Epoch: 45, Iteration: 14500, Loss: 1.854\n",
            "Epoch: 45, Iteration: 15000, Loss: 0.098\n",
            "Epoch: 45, Iteration: 15500, Loss: 0.121\n",
            "Epoch: 45, Iteration: 16000, Loss: 1.289\n",
            "Epoch: 45, Iteration: 16500, Loss: 1.171\n",
            "Epoch: 45, Iteration: 17000, Loss: 0.107\n",
            "Epoch: 45, Iteration: 17500, Loss: 0.095\n",
            "Epoch: 45, Iteration: 18000, Loss: 0.150\n",
            "Epoch: 45, Iteration: 18500, Loss: 0.106\n",
            "Epoch: 45, Iteration: 19000, Loss: 1.459\n",
            "Epoch: 45, Iteration: 19500, Loss: 0.244\n",
            "Epoch: 45, Iteration: 20000, Loss: 0.077\n",
            "Epoch: 45, Iteration: 20500, Loss: 0.101\n",
            "Epoch: 45, Iteration: 21000, Loss: 0.776\n",
            "Epoch: 45, Iteration: 21500, Loss: 0.123\n",
            "Epoch: 45, Iteration: 22000, Loss: 1.330\n",
            "Epoch: 45, Iteration: 22500, Loss: 0.663\n",
            "Epoch: 45, Iteration: 23000, Loss: 0.278\n",
            "Epoch: 45, Iteration: 23500, Loss: 1.086\n",
            "Epoch: 45, Iteration: 24000, Loss: 0.130\n",
            "Epoch: 45, Iteration: 24500, Loss: 1.714\n",
            "Epoch: 45, Iteration: 25000, Loss: 0.103\n",
            "Epoch: 45, Iteration: 25500, Loss: 0.141\n",
            "Epoch: 45, Iteration: 26000, Loss: 1.893\n",
            "Epoch: 45, Iteration: 26500, Loss: 0.697\n",
            "Epoch: 45, Iteration: 27000, Loss: 0.148\n",
            "Epoch: 45, Iteration: 27500, Loss: 0.122\n",
            "Epoch: 45, Iteration: 28000, Loss: 1.266\n",
            "Epoch: 45, Iteration: 28500, Loss: 0.088\n",
            "Epoch: 45, Iteration: 29000, Loss: 0.170\n",
            "Epoch: 45, Iteration: 29500, Loss: 0.154\n",
            "Epoch: 45, Iteration: 30000, Loss: 1.406\n",
            "Epoch: 45, Iteration: 30500, Loss: 0.114\n",
            "Epoch: 45, Iteration: 31000, Loss: 0.129\n",
            "Epoch: 45, Iteration: 31500, Loss: 0.130\n",
            "Epoch: 45, Iteration: 32000, Loss: 0.410\n",
            "Epoch: 45, Iteration: 32500, Loss: 1.334\n",
            "Epoch: 45, Iteration: 33000, Loss: 0.392\n",
            "Epoch: 45, Iteration: 33500, Loss: 0.833\n",
            "Epoch: 45, Iteration: 34000, Loss: 0.168\n",
            "Epoch: 45, Iteration: 34500, Loss: 0.080\n",
            "Epoch: 45, Iteration: 35000, Loss: 0.405\n",
            "Epoch: 45, Iteration: 35500, Loss: 0.797\n",
            "Epoch: 45, Iteration: 36000, Loss: 1.501\n",
            "Epoch: 45, Iteration: 36500, Loss: 1.780\n",
            "Epoch: 45, Iteration: 37000, Loss: 0.089\n",
            "Epoch: 45, Iteration: 37500, Loss: 0.654\n",
            "Epoch: 45, Iteration: 38000, Loss: 1.931\n",
            "Epoch: 45, Iteration: 38500, Loss: 0.090\n",
            "Epoch: 45, Iteration: 39000, Loss: 0.381\n",
            "Epoch: 45, Iteration: 39500, Loss: 0.092\n",
            "Epoch: 45, Iteration: 40000, Loss: 0.196\n",
            "Epoch: 45, Iteration: 40500, Loss: 0.091\n",
            "Epoch: 45, Iteration: 41000, Loss: 1.693\n",
            "Epoch: 45, Iteration: 41500, Loss: 0.711\n",
            "Epoch: 45, Iteration: 42000, Loss: 0.084\n",
            "Epoch: 45, Iteration: 42500, Loss: 1.056\n",
            "Epoch: 45, Iteration: 43000, Loss: 0.057\n",
            "Epoch: 45, Iteration: 43500, Loss: 0.129\n",
            "Epoch: 45, Iteration: 44000, Loss: 0.072\n",
            "Epoch: 45, Iteration: 44500, Loss: 0.071\n",
            "Epoch: 45, Iteration: 45000, Loss: 1.239\n",
            "Epoch: 45, Iteration: 45500, Loss: 1.041\n",
            "Epoch: 45, Iteration: 46000, Loss: 3.385\n",
            "Epoch: 45, Iteration: 46500, Loss: 0.093\n",
            "Epoch: 45, Iteration: 47000, Loss: 0.118\n",
            "Epoch: 45, Iteration: 47500, Loss: 0.448\n",
            "Epoch: 45, Iteration: 48000, Loss: 0.118\n",
            "Epoch: 45, Iteration: 48500, Loss: 0.428\n",
            "Epoch: 45, Iteration: 49000, Loss: 0.370\n",
            "Epoch: 45, Iteration: 49500, Loss: 0.070\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.55 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.62 %\n",
            "w(T) = 0.931\n",
            "Epoch: 46, Iteration:     0, Loss: 0.088\n",
            "Epoch: 46, Iteration:   500, Loss: 0.099\n",
            "Epoch: 46, Iteration:  1000, Loss: 0.101\n",
            "Epoch: 46, Iteration:  1500, Loss: 0.505\n",
            "Epoch: 46, Iteration:  2000, Loss: 0.103\n",
            "Epoch: 46, Iteration:  2500, Loss: 0.330\n",
            "Epoch: 46, Iteration:  3000, Loss: 0.328\n",
            "Epoch: 46, Iteration:  3500, Loss: 0.406\n",
            "Epoch: 46, Iteration:  4000, Loss: 0.155\n",
            "Epoch: 46, Iteration:  4500, Loss: 0.103\n",
            "Epoch: 46, Iteration:  5000, Loss: 0.095\n",
            "Epoch: 46, Iteration:  5500, Loss: 1.434\n",
            "Epoch: 46, Iteration:  6000, Loss: 0.080\n",
            "Epoch: 46, Iteration:  6500, Loss: 2.229\n",
            "Epoch: 46, Iteration:  7000, Loss: 1.440\n",
            "Epoch: 46, Iteration:  7500, Loss: 0.247\n",
            "Epoch: 46, Iteration:  8000, Loss: 2.920\n",
            "Epoch: 46, Iteration:  8500, Loss: 0.148\n",
            "Epoch: 46, Iteration:  9000, Loss: 0.573\n",
            "Epoch: 46, Iteration:  9500, Loss: 2.198\n",
            "Epoch: 46, Iteration: 10000, Loss: 0.532\n",
            "Epoch: 46, Iteration: 10500, Loss: 2.069\n",
            "Epoch: 46, Iteration: 11000, Loss: 0.070\n",
            "Epoch: 46, Iteration: 11500, Loss: 1.709\n",
            "Epoch: 46, Iteration: 12000, Loss: 0.272\n",
            "Epoch: 46, Iteration: 12500, Loss: 0.850\n",
            "Epoch: 46, Iteration: 13000, Loss: 0.155\n",
            "Epoch: 46, Iteration: 13500, Loss: 0.194\n",
            "Epoch: 46, Iteration: 14000, Loss: 0.120\n",
            "Epoch: 46, Iteration: 14500, Loss: 0.152\n",
            "Epoch: 46, Iteration: 15000, Loss: 0.952\n",
            "Epoch: 46, Iteration: 15500, Loss: 1.760\n",
            "Epoch: 46, Iteration: 16000, Loss: 2.170\n",
            "Epoch: 46, Iteration: 16500, Loss: 0.114\n",
            "Epoch: 46, Iteration: 17000, Loss: 0.135\n",
            "Epoch: 46, Iteration: 17500, Loss: 0.101\n",
            "Epoch: 46, Iteration: 18000, Loss: 1.763\n",
            "Epoch: 46, Iteration: 18500, Loss: 0.058\n",
            "Epoch: 46, Iteration: 19000, Loss: 0.671\n",
            "Epoch: 46, Iteration: 19500, Loss: 0.815\n",
            "Epoch: 46, Iteration: 20000, Loss: 0.088\n",
            "Epoch: 46, Iteration: 20500, Loss: 0.146\n",
            "Epoch: 46, Iteration: 21000, Loss: 0.182\n",
            "Epoch: 46, Iteration: 21500, Loss: 0.104\n",
            "Epoch: 46, Iteration: 22000, Loss: 0.649\n",
            "Epoch: 46, Iteration: 22500, Loss: 0.063\n",
            "Epoch: 46, Iteration: 23000, Loss: 0.440\n",
            "Epoch: 46, Iteration: 23500, Loss: 0.087\n",
            "Epoch: 46, Iteration: 24000, Loss: 0.975\n",
            "Epoch: 46, Iteration: 24500, Loss: 1.773\n",
            "Epoch: 46, Iteration: 25000, Loss: 1.255\n",
            "Epoch: 46, Iteration: 25500, Loss: 0.095\n",
            "Epoch: 46, Iteration: 26000, Loss: 0.995\n",
            "Epoch: 46, Iteration: 26500, Loss: 1.791\n",
            "Epoch: 46, Iteration: 27000, Loss: 1.686\n",
            "Epoch: 46, Iteration: 27500, Loss: 0.099\n",
            "Epoch: 46, Iteration: 28000, Loss: 1.141\n",
            "Epoch: 46, Iteration: 28500, Loss: 0.104\n",
            "Epoch: 46, Iteration: 29000, Loss: 0.087\n",
            "Epoch: 46, Iteration: 29500, Loss: 0.654\n",
            "Epoch: 46, Iteration: 30000, Loss: 0.105\n",
            "Epoch: 46, Iteration: 30500, Loss: 0.169\n",
            "Epoch: 46, Iteration: 31000, Loss: 0.769\n",
            "Epoch: 46, Iteration: 31500, Loss: 0.103\n",
            "Epoch: 46, Iteration: 32000, Loss: 0.114\n",
            "Epoch: 46, Iteration: 32500, Loss: 0.132\n",
            "Epoch: 46, Iteration: 33000, Loss: 0.117\n",
            "Epoch: 46, Iteration: 33500, Loss: 0.118\n",
            "Epoch: 46, Iteration: 34000, Loss: 0.173\n",
            "Epoch: 46, Iteration: 34500, Loss: 0.514\n",
            "Epoch: 46, Iteration: 35000, Loss: 1.322\n",
            "Epoch: 46, Iteration: 35500, Loss: 0.097\n",
            "Epoch: 46, Iteration: 36000, Loss: 1.512\n",
            "Epoch: 46, Iteration: 36500, Loss: 0.200\n",
            "Epoch: 46, Iteration: 37000, Loss: 1.741\n",
            "Epoch: 46, Iteration: 37500, Loss: 1.204\n",
            "Epoch: 46, Iteration: 38000, Loss: 2.713\n",
            "Epoch: 46, Iteration: 38500, Loss: 0.124\n",
            "Epoch: 46, Iteration: 39000, Loss: 0.114\n",
            "Epoch: 46, Iteration: 39500, Loss: 0.548\n",
            "Epoch: 46, Iteration: 40000, Loss: 1.692\n",
            "Epoch: 46, Iteration: 40500, Loss: 0.436\n",
            "Epoch: 46, Iteration: 41000, Loss: 0.665\n",
            "Epoch: 46, Iteration: 41500, Loss: 0.129\n",
            "Epoch: 46, Iteration: 42000, Loss: 1.313\n",
            "Epoch: 46, Iteration: 42500, Loss: 0.533\n",
            "Epoch: 46, Iteration: 43000, Loss: 1.348\n",
            "Epoch: 46, Iteration: 43500, Loss: 0.389\n",
            "Epoch: 46, Iteration: 44000, Loss: 0.071\n",
            "Epoch: 46, Iteration: 44500, Loss: 0.655\n",
            "Epoch: 46, Iteration: 45000, Loss: 1.171\n",
            "Epoch: 46, Iteration: 45500, Loss: 1.881\n",
            "Epoch: 46, Iteration: 46000, Loss: 0.108\n",
            "Epoch: 46, Iteration: 46500, Loss: 0.070\n",
            "Epoch: 46, Iteration: 47000, Loss: 1.608\n",
            "Epoch: 46, Iteration: 47500, Loss: 0.924\n",
            "Epoch: 46, Iteration: 48000, Loss: 0.124\n",
            "Epoch: 46, Iteration: 48500, Loss: 0.438\n",
            "Epoch: 46, Iteration: 49000, Loss: 0.331\n",
            "Epoch: 46, Iteration: 49500, Loss: 0.121\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.83 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.77 %\n",
            "w(T) = 0.951\n",
            "Epoch: 47, Iteration:     0, Loss: 3.131\n",
            "Epoch: 47, Iteration:   500, Loss: 0.402\n",
            "Epoch: 47, Iteration:  1000, Loss: 0.439\n",
            "Epoch: 47, Iteration:  1500, Loss: 0.137\n",
            "Epoch: 47, Iteration:  2000, Loss: 1.681\n",
            "Epoch: 47, Iteration:  2500, Loss: 0.106\n",
            "Epoch: 47, Iteration:  3000, Loss: 0.117\n",
            "Epoch: 47, Iteration:  3500, Loss: 0.120\n",
            "Epoch: 47, Iteration:  4000, Loss: 0.165\n",
            "Epoch: 47, Iteration:  4500, Loss: 0.114\n",
            "Epoch: 47, Iteration:  5000, Loss: 0.112\n",
            "Epoch: 47, Iteration:  5500, Loss: 0.270\n",
            "Epoch: 47, Iteration:  6000, Loss: 0.177\n",
            "Epoch: 47, Iteration:  6500, Loss: 0.207\n",
            "Epoch: 47, Iteration:  7000, Loss: 0.128\n",
            "Epoch: 47, Iteration:  7500, Loss: 1.149\n",
            "Epoch: 47, Iteration:  8000, Loss: 0.118\n",
            "Epoch: 47, Iteration:  8500, Loss: 0.168\n",
            "Epoch: 47, Iteration:  9000, Loss: 0.128\n",
            "Epoch: 47, Iteration:  9500, Loss: 0.481\n",
            "Epoch: 47, Iteration: 10000, Loss: 0.477\n",
            "Epoch: 47, Iteration: 10500, Loss: 0.954\n",
            "Epoch: 47, Iteration: 11000, Loss: 0.182\n",
            "Epoch: 47, Iteration: 11500, Loss: 0.710\n",
            "Epoch: 47, Iteration: 12000, Loss: 0.121\n",
            "Epoch: 47, Iteration: 12500, Loss: 0.715\n",
            "Epoch: 47, Iteration: 13000, Loss: 0.727\n",
            "Epoch: 47, Iteration: 13500, Loss: 9.895\n",
            "Epoch: 47, Iteration: 14000, Loss: 0.832\n",
            "Epoch: 47, Iteration: 14500, Loss: 0.106\n",
            "Epoch: 47, Iteration: 15000, Loss: 4.081\n",
            "Epoch: 47, Iteration: 15500, Loss: 0.696\n",
            "Epoch: 47, Iteration: 16000, Loss: 1.117\n",
            "Epoch: 47, Iteration: 16500, Loss: 0.109\n",
            "Epoch: 47, Iteration: 17000, Loss: 1.411\n",
            "Epoch: 47, Iteration: 17500, Loss: 2.270\n",
            "Epoch: 47, Iteration: 18000, Loss: 1.858\n",
            "Epoch: 47, Iteration: 18500, Loss: 1.164\n",
            "Epoch: 47, Iteration: 19000, Loss: 0.111\n",
            "Epoch: 47, Iteration: 19500, Loss: 6.171\n",
            "Epoch: 47, Iteration: 20000, Loss: 0.711\n",
            "Epoch: 47, Iteration: 20500, Loss: 0.093\n",
            "Epoch: 47, Iteration: 21000, Loss: 0.116\n",
            "Epoch: 47, Iteration: 21500, Loss: 0.123\n",
            "Epoch: 47, Iteration: 22000, Loss: 0.988\n",
            "Epoch: 47, Iteration: 22500, Loss: 2.688\n",
            "Epoch: 47, Iteration: 23000, Loss: 0.073\n",
            "Epoch: 47, Iteration: 23500, Loss: 0.067\n",
            "Epoch: 47, Iteration: 24000, Loss: 1.223\n",
            "Epoch: 47, Iteration: 24500, Loss: 0.240\n",
            "Epoch: 47, Iteration: 25000, Loss: 0.085\n",
            "Epoch: 47, Iteration: 25500, Loss: 1.654\n",
            "Epoch: 47, Iteration: 26000, Loss: 0.255\n",
            "Epoch: 47, Iteration: 26500, Loss: 0.268\n",
            "Epoch: 47, Iteration: 27000, Loss: 1.807\n",
            "Epoch: 47, Iteration: 27500, Loss: 0.092\n",
            "Epoch: 47, Iteration: 28000, Loss: 0.086\n",
            "Epoch: 47, Iteration: 28500, Loss: 0.085\n",
            "Epoch: 47, Iteration: 29000, Loss: 0.940\n",
            "Epoch: 47, Iteration: 29500, Loss: 1.741\n",
            "Epoch: 47, Iteration: 30000, Loss: 1.824\n",
            "Epoch: 47, Iteration: 30500, Loss: 0.136\n",
            "Epoch: 47, Iteration: 31000, Loss: 2.332\n",
            "Epoch: 47, Iteration: 31500, Loss: 0.122\n",
            "Epoch: 47, Iteration: 32000, Loss: 1.403\n",
            "Epoch: 47, Iteration: 32500, Loss: 0.131\n",
            "Epoch: 47, Iteration: 33000, Loss: 1.824\n",
            "Epoch: 47, Iteration: 33500, Loss: 0.062\n",
            "Epoch: 47, Iteration: 34000, Loss: 0.083\n",
            "Epoch: 47, Iteration: 34500, Loss: 0.432\n",
            "Epoch: 47, Iteration: 35000, Loss: 0.562\n",
            "Epoch: 47, Iteration: 35500, Loss: 0.110\n",
            "Epoch: 47, Iteration: 36000, Loss: 0.608\n",
            "Epoch: 47, Iteration: 36500, Loss: 0.092\n",
            "Epoch: 47, Iteration: 37000, Loss: 0.092\n",
            "Epoch: 47, Iteration: 37500, Loss: 1.460\n",
            "Epoch: 47, Iteration: 38000, Loss: 0.062\n",
            "Epoch: 47, Iteration: 38500, Loss: 1.645\n",
            "Epoch: 47, Iteration: 39000, Loss: 0.134\n",
            "Epoch: 47, Iteration: 39500, Loss: 0.662\n",
            "Epoch: 47, Iteration: 40000, Loss: 2.463\n",
            "Epoch: 47, Iteration: 40500, Loss: 0.380\n",
            "Epoch: 47, Iteration: 41000, Loss: 0.125\n",
            "Epoch: 47, Iteration: 41500, Loss: 0.108\n",
            "Epoch: 47, Iteration: 42000, Loss: 1.790\n",
            "Epoch: 47, Iteration: 42500, Loss: 0.434\n",
            "Epoch: 47, Iteration: 43000, Loss: 3.668\n",
            "Epoch: 47, Iteration: 43500, Loss: 1.749\n",
            "Epoch: 47, Iteration: 44000, Loss: 0.444\n",
            "Epoch: 47, Iteration: 44500, Loss: 1.454\n",
            "Epoch: 47, Iteration: 45000, Loss: 0.226\n",
            "Epoch: 47, Iteration: 45500, Loss: 0.851\n",
            "Epoch: 47, Iteration: 46000, Loss: 0.256\n",
            "Epoch: 47, Iteration: 46500, Loss: 2.688\n",
            "Epoch: 47, Iteration: 47000, Loss: 0.734\n",
            "Epoch: 47, Iteration: 47500, Loss: 0.091\n",
            "Epoch: 47, Iteration: 48000, Loss: 1.320\n",
            "Epoch: 47, Iteration: 48500, Loss: 0.368\n",
            "Epoch: 47, Iteration: 49000, Loss: 0.132\n",
            "Epoch: 47, Iteration: 49500, Loss: 0.116\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.34 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.56 %\n",
            "w(T) = 0.969\n",
            "Epoch: 48, Iteration:     0, Loss: 1.789\n",
            "Epoch: 48, Iteration:   500, Loss: 0.148\n",
            "Epoch: 48, Iteration:  1000, Loss: 0.448\n",
            "Epoch: 48, Iteration:  1500, Loss: 0.157\n",
            "Epoch: 48, Iteration:  2000, Loss: 0.127\n",
            "Epoch: 48, Iteration:  2500, Loss: 1.672\n",
            "Epoch: 48, Iteration:  3000, Loss: 1.114\n",
            "Epoch: 48, Iteration:  3500, Loss: 0.757\n",
            "Epoch: 48, Iteration:  4000, Loss: 0.396\n",
            "Epoch: 48, Iteration:  4500, Loss: 0.079\n",
            "Epoch: 48, Iteration:  5000, Loss: 0.783\n",
            "Epoch: 48, Iteration:  5500, Loss: 0.158\n",
            "Epoch: 48, Iteration:  6000, Loss: 0.665\n",
            "Epoch: 48, Iteration:  6500, Loss: 0.235\n",
            "Epoch: 48, Iteration:  7000, Loss: 0.582\n",
            "Epoch: 48, Iteration:  7500, Loss: 0.331\n",
            "Epoch: 48, Iteration:  8000, Loss: 0.129\n",
            "Epoch: 48, Iteration:  8500, Loss: 0.366\n",
            "Epoch: 48, Iteration:  9000, Loss: 0.100\n",
            "Epoch: 48, Iteration:  9500, Loss: 0.458\n",
            "Epoch: 48, Iteration: 10000, Loss: 0.087\n",
            "Epoch: 48, Iteration: 10500, Loss: 1.639\n",
            "Epoch: 48, Iteration: 11000, Loss: 0.124\n",
            "Epoch: 48, Iteration: 11500, Loss: 0.349\n",
            "Epoch: 48, Iteration: 12000, Loss: 0.132\n",
            "Epoch: 48, Iteration: 12500, Loss: 0.133\n",
            "Epoch: 48, Iteration: 13000, Loss: 0.120\n",
            "Epoch: 48, Iteration: 13500, Loss: 0.232\n",
            "Epoch: 48, Iteration: 14000, Loss: 0.121\n",
            "Epoch: 48, Iteration: 14500, Loss: 0.253\n",
            "Epoch: 48, Iteration: 15000, Loss: 0.140\n",
            "Epoch: 48, Iteration: 15500, Loss: 1.168\n",
            "Epoch: 48, Iteration: 16000, Loss: 0.105\n",
            "Epoch: 48, Iteration: 16500, Loss: 0.692\n",
            "Epoch: 48, Iteration: 17000, Loss: 0.090\n",
            "Epoch: 48, Iteration: 17500, Loss: 0.207\n",
            "Epoch: 48, Iteration: 18000, Loss: 0.084\n",
            "Epoch: 48, Iteration: 18500, Loss: 0.115\n",
            "Epoch: 48, Iteration: 19000, Loss: 1.944\n",
            "Epoch: 48, Iteration: 19500, Loss: 2.088\n",
            "Epoch: 48, Iteration: 20000, Loss: 0.953\n",
            "Epoch: 48, Iteration: 20500, Loss: 0.094\n",
            "Epoch: 48, Iteration: 21000, Loss: 0.513\n",
            "Epoch: 48, Iteration: 21500, Loss: 0.107\n",
            "Epoch: 48, Iteration: 22000, Loss: 1.084\n",
            "Epoch: 48, Iteration: 22500, Loss: 0.188\n",
            "Epoch: 48, Iteration: 23000, Loss: 0.109\n",
            "Epoch: 48, Iteration: 23500, Loss: 1.490\n",
            "Epoch: 48, Iteration: 24000, Loss: 1.082\n",
            "Epoch: 48, Iteration: 24500, Loss: 0.105\n",
            "Epoch: 48, Iteration: 25000, Loss: 0.078\n",
            "Epoch: 48, Iteration: 25500, Loss: 0.096\n",
            "Epoch: 48, Iteration: 26000, Loss: 0.798\n",
            "Epoch: 48, Iteration: 26500, Loss: 0.090\n",
            "Epoch: 48, Iteration: 27000, Loss: 1.429\n",
            "Epoch: 48, Iteration: 27500, Loss: 0.365\n",
            "Epoch: 48, Iteration: 28000, Loss: 0.155\n",
            "Epoch: 48, Iteration: 28500, Loss: 0.783\n",
            "Epoch: 48, Iteration: 29000, Loss: 0.107\n",
            "Epoch: 48, Iteration: 29500, Loss: 0.106\n",
            "Epoch: 48, Iteration: 30000, Loss: 0.204\n",
            "Epoch: 48, Iteration: 30500, Loss: 0.658\n",
            "Epoch: 48, Iteration: 31000, Loss: 0.128\n",
            "Epoch: 48, Iteration: 31500, Loss: 0.094\n",
            "Epoch: 48, Iteration: 32000, Loss: 0.107\n",
            "Epoch: 48, Iteration: 32500, Loss: 0.139\n",
            "Epoch: 48, Iteration: 33000, Loss: 0.081\n",
            "Epoch: 48, Iteration: 33500, Loss: 0.081\n",
            "Epoch: 48, Iteration: 34000, Loss: 0.179\n",
            "Epoch: 48, Iteration: 34500, Loss: 2.105\n",
            "Epoch: 48, Iteration: 35000, Loss: 12.216\n",
            "Epoch: 48, Iteration: 35500, Loss: 0.106\n",
            "Epoch: 48, Iteration: 36000, Loss: 0.095\n",
            "Epoch: 48, Iteration: 36500, Loss: 0.085\n",
            "Epoch: 48, Iteration: 37000, Loss: 0.620\n",
            "Epoch: 48, Iteration: 37500, Loss: 2.729\n",
            "Epoch: 48, Iteration: 38000, Loss: 0.084\n",
            "Epoch: 48, Iteration: 38500, Loss: 1.764\n",
            "Epoch: 48, Iteration: 39000, Loss: 0.085\n",
            "Epoch: 48, Iteration: 39500, Loss: 0.075\n",
            "Epoch: 48, Iteration: 40000, Loss: 0.092\n",
            "Epoch: 48, Iteration: 40500, Loss: 0.099\n",
            "Epoch: 48, Iteration: 41000, Loss: 0.310\n",
            "Epoch: 48, Iteration: 41500, Loss: 1.195\n",
            "Epoch: 48, Iteration: 42000, Loss: 0.106\n",
            "Epoch: 48, Iteration: 42500, Loss: 0.188\n",
            "Epoch: 48, Iteration: 43000, Loss: 1.711\n",
            "Epoch: 48, Iteration: 43500, Loss: 0.683\n",
            "Epoch: 48, Iteration: 44000, Loss: 1.200\n",
            "Epoch: 48, Iteration: 44500, Loss: 0.425\n",
            "Epoch: 48, Iteration: 45000, Loss: 1.387\n",
            "Epoch: 48, Iteration: 45500, Loss: 3.020\n",
            "Epoch: 48, Iteration: 46000, Loss: 0.746\n",
            "Epoch: 48, Iteration: 46500, Loss: 0.089\n",
            "Epoch: 48, Iteration: 47000, Loss: 0.729\n",
            "Epoch: 48, Iteration: 47500, Loss: 0.102\n",
            "Epoch: 48, Iteration: 48000, Loss: 0.229\n",
            "Epoch: 48, Iteration: 48500, Loss: 1.553\n",
            "Epoch: 48, Iteration: 49000, Loss: 0.138\n",
            "Epoch: 48, Iteration: 49500, Loss: 0.470\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.78 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.29 %\n",
            "w(T) = 0.982\n",
            "Epoch: 49, Iteration:     0, Loss: 0.132\n",
            "Epoch: 49, Iteration:   500, Loss: 0.104\n",
            "Epoch: 49, Iteration:  1000, Loss: 1.108\n",
            "Epoch: 49, Iteration:  1500, Loss: 1.451\n",
            "Epoch: 49, Iteration:  2000, Loss: 0.825\n",
            "Epoch: 49, Iteration:  2500, Loss: 0.132\n",
            "Epoch: 49, Iteration:  3000, Loss: 0.109\n",
            "Epoch: 49, Iteration:  3500, Loss: 0.127\n",
            "Epoch: 49, Iteration:  4000, Loss: 0.093\n",
            "Epoch: 49, Iteration:  4500, Loss: 0.294\n",
            "Epoch: 49, Iteration:  5000, Loss: 0.064\n",
            "Epoch: 49, Iteration:  5500, Loss: 0.131\n",
            "Epoch: 49, Iteration:  6000, Loss: 0.089\n",
            "Epoch: 49, Iteration:  6500, Loss: 1.036\n",
            "Epoch: 49, Iteration:  7000, Loss: 0.127\n",
            "Epoch: 49, Iteration:  7500, Loss: 0.345\n",
            "Epoch: 49, Iteration:  8000, Loss: 0.094\n",
            "Epoch: 49, Iteration:  8500, Loss: 1.250\n",
            "Epoch: 49, Iteration:  9000, Loss: 0.112\n",
            "Epoch: 49, Iteration:  9500, Loss: 0.415\n",
            "Epoch: 49, Iteration: 10000, Loss: 4.119\n",
            "Epoch: 49, Iteration: 10500, Loss: 0.108\n",
            "Epoch: 49, Iteration: 11000, Loss: 0.114\n",
            "Epoch: 49, Iteration: 11500, Loss: 1.339\n",
            "Epoch: 49, Iteration: 12000, Loss: 0.100\n",
            "Epoch: 49, Iteration: 12500, Loss: 0.419\n",
            "Epoch: 49, Iteration: 13000, Loss: 0.771\n",
            "Epoch: 49, Iteration: 13500, Loss: 1.626\n",
            "Epoch: 49, Iteration: 14000, Loss: 0.107\n",
            "Epoch: 49, Iteration: 14500, Loss: 0.612\n",
            "Epoch: 49, Iteration: 15000, Loss: 0.109\n",
            "Epoch: 49, Iteration: 15500, Loss: 0.404\n",
            "Epoch: 49, Iteration: 16000, Loss: 0.084\n",
            "Epoch: 49, Iteration: 16500, Loss: 0.365\n",
            "Epoch: 49, Iteration: 17000, Loss: 0.116\n",
            "Epoch: 49, Iteration: 17500, Loss: 0.106\n",
            "Epoch: 49, Iteration: 18000, Loss: 0.086\n",
            "Epoch: 49, Iteration: 18500, Loss: 1.552\n",
            "Epoch: 49, Iteration: 19000, Loss: 1.939\n",
            "Epoch: 49, Iteration: 19500, Loss: 1.450\n",
            "Epoch: 49, Iteration: 20000, Loss: 0.082\n",
            "Epoch: 49, Iteration: 20500, Loss: 0.898\n",
            "Epoch: 49, Iteration: 21000, Loss: 0.106\n",
            "Epoch: 49, Iteration: 21500, Loss: 0.194\n",
            "Epoch: 49, Iteration: 22000, Loss: 0.289\n",
            "Epoch: 49, Iteration: 22500, Loss: 1.356\n",
            "Epoch: 49, Iteration: 23000, Loss: 0.116\n",
            "Epoch: 49, Iteration: 23500, Loss: 0.127\n",
            "Epoch: 49, Iteration: 24000, Loss: 0.327\n",
            "Epoch: 49, Iteration: 24500, Loss: 0.089\n",
            "Epoch: 49, Iteration: 25000, Loss: 0.433\n",
            "Epoch: 49, Iteration: 25500, Loss: 1.509\n",
            "Epoch: 49, Iteration: 26000, Loss: 0.133\n",
            "Epoch: 49, Iteration: 26500, Loss: 0.092\n",
            "Epoch: 49, Iteration: 27000, Loss: 1.274\n",
            "Epoch: 49, Iteration: 27500, Loss: 0.304\n",
            "Epoch: 49, Iteration: 28000, Loss: 0.112\n",
            "Epoch: 49, Iteration: 28500, Loss: 0.562\n",
            "Epoch: 49, Iteration: 29000, Loss: 0.131\n",
            "Epoch: 49, Iteration: 29500, Loss: 0.079\n",
            "Epoch: 49, Iteration: 30000, Loss: 0.106\n",
            "Epoch: 49, Iteration: 30500, Loss: 0.096\n",
            "Epoch: 49, Iteration: 31000, Loss: 2.380\n",
            "Epoch: 49, Iteration: 31500, Loss: 1.821\n",
            "Epoch: 49, Iteration: 32000, Loss: 1.246\n",
            "Epoch: 49, Iteration: 32500, Loss: 2.442\n",
            "Epoch: 49, Iteration: 33000, Loss: 2.589\n",
            "Epoch: 49, Iteration: 33500, Loss: 1.978\n",
            "Epoch: 49, Iteration: 34000, Loss: 0.089\n",
            "Epoch: 49, Iteration: 34500, Loss: 2.047\n",
            "Epoch: 49, Iteration: 35000, Loss: 1.432\n",
            "Epoch: 49, Iteration: 35500, Loss: 1.843\n",
            "Epoch: 49, Iteration: 36000, Loss: 0.097\n",
            "Epoch: 49, Iteration: 36500, Loss: 0.090\n",
            "Epoch: 49, Iteration: 37000, Loss: 1.651\n",
            "Epoch: 49, Iteration: 37500, Loss: 0.096\n",
            "Epoch: 49, Iteration: 38000, Loss: 0.140\n",
            "Epoch: 49, Iteration: 38500, Loss: 1.614\n",
            "Epoch: 49, Iteration: 39000, Loss: 2.577\n",
            "Epoch: 49, Iteration: 39500, Loss: 0.124\n",
            "Epoch: 49, Iteration: 40000, Loss: 0.115\n",
            "Epoch: 49, Iteration: 40500, Loss: 1.606\n",
            "Epoch: 49, Iteration: 41000, Loss: 0.736\n",
            "Epoch: 49, Iteration: 41500, Loss: 3.708\n",
            "Epoch: 49, Iteration: 42000, Loss: 0.115\n",
            "Epoch: 49, Iteration: 42500, Loss: 0.129\n",
            "Epoch: 49, Iteration: 43000, Loss: 0.238\n",
            "Epoch: 49, Iteration: 43500, Loss: 1.443\n",
            "Epoch: 49, Iteration: 44000, Loss: 2.126\n",
            "Epoch: 49, Iteration: 44500, Loss: 1.330\n",
            "Epoch: 49, Iteration: 45000, Loss: 0.168\n",
            "Epoch: 49, Iteration: 45500, Loss: 2.260\n",
            "Epoch: 49, Iteration: 46000, Loss: 1.346\n",
            "Epoch: 49, Iteration: 46500, Loss: 0.713\n",
            "Epoch: 49, Iteration: 47000, Loss: 2.217\n",
            "Epoch: 49, Iteration: 47500, Loss: 0.641\n",
            "Epoch: 49, Iteration: 48000, Loss: 0.120\n",
            "Epoch: 49, Iteration: 48500, Loss: 0.116\n",
            "Epoch: 49, Iteration: 49000, Loss: 1.699\n",
            "Epoch: 49, Iteration: 49500, Loss: 0.102\n",
            "Accuracy of the neural network on CIFAR_10 is: 36.22 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 34.75 %\n",
            "w(T) = 0.992\n",
            "Epoch: 50, Iteration:     0, Loss: 0.139\n",
            "Epoch: 50, Iteration:   500, Loss: 2.724\n",
            "Epoch: 50, Iteration:  1000, Loss: 0.095\n",
            "Epoch: 50, Iteration:  1500, Loss: 0.081\n",
            "Epoch: 50, Iteration:  2000, Loss: 0.104\n",
            "Epoch: 50, Iteration:  2500, Loss: 0.502\n",
            "Epoch: 50, Iteration:  3000, Loss: 0.184\n",
            "Epoch: 50, Iteration:  3500, Loss: 0.111\n",
            "Epoch: 50, Iteration:  4000, Loss: 1.939\n",
            "Epoch: 50, Iteration:  4500, Loss: 0.097\n",
            "Epoch: 50, Iteration:  5000, Loss: 2.674\n",
            "Epoch: 50, Iteration:  5500, Loss: 0.857\n",
            "Epoch: 50, Iteration:  6000, Loss: 0.119\n",
            "Epoch: 50, Iteration:  6500, Loss: 0.671\n",
            "Epoch: 50, Iteration:  7000, Loss: 0.142\n",
            "Epoch: 50, Iteration:  7500, Loss: 0.098\n",
            "Epoch: 50, Iteration:  8000, Loss: 2.361\n",
            "Epoch: 50, Iteration:  8500, Loss: 2.100\n",
            "Epoch: 50, Iteration:  9000, Loss: 0.098\n",
            "Epoch: 50, Iteration:  9500, Loss: 0.136\n",
            "Epoch: 50, Iteration: 10000, Loss: 0.114\n",
            "Epoch: 50, Iteration: 10500, Loss: 0.122\n",
            "Epoch: 50, Iteration: 11000, Loss: 0.135\n",
            "Epoch: 50, Iteration: 11500, Loss: 0.144\n",
            "Epoch: 50, Iteration: 12000, Loss: 1.888\n",
            "Epoch: 50, Iteration: 12500, Loss: 2.152\n",
            "Epoch: 50, Iteration: 13000, Loss: 0.845\n",
            "Epoch: 50, Iteration: 13500, Loss: 1.090\n",
            "Epoch: 50, Iteration: 14000, Loss: 2.951\n",
            "Epoch: 50, Iteration: 14500, Loss: 1.481\n",
            "Epoch: 50, Iteration: 15000, Loss: 0.061\n",
            "Epoch: 50, Iteration: 15500, Loss: 1.900\n",
            "Epoch: 50, Iteration: 16000, Loss: 0.068\n",
            "Epoch: 50, Iteration: 16500, Loss: 0.968\n",
            "Epoch: 50, Iteration: 17000, Loss: 0.169\n",
            "Epoch: 50, Iteration: 17500, Loss: 0.194\n",
            "Epoch: 50, Iteration: 18000, Loss: 0.127\n",
            "Epoch: 50, Iteration: 18500, Loss: 1.461\n",
            "Epoch: 50, Iteration: 19000, Loss: 2.853\n",
            "Epoch: 50, Iteration: 19500, Loss: 0.108\n",
            "Epoch: 50, Iteration: 20000, Loss: 1.116\n",
            "Epoch: 50, Iteration: 20500, Loss: 0.081\n",
            "Epoch: 50, Iteration: 21000, Loss: 0.097\n",
            "Epoch: 50, Iteration: 21500, Loss: 2.196\n",
            "Epoch: 50, Iteration: 22000, Loss: 0.108\n",
            "Epoch: 50, Iteration: 22500, Loss: 0.126\n",
            "Epoch: 50, Iteration: 23000, Loss: 0.133\n",
            "Epoch: 50, Iteration: 23500, Loss: 0.810\n",
            "Epoch: 50, Iteration: 24000, Loss: 0.157\n",
            "Epoch: 50, Iteration: 24500, Loss: 2.301\n",
            "Epoch: 50, Iteration: 25000, Loss: 0.591\n",
            "Epoch: 50, Iteration: 25500, Loss: 0.533\n",
            "Epoch: 50, Iteration: 26000, Loss: 0.105\n",
            "Epoch: 50, Iteration: 26500, Loss: 1.039\n",
            "Epoch: 50, Iteration: 27000, Loss: 0.304\n",
            "Epoch: 50, Iteration: 27500, Loss: 0.336\n",
            "Epoch: 50, Iteration: 28000, Loss: 0.600\n",
            "Epoch: 50, Iteration: 28500, Loss: 0.574\n",
            "Epoch: 50, Iteration: 29000, Loss: 0.120\n",
            "Epoch: 50, Iteration: 29500, Loss: 0.456\n",
            "Epoch: 50, Iteration: 30000, Loss: 0.825\n",
            "Epoch: 50, Iteration: 30500, Loss: 0.838\n",
            "Epoch: 50, Iteration: 31000, Loss: 0.177\n",
            "Epoch: 50, Iteration: 31500, Loss: 0.121\n",
            "Epoch: 50, Iteration: 32000, Loss: 0.611\n",
            "Epoch: 50, Iteration: 32500, Loss: 2.390\n",
            "Epoch: 50, Iteration: 33000, Loss: 0.355\n",
            "Epoch: 50, Iteration: 33500, Loss: 1.201\n",
            "Epoch: 50, Iteration: 34000, Loss: 0.668\n",
            "Epoch: 50, Iteration: 34500, Loss: 0.091\n",
            "Epoch: 50, Iteration: 35000, Loss: 1.943\n",
            "Epoch: 50, Iteration: 35500, Loss: 0.137\n",
            "Epoch: 50, Iteration: 36000, Loss: 0.125\n",
            "Epoch: 50, Iteration: 36500, Loss: 0.583\n",
            "Epoch: 50, Iteration: 37000, Loss: 0.541\n",
            "Epoch: 50, Iteration: 37500, Loss: 0.245\n",
            "Epoch: 50, Iteration: 38000, Loss: 0.419\n",
            "Epoch: 50, Iteration: 38500, Loss: 1.548\n",
            "Epoch: 50, Iteration: 39000, Loss: 0.202\n",
            "Epoch: 50, Iteration: 39500, Loss: 0.108\n",
            "Epoch: 50, Iteration: 40000, Loss: 0.964\n",
            "Epoch: 50, Iteration: 40500, Loss: 1.441\n",
            "Epoch: 50, Iteration: 41000, Loss: 0.195\n",
            "Epoch: 50, Iteration: 41500, Loss: 0.072\n",
            "Epoch: 50, Iteration: 42000, Loss: 1.385\n",
            "Epoch: 50, Iteration: 42500, Loss: 1.772\n",
            "Epoch: 50, Iteration: 43000, Loss: 1.257\n",
            "Epoch: 50, Iteration: 43500, Loss: 1.474\n",
            "Epoch: 50, Iteration: 44000, Loss: 0.084\n",
            "Epoch: 50, Iteration: 44500, Loss: 0.100\n",
            "Epoch: 50, Iteration: 45000, Loss: 0.083\n",
            "Epoch: 50, Iteration: 45500, Loss: 0.859\n",
            "Epoch: 50, Iteration: 46000, Loss: 0.747\n",
            "Epoch: 50, Iteration: 46500, Loss: 0.058\n",
            "Epoch: 50, Iteration: 47000, Loss: 1.135\n",
            "Epoch: 50, Iteration: 47500, Loss: 0.097\n",
            "Epoch: 50, Iteration: 48000, Loss: 0.088\n",
            "Epoch: 50, Iteration: 48500, Loss: 0.065\n",
            "Epoch: 50, Iteration: 49000, Loss: 0.068\n",
            "Epoch: 50, Iteration: 49500, Loss: 0.117\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.40 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.03 %\n",
            "w(T) = 0.998\n",
            "Epoch: 51, Iteration:     0, Loss: 0.414\n",
            "Epoch: 51, Iteration:   500, Loss: 2.390\n",
            "Epoch: 51, Iteration:  1000, Loss: 2.206\n",
            "Epoch: 51, Iteration:  1500, Loss: 0.903\n",
            "Epoch: 51, Iteration:  2000, Loss: 0.932\n",
            "Epoch: 51, Iteration:  2500, Loss: 0.290\n",
            "Epoch: 51, Iteration:  3000, Loss: 0.062\n",
            "Epoch: 51, Iteration:  3500, Loss: 0.079\n",
            "Epoch: 51, Iteration:  4000, Loss: 1.839\n",
            "Epoch: 51, Iteration:  4500, Loss: 1.295\n",
            "Epoch: 51, Iteration:  5000, Loss: 0.053\n",
            "Epoch: 51, Iteration:  5500, Loss: 0.073\n",
            "Epoch: 51, Iteration:  6000, Loss: 0.463\n",
            "Epoch: 51, Iteration:  6500, Loss: 1.307\n",
            "Epoch: 51, Iteration:  7000, Loss: 0.071\n",
            "Epoch: 51, Iteration:  7500, Loss: 0.412\n",
            "Epoch: 51, Iteration:  8000, Loss: 2.520\n",
            "Epoch: 51, Iteration:  8500, Loss: 0.809\n",
            "Epoch: 51, Iteration:  9000, Loss: 0.386\n",
            "Epoch: 51, Iteration:  9500, Loss: 0.123\n",
            "Epoch: 51, Iteration: 10000, Loss: 2.720\n",
            "Epoch: 51, Iteration: 10500, Loss: 1.943\n",
            "Epoch: 51, Iteration: 11000, Loss: 0.958\n",
            "Epoch: 51, Iteration: 11500, Loss: 0.104\n",
            "Epoch: 51, Iteration: 12000, Loss: 1.000\n",
            "Epoch: 51, Iteration: 12500, Loss: 2.263\n",
            "Epoch: 51, Iteration: 13000, Loss: 1.589\n",
            "Epoch: 51, Iteration: 13500, Loss: 0.175\n",
            "Epoch: 51, Iteration: 14000, Loss: 3.696\n",
            "Epoch: 51, Iteration: 14500, Loss: 0.091\n",
            "Epoch: 51, Iteration: 15000, Loss: 0.163\n",
            "Epoch: 51, Iteration: 15500, Loss: 0.192\n",
            "Epoch: 51, Iteration: 16000, Loss: 0.837\n",
            "Epoch: 51, Iteration: 16500, Loss: 0.331\n",
            "Epoch: 51, Iteration: 17000, Loss: 1.416\n",
            "Epoch: 51, Iteration: 17500, Loss: 2.775\n",
            "Epoch: 51, Iteration: 18000, Loss: 0.094\n",
            "Epoch: 51, Iteration: 18500, Loss: 2.882\n",
            "Epoch: 51, Iteration: 19000, Loss: 0.492\n",
            "Epoch: 51, Iteration: 19500, Loss: 0.432\n",
            "Epoch: 51, Iteration: 20000, Loss: 4.519\n",
            "Epoch: 51, Iteration: 20500, Loss: 1.198\n",
            "Epoch: 51, Iteration: 21000, Loss: 0.091\n",
            "Epoch: 51, Iteration: 21500, Loss: 1.343\n",
            "Epoch: 51, Iteration: 22000, Loss: 1.034\n",
            "Epoch: 51, Iteration: 22500, Loss: 2.981\n",
            "Epoch: 51, Iteration: 23000, Loss: 1.311\n",
            "Epoch: 51, Iteration: 23500, Loss: 0.090\n",
            "Epoch: 51, Iteration: 24000, Loss: 0.880\n",
            "Epoch: 51, Iteration: 24500, Loss: 0.503\n",
            "Epoch: 51, Iteration: 25000, Loss: 0.271\n",
            "Epoch: 51, Iteration: 25500, Loss: 2.124\n",
            "Epoch: 51, Iteration: 26000, Loss: 0.093\n",
            "Epoch: 51, Iteration: 26500, Loss: 0.994\n",
            "Epoch: 51, Iteration: 27000, Loss: 1.525\n",
            "Epoch: 51, Iteration: 27500, Loss: 1.157\n",
            "Epoch: 51, Iteration: 28000, Loss: 0.083\n",
            "Epoch: 51, Iteration: 28500, Loss: 0.858\n",
            "Epoch: 51, Iteration: 29000, Loss: 0.325\n",
            "Epoch: 51, Iteration: 29500, Loss: 0.103\n",
            "Epoch: 51, Iteration: 30000, Loss: 0.091\n",
            "Epoch: 51, Iteration: 30500, Loss: 0.772\n",
            "Epoch: 51, Iteration: 31000, Loss: 1.367\n",
            "Epoch: 51, Iteration: 31500, Loss: 0.071\n",
            "Epoch: 51, Iteration: 32000, Loss: 0.821\n",
            "Epoch: 51, Iteration: 32500, Loss: 0.100\n",
            "Epoch: 51, Iteration: 33000, Loss: 0.117\n",
            "Epoch: 51, Iteration: 33500, Loss: 2.631\n",
            "Epoch: 51, Iteration: 34000, Loss: 1.998\n",
            "Epoch: 51, Iteration: 34500, Loss: 1.697\n",
            "Epoch: 51, Iteration: 35000, Loss: 0.890\n",
            "Epoch: 51, Iteration: 35500, Loss: 0.085\n",
            "Epoch: 51, Iteration: 36000, Loss: 0.137\n",
            "Epoch: 51, Iteration: 36500, Loss: 0.100\n",
            "Epoch: 51, Iteration: 37000, Loss: 1.600\n",
            "Epoch: 51, Iteration: 37500, Loss: 1.555\n",
            "Epoch: 51, Iteration: 38000, Loss: 1.739\n",
            "Epoch: 51, Iteration: 38500, Loss: 0.338\n",
            "Epoch: 51, Iteration: 39000, Loss: 0.155\n",
            "Epoch: 51, Iteration: 39500, Loss: 1.902\n",
            "Epoch: 51, Iteration: 40000, Loss: 0.716\n",
            "Epoch: 51, Iteration: 40500, Loss: 0.142\n",
            "Epoch: 51, Iteration: 41000, Loss: 0.237\n",
            "Epoch: 51, Iteration: 41500, Loss: 0.163\n",
            "Epoch: 51, Iteration: 42000, Loss: 0.371\n",
            "Epoch: 51, Iteration: 42500, Loss: 0.102\n",
            "Epoch: 51, Iteration: 43000, Loss: 1.027\n",
            "Epoch: 51, Iteration: 43500, Loss: 1.178\n",
            "Epoch: 51, Iteration: 44000, Loss: 0.727\n",
            "Epoch: 51, Iteration: 44500, Loss: 1.353\n",
            "Epoch: 51, Iteration: 45000, Loss: 1.813\n",
            "Epoch: 51, Iteration: 45500, Loss: 0.134\n",
            "Epoch: 51, Iteration: 46000, Loss: 0.142\n",
            "Epoch: 51, Iteration: 46500, Loss: 0.615\n",
            "Epoch: 51, Iteration: 47000, Loss: 0.094\n",
            "Epoch: 51, Iteration: 47500, Loss: 2.667\n",
            "Epoch: 51, Iteration: 48000, Loss: 0.724\n",
            "Epoch: 51, Iteration: 48500, Loss: 2.661\n",
            "Epoch: 51, Iteration: 49000, Loss: 0.082\n",
            "Epoch: 51, Iteration: 49500, Loss: 0.099\n",
            "Accuracy of the neural network on CIFAR_10 is: 36.87 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 35.93 %\n",
            "w(T) = 1.000\n",
            "Epoch: 52, Iteration:     0, Loss: 0.089\n",
            "Epoch: 52, Iteration:   500, Loss: 0.117\n",
            "Epoch: 52, Iteration:  1000, Loss: 2.704\n",
            "Epoch: 52, Iteration:  1500, Loss: 0.117\n",
            "Epoch: 52, Iteration:  2000, Loss: 0.116\n",
            "Epoch: 52, Iteration:  2500, Loss: 0.781\n",
            "Epoch: 52, Iteration:  3000, Loss: 0.101\n",
            "Epoch: 52, Iteration:  3500, Loss: 2.122\n",
            "Epoch: 52, Iteration:  4000, Loss: 1.124\n",
            "Epoch: 52, Iteration:  4500, Loss: 0.997\n",
            "Epoch: 52, Iteration:  5000, Loss: 1.083\n",
            "Epoch: 52, Iteration:  5500, Loss: 0.130\n",
            "Epoch: 52, Iteration:  6000, Loss: 1.246\n",
            "Epoch: 52, Iteration:  6500, Loss: 2.536\n",
            "Epoch: 52, Iteration:  7000, Loss: 0.126\n",
            "Epoch: 52, Iteration:  7500, Loss: 2.010\n",
            "Epoch: 52, Iteration:  8000, Loss: 0.124\n",
            "Epoch: 52, Iteration:  8500, Loss: 0.430\n",
            "Epoch: 52, Iteration:  9000, Loss: 0.122\n",
            "Epoch: 52, Iteration:  9500, Loss: 0.091\n",
            "Epoch: 52, Iteration: 10000, Loss: 0.096\n",
            "Epoch: 52, Iteration: 10500, Loss: 0.274\n",
            "Epoch: 52, Iteration: 11000, Loss: 0.614\n",
            "Epoch: 52, Iteration: 11500, Loss: 0.706\n",
            "Epoch: 52, Iteration: 12000, Loss: 1.502\n",
            "Epoch: 52, Iteration: 12500, Loss: 0.113\n",
            "Epoch: 52, Iteration: 13000, Loss: 4.151\n",
            "Epoch: 52, Iteration: 13500, Loss: 0.108\n",
            "Epoch: 52, Iteration: 14000, Loss: 0.083\n",
            "Epoch: 52, Iteration: 14500, Loss: 1.006\n",
            "Epoch: 52, Iteration: 15000, Loss: 0.881\n",
            "Epoch: 52, Iteration: 15500, Loss: 0.130\n",
            "Epoch: 52, Iteration: 16000, Loss: 0.070\n",
            "Epoch: 52, Iteration: 16500, Loss: 0.792\n",
            "Epoch: 52, Iteration: 17000, Loss: 0.082\n",
            "Epoch: 52, Iteration: 17500, Loss: 0.866\n",
            "Epoch: 52, Iteration: 18000, Loss: 0.077\n",
            "Epoch: 52, Iteration: 18500, Loss: 0.088\n",
            "Epoch: 52, Iteration: 19000, Loss: 1.130\n",
            "Epoch: 52, Iteration: 19500, Loss: 0.609\n",
            "Epoch: 52, Iteration: 20000, Loss: 0.147\n",
            "Epoch: 52, Iteration: 20500, Loss: 0.303\n",
            "Epoch: 52, Iteration: 21000, Loss: 0.246\n",
            "Epoch: 52, Iteration: 21500, Loss: 4.254\n",
            "Epoch: 52, Iteration: 22000, Loss: 0.168\n",
            "Epoch: 52, Iteration: 22500, Loss: 2.350\n",
            "Epoch: 52, Iteration: 23000, Loss: 0.803\n",
            "Epoch: 52, Iteration: 23500, Loss: 0.106\n",
            "Epoch: 52, Iteration: 24000, Loss: 1.868\n",
            "Epoch: 52, Iteration: 24500, Loss: 0.572\n",
            "Epoch: 52, Iteration: 25000, Loss: 0.492\n",
            "Epoch: 52, Iteration: 25500, Loss: 0.119\n",
            "Epoch: 52, Iteration: 26000, Loss: 0.093\n",
            "Epoch: 52, Iteration: 26500, Loss: 1.439\n",
            "Epoch: 52, Iteration: 27000, Loss: 0.147\n",
            "Epoch: 52, Iteration: 27500, Loss: 2.637\n",
            "Epoch: 52, Iteration: 28000, Loss: 1.623\n",
            "Epoch: 52, Iteration: 28500, Loss: 0.128\n",
            "Epoch: 52, Iteration: 29000, Loss: 1.998\n",
            "Epoch: 52, Iteration: 29500, Loss: 1.786\n",
            "Epoch: 52, Iteration: 30000, Loss: 0.609\n",
            "Epoch: 52, Iteration: 30500, Loss: 0.128\n",
            "Epoch: 52, Iteration: 31000, Loss: 0.112\n",
            "Epoch: 52, Iteration: 31500, Loss: 1.174\n",
            "Epoch: 52, Iteration: 32000, Loss: 0.182\n",
            "Epoch: 52, Iteration: 32500, Loss: 0.221\n",
            "Epoch: 52, Iteration: 33000, Loss: 0.091\n",
            "Epoch: 52, Iteration: 33500, Loss: 0.380\n",
            "Epoch: 52, Iteration: 34000, Loss: 0.426\n",
            "Epoch: 52, Iteration: 34500, Loss: 1.073\n",
            "Epoch: 52, Iteration: 35000, Loss: 0.086\n",
            "Epoch: 52, Iteration: 35500, Loss: 0.990\n",
            "Epoch: 52, Iteration: 36000, Loss: 0.281\n",
            "Epoch: 52, Iteration: 36500, Loss: 0.103\n",
            "Epoch: 52, Iteration: 37000, Loss: 0.105\n",
            "Epoch: 52, Iteration: 37500, Loss: 0.071\n",
            "Epoch: 52, Iteration: 38000, Loss: 2.221\n",
            "Epoch: 52, Iteration: 38500, Loss: 1.772\n",
            "Epoch: 52, Iteration: 39000, Loss: 0.088\n",
            "Epoch: 52, Iteration: 39500, Loss: 0.473\n",
            "Epoch: 52, Iteration: 40000, Loss: 0.387\n",
            "Epoch: 52, Iteration: 40500, Loss: 0.106\n",
            "Epoch: 52, Iteration: 41000, Loss: 0.118\n",
            "Epoch: 52, Iteration: 41500, Loss: 0.095\n",
            "Epoch: 52, Iteration: 42000, Loss: 0.447\n",
            "Epoch: 52, Iteration: 42500, Loss: 0.075\n",
            "Epoch: 52, Iteration: 43000, Loss: 0.293\n",
            "Epoch: 52, Iteration: 43500, Loss: 0.090\n",
            "Epoch: 52, Iteration: 44000, Loss: 0.964\n",
            "Epoch: 52, Iteration: 44500, Loss: 0.126\n",
            "Epoch: 52, Iteration: 45000, Loss: 0.125\n",
            "Epoch: 52, Iteration: 45500, Loss: 2.097\n",
            "Epoch: 52, Iteration: 46000, Loss: 0.130\n",
            "Epoch: 52, Iteration: 46500, Loss: 0.853\n",
            "Epoch: 52, Iteration: 47000, Loss: 0.312\n",
            "Epoch: 52, Iteration: 47500, Loss: 0.115\n",
            "Epoch: 52, Iteration: 48000, Loss: 0.263\n",
            "Epoch: 52, Iteration: 48500, Loss: 2.322\n",
            "Epoch: 52, Iteration: 49000, Loss: 0.140\n",
            "Epoch: 52, Iteration: 49500, Loss: 0.313\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.24 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.89 %\n",
            "w(T) = 1.000\n",
            "Epoch: 53, Iteration:     0, Loss: 0.111\n",
            "Epoch: 53, Iteration:   500, Loss: 0.112\n",
            "Epoch: 53, Iteration:  1000, Loss: 0.075\n",
            "Epoch: 53, Iteration:  1500, Loss: 1.487\n",
            "Epoch: 53, Iteration:  2000, Loss: 0.078\n",
            "Epoch: 53, Iteration:  2500, Loss: 0.259\n",
            "Epoch: 53, Iteration:  3000, Loss: 0.090\n",
            "Epoch: 53, Iteration:  3500, Loss: 0.087\n",
            "Epoch: 53, Iteration:  4000, Loss: 0.106\n",
            "Epoch: 53, Iteration:  4500, Loss: 0.865\n",
            "Epoch: 53, Iteration:  5000, Loss: 3.501\n",
            "Epoch: 53, Iteration:  5500, Loss: 0.091\n",
            "Epoch: 53, Iteration:  6000, Loss: 0.512\n",
            "Epoch: 53, Iteration:  6500, Loss: 0.431\n",
            "Epoch: 53, Iteration:  7000, Loss: 0.090\n",
            "Epoch: 53, Iteration:  7500, Loss: 0.138\n",
            "Epoch: 53, Iteration:  8000, Loss: 0.709\n",
            "Epoch: 53, Iteration:  8500, Loss: 0.080\n",
            "Epoch: 53, Iteration:  9000, Loss: 2.578\n",
            "Epoch: 53, Iteration:  9500, Loss: 1.777\n",
            "Epoch: 53, Iteration: 10000, Loss: 0.131\n",
            "Epoch: 53, Iteration: 10500, Loss: 0.108\n",
            "Epoch: 53, Iteration: 11000, Loss: 0.126\n",
            "Epoch: 53, Iteration: 11500, Loss: 0.081\n",
            "Epoch: 53, Iteration: 12000, Loss: 0.114\n",
            "Epoch: 53, Iteration: 12500, Loss: 0.425\n",
            "Epoch: 53, Iteration: 13000, Loss: 0.996\n",
            "Epoch: 53, Iteration: 13500, Loss: 0.130\n",
            "Epoch: 53, Iteration: 14000, Loss: 0.110\n",
            "Epoch: 53, Iteration: 14500, Loss: 0.110\n",
            "Epoch: 53, Iteration: 15000, Loss: 1.684\n",
            "Epoch: 53, Iteration: 15500, Loss: 0.084\n",
            "Epoch: 53, Iteration: 16000, Loss: 1.204\n",
            "Epoch: 53, Iteration: 16500, Loss: 0.161\n",
            "Epoch: 53, Iteration: 17000, Loss: 2.394\n",
            "Epoch: 53, Iteration: 17500, Loss: 0.087\n",
            "Epoch: 53, Iteration: 18000, Loss: 0.119\n",
            "Epoch: 53, Iteration: 18500, Loss: 1.466\n",
            "Epoch: 53, Iteration: 19000, Loss: 1.910\n",
            "Epoch: 53, Iteration: 19500, Loss: 0.141\n",
            "Epoch: 53, Iteration: 20000, Loss: 0.113\n",
            "Epoch: 53, Iteration: 20500, Loss: 0.146\n",
            "Epoch: 53, Iteration: 21000, Loss: 0.169\n",
            "Epoch: 53, Iteration: 21500, Loss: 1.494\n",
            "Epoch: 53, Iteration: 22000, Loss: 0.353\n",
            "Epoch: 53, Iteration: 22500, Loss: 1.429\n",
            "Epoch: 53, Iteration: 23000, Loss: 0.137\n",
            "Epoch: 53, Iteration: 23500, Loss: 0.100\n",
            "Epoch: 53, Iteration: 24000, Loss: 0.106\n",
            "Epoch: 53, Iteration: 24500, Loss: 0.132\n",
            "Epoch: 53, Iteration: 25000, Loss: 2.318\n",
            "Epoch: 53, Iteration: 25500, Loss: 0.109\n",
            "Epoch: 53, Iteration: 26000, Loss: 0.432\n",
            "Epoch: 53, Iteration: 26500, Loss: 3.061\n",
            "Epoch: 53, Iteration: 27000, Loss: 0.099\n",
            "Epoch: 53, Iteration: 27500, Loss: 0.400\n",
            "Epoch: 53, Iteration: 28000, Loss: 0.113\n",
            "Epoch: 53, Iteration: 28500, Loss: 2.232\n",
            "Epoch: 53, Iteration: 29000, Loss: 2.830\n",
            "Epoch: 53, Iteration: 29500, Loss: 0.664\n",
            "Epoch: 53, Iteration: 30000, Loss: 0.105\n",
            "Epoch: 53, Iteration: 30500, Loss: 0.090\n",
            "Epoch: 53, Iteration: 31000, Loss: 0.100\n",
            "Epoch: 53, Iteration: 31500, Loss: 0.122\n",
            "Epoch: 53, Iteration: 32000, Loss: 2.674\n",
            "Epoch: 53, Iteration: 32500, Loss: 0.085\n",
            "Epoch: 53, Iteration: 33000, Loss: 0.472\n",
            "Epoch: 53, Iteration: 33500, Loss: 1.828\n",
            "Epoch: 53, Iteration: 34000, Loss: 0.132\n",
            "Epoch: 53, Iteration: 34500, Loss: 0.104\n",
            "Epoch: 53, Iteration: 35000, Loss: 0.114\n",
            "Epoch: 53, Iteration: 35500, Loss: 0.108\n",
            "Epoch: 53, Iteration: 36000, Loss: 0.311\n",
            "Epoch: 53, Iteration: 36500, Loss: 1.524\n",
            "Epoch: 53, Iteration: 37000, Loss: 1.206\n",
            "Epoch: 53, Iteration: 37500, Loss: 0.867\n",
            "Epoch: 53, Iteration: 38000, Loss: 0.721\n",
            "Epoch: 53, Iteration: 38500, Loss: 0.104\n",
            "Epoch: 53, Iteration: 39000, Loss: 0.523\n",
            "Epoch: 53, Iteration: 39500, Loss: 1.238\n",
            "Epoch: 53, Iteration: 40000, Loss: 0.922\n",
            "Epoch: 53, Iteration: 40500, Loss: 0.111\n",
            "Epoch: 53, Iteration: 41000, Loss: 0.105\n",
            "Epoch: 53, Iteration: 41500, Loss: 3.242\n",
            "Epoch: 53, Iteration: 42000, Loss: 0.099\n",
            "Epoch: 53, Iteration: 42500, Loss: 0.101\n",
            "Epoch: 53, Iteration: 43000, Loss: 0.062\n",
            "Epoch: 53, Iteration: 43500, Loss: 1.298\n",
            "Epoch: 53, Iteration: 44000, Loss: 0.103\n",
            "Epoch: 53, Iteration: 44500, Loss: 0.090\n",
            "Epoch: 53, Iteration: 45000, Loss: 0.151\n",
            "Epoch: 53, Iteration: 45500, Loss: 0.199\n",
            "Epoch: 53, Iteration: 46000, Loss: 0.121\n",
            "Epoch: 53, Iteration: 46500, Loss: 0.511\n",
            "Epoch: 53, Iteration: 47000, Loss: 0.840\n",
            "Epoch: 53, Iteration: 47500, Loss: 1.604\n",
            "Epoch: 53, Iteration: 48000, Loss: 2.432\n",
            "Epoch: 53, Iteration: 48500, Loss: 0.097\n",
            "Epoch: 53, Iteration: 49000, Loss: 3.166\n",
            "Epoch: 53, Iteration: 49500, Loss: 0.091\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.73 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.19 %\n",
            "w(T) = 1.000\n",
            "Epoch: 54, Iteration:     0, Loss: 0.357\n",
            "Epoch: 54, Iteration:   500, Loss: 1.697\n",
            "Epoch: 54, Iteration:  1000, Loss: 0.425\n",
            "Epoch: 54, Iteration:  1500, Loss: 0.564\n",
            "Epoch: 54, Iteration:  2000, Loss: 0.642\n",
            "Epoch: 54, Iteration:  2500, Loss: 0.109\n",
            "Epoch: 54, Iteration:  3000, Loss: 0.136\n",
            "Epoch: 54, Iteration:  3500, Loss: 1.325\n",
            "Epoch: 54, Iteration:  4000, Loss: 0.279\n",
            "Epoch: 54, Iteration:  4500, Loss: 0.524\n",
            "Epoch: 54, Iteration:  5000, Loss: 0.083\n",
            "Epoch: 54, Iteration:  5500, Loss: 0.102\n",
            "Epoch: 54, Iteration:  6000, Loss: 0.214\n",
            "Epoch: 54, Iteration:  6500, Loss: 0.127\n",
            "Epoch: 54, Iteration:  7000, Loss: 0.123\n",
            "Epoch: 54, Iteration:  7500, Loss: 0.137\n",
            "Epoch: 54, Iteration:  8000, Loss: 0.115\n",
            "Epoch: 54, Iteration:  8500, Loss: 0.136\n",
            "Epoch: 54, Iteration:  9000, Loss: 0.552\n",
            "Epoch: 54, Iteration:  9500, Loss: 0.099\n",
            "Epoch: 54, Iteration: 10000, Loss: 0.655\n",
            "Epoch: 54, Iteration: 10500, Loss: 0.831\n",
            "Epoch: 54, Iteration: 11000, Loss: 0.157\n",
            "Epoch: 54, Iteration: 11500, Loss: 0.091\n",
            "Epoch: 54, Iteration: 12000, Loss: 0.095\n",
            "Epoch: 54, Iteration: 12500, Loss: 0.107\n",
            "Epoch: 54, Iteration: 13000, Loss: 0.101\n",
            "Epoch: 54, Iteration: 13500, Loss: 0.246\n",
            "Epoch: 54, Iteration: 14000, Loss: 0.160\n",
            "Epoch: 54, Iteration: 14500, Loss: 0.268\n",
            "Epoch: 54, Iteration: 15000, Loss: 0.077\n",
            "Epoch: 54, Iteration: 15500, Loss: 0.595\n",
            "Epoch: 54, Iteration: 16000, Loss: 1.011\n",
            "Epoch: 54, Iteration: 16500, Loss: 0.087\n",
            "Epoch: 54, Iteration: 17000, Loss: 0.240\n",
            "Epoch: 54, Iteration: 17500, Loss: 0.109\n",
            "Epoch: 54, Iteration: 18000, Loss: 0.369\n",
            "Epoch: 54, Iteration: 18500, Loss: 0.120\n",
            "Epoch: 54, Iteration: 19000, Loss: 0.752\n",
            "Epoch: 54, Iteration: 19500, Loss: 0.127\n",
            "Epoch: 54, Iteration: 20000, Loss: 1.112\n",
            "Epoch: 54, Iteration: 20500, Loss: 0.146\n",
            "Epoch: 54, Iteration: 21000, Loss: 0.147\n",
            "Epoch: 54, Iteration: 21500, Loss: 0.727\n",
            "Epoch: 54, Iteration: 22000, Loss: 0.547\n",
            "Epoch: 54, Iteration: 22500, Loss: 0.561\n",
            "Epoch: 54, Iteration: 23000, Loss: 3.054\n",
            "Epoch: 54, Iteration: 23500, Loss: 0.083\n",
            "Epoch: 54, Iteration: 24000, Loss: 1.133\n",
            "Epoch: 54, Iteration: 24500, Loss: 1.825\n",
            "Epoch: 54, Iteration: 25000, Loss: 0.923\n",
            "Epoch: 54, Iteration: 25500, Loss: 0.167\n",
            "Epoch: 54, Iteration: 26000, Loss: 0.457\n",
            "Epoch: 54, Iteration: 26500, Loss: 1.998\n",
            "Epoch: 54, Iteration: 27000, Loss: 4.511\n",
            "Epoch: 54, Iteration: 27500, Loss: 0.132\n",
            "Epoch: 54, Iteration: 28000, Loss: 1.159\n",
            "Epoch: 54, Iteration: 28500, Loss: 1.296\n",
            "Epoch: 54, Iteration: 29000, Loss: 0.198\n",
            "Epoch: 54, Iteration: 29500, Loss: 0.075\n",
            "Epoch: 54, Iteration: 30000, Loss: 0.156\n",
            "Epoch: 54, Iteration: 30500, Loss: 0.137\n",
            "Epoch: 54, Iteration: 31000, Loss: 0.245\n",
            "Epoch: 54, Iteration: 31500, Loss: 1.298\n",
            "Epoch: 54, Iteration: 32000, Loss: 0.207\n",
            "Epoch: 54, Iteration: 32500, Loss: 0.576\n",
            "Epoch: 54, Iteration: 33000, Loss: 0.125\n",
            "Epoch: 54, Iteration: 33500, Loss: 0.859\n",
            "Epoch: 54, Iteration: 34000, Loss: 0.143\n",
            "Epoch: 54, Iteration: 34500, Loss: 1.188\n",
            "Epoch: 54, Iteration: 35000, Loss: 0.166\n",
            "Epoch: 54, Iteration: 35500, Loss: 1.248\n",
            "Epoch: 54, Iteration: 36000, Loss: 0.109\n",
            "Epoch: 54, Iteration: 36500, Loss: 0.435\n",
            "Epoch: 54, Iteration: 37000, Loss: 0.244\n",
            "Epoch: 54, Iteration: 37500, Loss: 0.106\n",
            "Epoch: 54, Iteration: 38000, Loss: 0.113\n",
            "Epoch: 54, Iteration: 38500, Loss: 0.171\n",
            "Epoch: 54, Iteration: 39000, Loss: 0.098\n",
            "Epoch: 54, Iteration: 39500, Loss: 0.310\n",
            "Epoch: 54, Iteration: 40000, Loss: 0.421\n",
            "Epoch: 54, Iteration: 40500, Loss: 0.109\n",
            "Epoch: 54, Iteration: 41000, Loss: 0.115\n",
            "Epoch: 54, Iteration: 41500, Loss: 0.171\n",
            "Epoch: 54, Iteration: 42000, Loss: 0.141\n",
            "Epoch: 54, Iteration: 42500, Loss: 0.910\n",
            "Epoch: 54, Iteration: 43000, Loss: 1.562\n",
            "Epoch: 54, Iteration: 43500, Loss: 0.088\n",
            "Epoch: 54, Iteration: 44000, Loss: 2.448\n",
            "Epoch: 54, Iteration: 44500, Loss: 2.272\n",
            "Epoch: 54, Iteration: 45000, Loss: 0.142\n",
            "Epoch: 54, Iteration: 45500, Loss: 0.856\n",
            "Epoch: 54, Iteration: 46000, Loss: 0.081\n",
            "Epoch: 54, Iteration: 46500, Loss: 2.187\n",
            "Epoch: 54, Iteration: 47000, Loss: 2.298\n",
            "Epoch: 54, Iteration: 47500, Loss: 0.397\n",
            "Epoch: 54, Iteration: 48000, Loss: 1.002\n",
            "Epoch: 54, Iteration: 48500, Loss: 0.912\n",
            "Epoch: 54, Iteration: 49000, Loss: 1.555\n",
            "Epoch: 54, Iteration: 49500, Loss: 0.131\n",
            "Accuracy of the neural network on CIFAR_10 is: 38.42 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 37.85 %\n",
            "w(T) = 1.000\n",
            "Epoch: 55, Iteration:     0, Loss: 1.642\n",
            "Epoch: 55, Iteration:   500, Loss: 0.796\n",
            "Epoch: 55, Iteration:  1000, Loss: 1.357\n",
            "Epoch: 55, Iteration:  1500, Loss: 0.384\n",
            "Epoch: 55, Iteration:  2000, Loss: 0.092\n",
            "Epoch: 55, Iteration:  2500, Loss: 0.481\n",
            "Epoch: 55, Iteration:  3000, Loss: 3.114\n",
            "Epoch: 55, Iteration:  3500, Loss: 2.035\n",
            "Epoch: 55, Iteration:  4000, Loss: 0.808\n",
            "Epoch: 55, Iteration:  4500, Loss: 0.174\n",
            "Epoch: 55, Iteration:  5000, Loss: 1.402\n",
            "Epoch: 55, Iteration:  5500, Loss: 1.577\n",
            "Epoch: 55, Iteration:  6000, Loss: 0.118\n",
            "Epoch: 55, Iteration:  6500, Loss: 0.094\n",
            "Epoch: 55, Iteration:  7000, Loss: 0.465\n",
            "Epoch: 55, Iteration:  7500, Loss: 1.651\n",
            "Epoch: 55, Iteration:  8000, Loss: 0.315\n",
            "Epoch: 55, Iteration:  8500, Loss: 0.082\n",
            "Epoch: 55, Iteration:  9000, Loss: 0.468\n",
            "Epoch: 55, Iteration:  9500, Loss: 0.144\n",
            "Epoch: 55, Iteration: 10000, Loss: 0.124\n",
            "Epoch: 55, Iteration: 10500, Loss: 1.399\n",
            "Epoch: 55, Iteration: 11000, Loss: 0.399\n",
            "Epoch: 55, Iteration: 11500, Loss: 0.879\n",
            "Epoch: 55, Iteration: 12000, Loss: 0.154\n",
            "Epoch: 55, Iteration: 12500, Loss: 0.107\n",
            "Epoch: 55, Iteration: 13000, Loss: 0.420\n",
            "Epoch: 55, Iteration: 13500, Loss: 0.110\n",
            "Epoch: 55, Iteration: 14000, Loss: 0.077\n",
            "Epoch: 55, Iteration: 14500, Loss: 0.790\n",
            "Epoch: 55, Iteration: 15000, Loss: 0.120\n",
            "Epoch: 55, Iteration: 15500, Loss: 0.369\n",
            "Epoch: 55, Iteration: 16000, Loss: 0.094\n",
            "Epoch: 55, Iteration: 16500, Loss: 0.108\n",
            "Epoch: 55, Iteration: 17000, Loss: 0.084\n",
            "Epoch: 55, Iteration: 17500, Loss: 0.172\n",
            "Epoch: 55, Iteration: 18000, Loss: 0.309\n",
            "Epoch: 55, Iteration: 18500, Loss: 0.669\n",
            "Epoch: 55, Iteration: 19000, Loss: 0.896\n",
            "Epoch: 55, Iteration: 19500, Loss: 0.084\n",
            "Epoch: 55, Iteration: 20000, Loss: 0.473\n",
            "Epoch: 55, Iteration: 20500, Loss: 0.470\n",
            "Epoch: 55, Iteration: 21000, Loss: 0.089\n",
            "Epoch: 55, Iteration: 21500, Loss: 0.909\n",
            "Epoch: 55, Iteration: 22000, Loss: 0.139\n",
            "Epoch: 55, Iteration: 22500, Loss: 0.084\n",
            "Epoch: 55, Iteration: 23000, Loss: 0.092\n",
            "Epoch: 55, Iteration: 23500, Loss: 0.124\n",
            "Epoch: 55, Iteration: 24000, Loss: 1.663\n",
            "Epoch: 55, Iteration: 24500, Loss: 0.730\n",
            "Epoch: 55, Iteration: 25000, Loss: 0.178\n",
            "Epoch: 55, Iteration: 25500, Loss: 0.093\n",
            "Epoch: 55, Iteration: 26000, Loss: 1.185\n",
            "Epoch: 55, Iteration: 26500, Loss: 0.174\n",
            "Epoch: 55, Iteration: 27000, Loss: 0.243\n",
            "Epoch: 55, Iteration: 27500, Loss: 0.827\n",
            "Epoch: 55, Iteration: 28000, Loss: 0.117\n",
            "Epoch: 55, Iteration: 28500, Loss: 1.213\n",
            "Epoch: 55, Iteration: 29000, Loss: 1.378\n",
            "Epoch: 55, Iteration: 29500, Loss: 0.120\n",
            "Epoch: 55, Iteration: 30000, Loss: 0.163\n",
            "Epoch: 55, Iteration: 30500, Loss: 0.100\n",
            "Epoch: 55, Iteration: 31000, Loss: 0.141\n",
            "Epoch: 55, Iteration: 31500, Loss: 0.085\n",
            "Epoch: 55, Iteration: 32000, Loss: 2.526\n",
            "Epoch: 55, Iteration: 32500, Loss: 1.196\n",
            "Epoch: 55, Iteration: 33000, Loss: 0.100\n",
            "Epoch: 55, Iteration: 33500, Loss: 0.561\n",
            "Epoch: 55, Iteration: 34000, Loss: 0.102\n",
            "Epoch: 55, Iteration: 34500, Loss: 0.251\n",
            "Epoch: 55, Iteration: 35000, Loss: 2.708\n",
            "Epoch: 55, Iteration: 35500, Loss: 0.154\n",
            "Epoch: 55, Iteration: 36000, Loss: 0.187\n",
            "Epoch: 55, Iteration: 36500, Loss: 1.089\n",
            "Epoch: 55, Iteration: 37000, Loss: 0.147\n",
            "Epoch: 55, Iteration: 37500, Loss: 1.226\n",
            "Epoch: 55, Iteration: 38000, Loss: 0.097\n",
            "Epoch: 55, Iteration: 38500, Loss: 0.473\n",
            "Epoch: 55, Iteration: 39000, Loss: 2.492\n",
            "Epoch: 55, Iteration: 39500, Loss: 0.142\n",
            "Epoch: 55, Iteration: 40000, Loss: 2.648\n",
            "Epoch: 55, Iteration: 40500, Loss: 3.571\n",
            "Epoch: 55, Iteration: 41000, Loss: 0.156\n",
            "Epoch: 55, Iteration: 41500, Loss: 0.132\n",
            "Epoch: 55, Iteration: 42000, Loss: 0.095\n",
            "Epoch: 55, Iteration: 42500, Loss: 0.518\n",
            "Epoch: 55, Iteration: 43000, Loss: 1.457\n",
            "Epoch: 55, Iteration: 43500, Loss: 0.108\n",
            "Epoch: 55, Iteration: 44000, Loss: 1.519\n",
            "Epoch: 55, Iteration: 44500, Loss: 0.288\n",
            "Epoch: 55, Iteration: 45000, Loss: 0.134\n",
            "Epoch: 55, Iteration: 45500, Loss: 0.763\n",
            "Epoch: 55, Iteration: 46000, Loss: 0.120\n",
            "Epoch: 55, Iteration: 46500, Loss: 0.390\n",
            "Epoch: 55, Iteration: 47000, Loss: 1.446\n",
            "Epoch: 55, Iteration: 47500, Loss: 1.299\n",
            "Epoch: 55, Iteration: 48000, Loss: 1.730\n",
            "Epoch: 55, Iteration: 48500, Loss: 1.079\n",
            "Epoch: 55, Iteration: 49000, Loss: 0.107\n",
            "Epoch: 55, Iteration: 49500, Loss: 0.093\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.83 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 39.86 %\n",
            "w(T) = 1.000\n",
            "Epoch: 56, Iteration:     0, Loss: 0.083\n",
            "Epoch: 56, Iteration:   500, Loss: 0.154\n",
            "Epoch: 56, Iteration:  1000, Loss: 0.179\n",
            "Epoch: 56, Iteration:  1500, Loss: 0.405\n",
            "Epoch: 56, Iteration:  2000, Loss: 0.107\n",
            "Epoch: 56, Iteration:  2500, Loss: 0.095\n",
            "Epoch: 56, Iteration:  3000, Loss: 1.713\n",
            "Epoch: 56, Iteration:  3500, Loss: 0.091\n",
            "Epoch: 56, Iteration:  4000, Loss: 0.103\n",
            "Epoch: 56, Iteration:  4500, Loss: 0.238\n",
            "Epoch: 56, Iteration:  5000, Loss: 0.118\n",
            "Epoch: 56, Iteration:  5500, Loss: 0.136\n",
            "Epoch: 56, Iteration:  6000, Loss: 0.075\n",
            "Epoch: 56, Iteration:  6500, Loss: 0.316\n",
            "Epoch: 56, Iteration:  7000, Loss: 0.340\n",
            "Epoch: 56, Iteration:  7500, Loss: 0.130\n",
            "Epoch: 56, Iteration:  8000, Loss: 0.835\n",
            "Epoch: 56, Iteration:  8500, Loss: 0.101\n",
            "Epoch: 56, Iteration:  9000, Loss: 0.161\n",
            "Epoch: 56, Iteration:  9500, Loss: 0.677\n",
            "Epoch: 56, Iteration: 10000, Loss: 0.101\n",
            "Epoch: 56, Iteration: 10500, Loss: 0.118\n",
            "Epoch: 56, Iteration: 11000, Loss: 0.109\n",
            "Epoch: 56, Iteration: 11500, Loss: 0.102\n",
            "Epoch: 56, Iteration: 12000, Loss: 0.599\n",
            "Epoch: 56, Iteration: 12500, Loss: 0.101\n",
            "Epoch: 56, Iteration: 13000, Loss: 0.431\n",
            "Epoch: 56, Iteration: 13500, Loss: 0.143\n",
            "Epoch: 56, Iteration: 14000, Loss: 0.723\n",
            "Epoch: 56, Iteration: 14500, Loss: 0.856\n",
            "Epoch: 56, Iteration: 15000, Loss: 0.162\n",
            "Epoch: 56, Iteration: 15500, Loss: 0.189\n",
            "Epoch: 56, Iteration: 16000, Loss: 0.114\n",
            "Epoch: 56, Iteration: 16500, Loss: 0.152\n",
            "Epoch: 56, Iteration: 17000, Loss: 0.135\n",
            "Epoch: 56, Iteration: 17500, Loss: 0.127\n",
            "Epoch: 56, Iteration: 18000, Loss: 0.530\n",
            "Epoch: 56, Iteration: 18500, Loss: 0.140\n",
            "Epoch: 56, Iteration: 19000, Loss: 2.605\n",
            "Epoch: 56, Iteration: 19500, Loss: 0.293\n",
            "Epoch: 56, Iteration: 20000, Loss: 0.137\n",
            "Epoch: 56, Iteration: 20500, Loss: 0.145\n",
            "Epoch: 56, Iteration: 21000, Loss: 0.482\n",
            "Epoch: 56, Iteration: 21500, Loss: 0.080\n",
            "Epoch: 56, Iteration: 22000, Loss: 0.097\n",
            "Epoch: 56, Iteration: 22500, Loss: 0.782\n",
            "Epoch: 56, Iteration: 23000, Loss: 0.111\n",
            "Epoch: 56, Iteration: 23500, Loss: 1.115\n",
            "Epoch: 56, Iteration: 24000, Loss: 0.117\n",
            "Epoch: 56, Iteration: 24500, Loss: 0.103\n",
            "Epoch: 56, Iteration: 25000, Loss: 0.139\n",
            "Epoch: 56, Iteration: 25500, Loss: 0.091\n",
            "Epoch: 56, Iteration: 26000, Loss: 1.311\n",
            "Epoch: 56, Iteration: 26500, Loss: 0.222\n",
            "Epoch: 56, Iteration: 27000, Loss: 0.103\n",
            "Epoch: 56, Iteration: 27500, Loss: 0.102\n",
            "Epoch: 56, Iteration: 28000, Loss: 0.090\n",
            "Epoch: 56, Iteration: 28500, Loss: 1.759\n",
            "Epoch: 56, Iteration: 29000, Loss: 0.413\n",
            "Epoch: 56, Iteration: 29500, Loss: 0.200\n",
            "Epoch: 56, Iteration: 30000, Loss: 0.115\n",
            "Epoch: 56, Iteration: 30500, Loss: 0.468\n",
            "Epoch: 56, Iteration: 31000, Loss: 0.069\n",
            "Epoch: 56, Iteration: 31500, Loss: 0.140\n",
            "Epoch: 56, Iteration: 32000, Loss: 0.105\n",
            "Epoch: 56, Iteration: 32500, Loss: 0.088\n",
            "Epoch: 56, Iteration: 33000, Loss: 0.076\n",
            "Epoch: 56, Iteration: 33500, Loss: 0.106\n",
            "Epoch: 56, Iteration: 34000, Loss: 0.159\n",
            "Epoch: 56, Iteration: 34500, Loss: 1.572\n",
            "Epoch: 56, Iteration: 35000, Loss: 1.144\n",
            "Epoch: 56, Iteration: 35500, Loss: 0.094\n",
            "Epoch: 56, Iteration: 36000, Loss: 0.127\n",
            "Epoch: 56, Iteration: 36500, Loss: 0.356\n",
            "Epoch: 56, Iteration: 37000, Loss: 0.117\n",
            "Epoch: 56, Iteration: 37500, Loss: 0.098\n",
            "Epoch: 56, Iteration: 38000, Loss: 0.097\n",
            "Epoch: 56, Iteration: 38500, Loss: 0.198\n",
            "Epoch: 56, Iteration: 39000, Loss: 1.226\n",
            "Epoch: 56, Iteration: 39500, Loss: 0.722\n",
            "Epoch: 56, Iteration: 40000, Loss: 2.909\n",
            "Epoch: 56, Iteration: 40500, Loss: 0.090\n",
            "Epoch: 56, Iteration: 41000, Loss: 0.705\n",
            "Epoch: 56, Iteration: 41500, Loss: 0.419\n",
            "Epoch: 56, Iteration: 42000, Loss: 0.118\n",
            "Epoch: 56, Iteration: 42500, Loss: 0.520\n",
            "Epoch: 56, Iteration: 43000, Loss: 0.108\n",
            "Epoch: 56, Iteration: 43500, Loss: 2.580\n",
            "Epoch: 56, Iteration: 44000, Loss: 0.119\n",
            "Epoch: 56, Iteration: 44500, Loss: 0.102\n",
            "Epoch: 56, Iteration: 45000, Loss: 3.115\n",
            "Epoch: 56, Iteration: 45500, Loss: 2.359\n",
            "Epoch: 56, Iteration: 46000, Loss: 0.080\n",
            "Epoch: 56, Iteration: 46500, Loss: 0.208\n",
            "Epoch: 56, Iteration: 47000, Loss: 0.096\n",
            "Epoch: 56, Iteration: 47500, Loss: 0.628\n",
            "Epoch: 56, Iteration: 48000, Loss: 2.027\n",
            "Epoch: 56, Iteration: 48500, Loss: 0.139\n",
            "Epoch: 56, Iteration: 49000, Loss: 0.134\n",
            "Epoch: 56, Iteration: 49500, Loss: 0.156\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.53 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.35 %\n",
            "w(T) = 1.000\n",
            "Epoch: 57, Iteration:     0, Loss: 1.172\n",
            "Epoch: 57, Iteration:   500, Loss: 0.111\n",
            "Epoch: 57, Iteration:  1000, Loss: 0.095\n",
            "Epoch: 57, Iteration:  1500, Loss: 0.366\n",
            "Epoch: 57, Iteration:  2000, Loss: 0.106\n",
            "Epoch: 57, Iteration:  2500, Loss: 0.520\n",
            "Epoch: 57, Iteration:  3000, Loss: 0.953\n",
            "Epoch: 57, Iteration:  3500, Loss: 0.535\n",
            "Epoch: 57, Iteration:  4000, Loss: 0.205\n",
            "Epoch: 57, Iteration:  4500, Loss: 0.445\n",
            "Epoch: 57, Iteration:  5000, Loss: 0.082\n",
            "Epoch: 57, Iteration:  5500, Loss: 1.052\n",
            "Epoch: 57, Iteration:  6000, Loss: 2.184\n",
            "Epoch: 57, Iteration:  6500, Loss: 0.107\n",
            "Epoch: 57, Iteration:  7000, Loss: 0.136\n",
            "Epoch: 57, Iteration:  7500, Loss: 0.105\n",
            "Epoch: 57, Iteration:  8000, Loss: 0.160\n",
            "Epoch: 57, Iteration:  8500, Loss: 0.281\n",
            "Epoch: 57, Iteration:  9000, Loss: 0.142\n",
            "Epoch: 57, Iteration:  9500, Loss: 1.588\n",
            "Epoch: 57, Iteration: 10000, Loss: 0.082\n",
            "Epoch: 57, Iteration: 10500, Loss: 0.110\n",
            "Epoch: 57, Iteration: 11000, Loss: 0.395\n",
            "Epoch: 57, Iteration: 11500, Loss: 0.210\n",
            "Epoch: 57, Iteration: 12000, Loss: 0.101\n",
            "Epoch: 57, Iteration: 12500, Loss: 0.102\n",
            "Epoch: 57, Iteration: 13000, Loss: 1.427\n",
            "Epoch: 57, Iteration: 13500, Loss: 0.111\n",
            "Epoch: 57, Iteration: 14000, Loss: 0.100\n",
            "Epoch: 57, Iteration: 14500, Loss: 0.096\n",
            "Epoch: 57, Iteration: 15000, Loss: 0.850\n",
            "Epoch: 57, Iteration: 15500, Loss: 0.084\n",
            "Epoch: 57, Iteration: 16000, Loss: 0.107\n",
            "Epoch: 57, Iteration: 16500, Loss: 0.376\n",
            "Epoch: 57, Iteration: 17000, Loss: 1.204\n",
            "Epoch: 57, Iteration: 17500, Loss: 0.299\n",
            "Epoch: 57, Iteration: 18000, Loss: 0.143\n",
            "Epoch: 57, Iteration: 18500, Loss: 0.498\n",
            "Epoch: 57, Iteration: 19000, Loss: 0.943\n",
            "Epoch: 57, Iteration: 19500, Loss: 0.088\n",
            "Epoch: 57, Iteration: 20000, Loss: 0.069\n",
            "Epoch: 57, Iteration: 20500, Loss: 0.741\n",
            "Epoch: 57, Iteration: 21000, Loss: 0.140\n",
            "Epoch: 57, Iteration: 21500, Loss: 0.477\n",
            "Epoch: 57, Iteration: 22000, Loss: 0.172\n",
            "Epoch: 57, Iteration: 22500, Loss: 2.081\n",
            "Epoch: 57, Iteration: 23000, Loss: 0.802\n",
            "Epoch: 57, Iteration: 23500, Loss: 0.390\n",
            "Epoch: 57, Iteration: 24000, Loss: 0.852\n",
            "Epoch: 57, Iteration: 24500, Loss: 1.067\n",
            "Epoch: 57, Iteration: 25000, Loss: 0.887\n",
            "Epoch: 57, Iteration: 25500, Loss: 0.621\n",
            "Epoch: 57, Iteration: 26000, Loss: 0.138\n",
            "Epoch: 57, Iteration: 26500, Loss: 0.527\n",
            "Epoch: 57, Iteration: 27000, Loss: 0.116\n",
            "Epoch: 57, Iteration: 27500, Loss: 0.116\n",
            "Epoch: 57, Iteration: 28000, Loss: 0.094\n",
            "Epoch: 57, Iteration: 28500, Loss: 0.129\n",
            "Epoch: 57, Iteration: 29000, Loss: 1.500\n",
            "Epoch: 57, Iteration: 29500, Loss: 0.204\n",
            "Epoch: 57, Iteration: 30000, Loss: 0.100\n",
            "Epoch: 57, Iteration: 30500, Loss: 0.092\n",
            "Epoch: 57, Iteration: 31000, Loss: 0.184\n",
            "Epoch: 57, Iteration: 31500, Loss: 0.934\n",
            "Epoch: 57, Iteration: 32000, Loss: 1.122\n",
            "Epoch: 57, Iteration: 32500, Loss: 0.113\n",
            "Epoch: 57, Iteration: 33000, Loss: 0.123\n",
            "Epoch: 57, Iteration: 33500, Loss: 0.795\n",
            "Epoch: 57, Iteration: 34000, Loss: 0.249\n",
            "Epoch: 57, Iteration: 34500, Loss: 0.118\n",
            "Epoch: 57, Iteration: 35000, Loss: 1.456\n",
            "Epoch: 57, Iteration: 35500, Loss: 0.332\n",
            "Epoch: 57, Iteration: 36000, Loss: 0.223\n",
            "Epoch: 57, Iteration: 36500, Loss: 0.648\n",
            "Epoch: 57, Iteration: 37000, Loss: 0.674\n",
            "Epoch: 57, Iteration: 37500, Loss: 0.119\n",
            "Epoch: 57, Iteration: 38000, Loss: 1.280\n",
            "Epoch: 57, Iteration: 38500, Loss: 0.353\n",
            "Epoch: 57, Iteration: 39000, Loss: 0.090\n",
            "Epoch: 57, Iteration: 39500, Loss: 0.215\n",
            "Epoch: 57, Iteration: 40000, Loss: 0.099\n",
            "Epoch: 57, Iteration: 40500, Loss: 0.115\n",
            "Epoch: 57, Iteration: 41000, Loss: 1.230\n",
            "Epoch: 57, Iteration: 41500, Loss: 2.884\n",
            "Epoch: 57, Iteration: 42000, Loss: 0.114\n",
            "Epoch: 57, Iteration: 42500, Loss: 3.023\n",
            "Epoch: 57, Iteration: 43000, Loss: 1.778\n",
            "Epoch: 57, Iteration: 43500, Loss: 0.404\n",
            "Epoch: 57, Iteration: 44000, Loss: 0.163\n",
            "Epoch: 57, Iteration: 44500, Loss: 1.741\n",
            "Epoch: 57, Iteration: 45000, Loss: 0.162\n",
            "Epoch: 57, Iteration: 45500, Loss: 0.477\n",
            "Epoch: 57, Iteration: 46000, Loss: 0.133\n",
            "Epoch: 57, Iteration: 46500, Loss: 0.343\n",
            "Epoch: 57, Iteration: 47000, Loss: 0.128\n",
            "Epoch: 57, Iteration: 47500, Loss: 0.236\n",
            "Epoch: 57, Iteration: 48000, Loss: 0.111\n",
            "Epoch: 57, Iteration: 48500, Loss: 0.108\n",
            "Epoch: 57, Iteration: 49000, Loss: 0.140\n",
            "Epoch: 57, Iteration: 49500, Loss: 0.115\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.25 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.33 %\n",
            "w(T) = 1.000\n",
            "Epoch: 58, Iteration:     0, Loss: 0.178\n",
            "Epoch: 58, Iteration:   500, Loss: 0.990\n",
            "Epoch: 58, Iteration:  1000, Loss: 1.075\n",
            "Epoch: 58, Iteration:  1500, Loss: 0.124\n",
            "Epoch: 58, Iteration:  2000, Loss: 0.562\n",
            "Epoch: 58, Iteration:  2500, Loss: 0.267\n",
            "Epoch: 58, Iteration:  3000, Loss: 0.100\n",
            "Epoch: 58, Iteration:  3500, Loss: 0.206\n",
            "Epoch: 58, Iteration:  4000, Loss: 1.233\n",
            "Epoch: 58, Iteration:  4500, Loss: 0.095\n",
            "Epoch: 58, Iteration:  5000, Loss: 0.116\n",
            "Epoch: 58, Iteration:  5500, Loss: 0.055\n",
            "Epoch: 58, Iteration:  6000, Loss: 0.091\n",
            "Epoch: 58, Iteration:  6500, Loss: 0.563\n",
            "Epoch: 58, Iteration:  7000, Loss: 1.361\n",
            "Epoch: 58, Iteration:  7500, Loss: 0.229\n",
            "Epoch: 58, Iteration:  8000, Loss: 0.098\n",
            "Epoch: 58, Iteration:  8500, Loss: 0.118\n",
            "Epoch: 58, Iteration:  9000, Loss: 0.785\n",
            "Epoch: 58, Iteration:  9500, Loss: 0.094\n",
            "Epoch: 58, Iteration: 10000, Loss: 0.085\n",
            "Epoch: 58, Iteration: 10500, Loss: 0.101\n",
            "Epoch: 58, Iteration: 11000, Loss: 0.395\n",
            "Epoch: 58, Iteration: 11500, Loss: 0.816\n",
            "Epoch: 58, Iteration: 12000, Loss: 0.792\n",
            "Epoch: 58, Iteration: 12500, Loss: 0.187\n",
            "Epoch: 58, Iteration: 13000, Loss: 0.119\n",
            "Epoch: 58, Iteration: 13500, Loss: 0.136\n",
            "Epoch: 58, Iteration: 14000, Loss: 0.111\n",
            "Epoch: 58, Iteration: 14500, Loss: 0.103\n",
            "Epoch: 58, Iteration: 15000, Loss: 0.577\n",
            "Epoch: 58, Iteration: 15500, Loss: 0.119\n",
            "Epoch: 58, Iteration: 16000, Loss: 0.086\n",
            "Epoch: 58, Iteration: 16500, Loss: 0.191\n",
            "Epoch: 58, Iteration: 17000, Loss: 0.126\n",
            "Epoch: 58, Iteration: 17500, Loss: 0.216\n",
            "Epoch: 58, Iteration: 18000, Loss: 0.198\n",
            "Epoch: 58, Iteration: 18500, Loss: 0.137\n",
            "Epoch: 58, Iteration: 19000, Loss: 0.492\n",
            "Epoch: 58, Iteration: 19500, Loss: 0.064\n",
            "Epoch: 58, Iteration: 20000, Loss: 1.611\n",
            "Epoch: 58, Iteration: 20500, Loss: 0.136\n",
            "Epoch: 58, Iteration: 21000, Loss: 0.089\n",
            "Epoch: 58, Iteration: 21500, Loss: 0.175\n",
            "Epoch: 58, Iteration: 22000, Loss: 1.472\n",
            "Epoch: 58, Iteration: 22500, Loss: 0.285\n",
            "Epoch: 58, Iteration: 23000, Loss: 1.730\n",
            "Epoch: 58, Iteration: 23500, Loss: 0.099\n",
            "Epoch: 58, Iteration: 24000, Loss: 0.094\n",
            "Epoch: 58, Iteration: 24500, Loss: 0.143\n",
            "Epoch: 58, Iteration: 25000, Loss: 0.180\n",
            "Epoch: 58, Iteration: 25500, Loss: 0.079\n",
            "Epoch: 58, Iteration: 26000, Loss: 0.187\n",
            "Epoch: 58, Iteration: 26500, Loss: 0.176\n",
            "Epoch: 58, Iteration: 27000, Loss: 0.100\n",
            "Epoch: 58, Iteration: 27500, Loss: 0.654\n",
            "Epoch: 58, Iteration: 28000, Loss: 1.584\n",
            "Epoch: 58, Iteration: 28500, Loss: 0.103\n",
            "Epoch: 58, Iteration: 29000, Loss: 0.117\n",
            "Epoch: 58, Iteration: 29500, Loss: 1.498\n",
            "Epoch: 58, Iteration: 30000, Loss: 0.116\n",
            "Epoch: 58, Iteration: 30500, Loss: 0.123\n",
            "Epoch: 58, Iteration: 31000, Loss: 0.272\n",
            "Epoch: 58, Iteration: 31500, Loss: 2.772\n",
            "Epoch: 58, Iteration: 32000, Loss: 0.721\n",
            "Epoch: 58, Iteration: 32500, Loss: 0.113\n",
            "Epoch: 58, Iteration: 33000, Loss: 1.317\n",
            "Epoch: 58, Iteration: 33500, Loss: 0.165\n",
            "Epoch: 58, Iteration: 34000, Loss: 0.342\n",
            "Epoch: 58, Iteration: 34500, Loss: 0.172\n",
            "Epoch: 58, Iteration: 35000, Loss: 0.109\n",
            "Epoch: 58, Iteration: 35500, Loss: 0.082\n",
            "Epoch: 58, Iteration: 36000, Loss: 0.393\n",
            "Epoch: 58, Iteration: 36500, Loss: 0.236\n",
            "Epoch: 58, Iteration: 37000, Loss: 0.112\n",
            "Epoch: 58, Iteration: 37500, Loss: 0.106\n",
            "Epoch: 58, Iteration: 38000, Loss: 0.322\n",
            "Epoch: 58, Iteration: 38500, Loss: 0.135\n",
            "Epoch: 58, Iteration: 39000, Loss: 0.088\n",
            "Epoch: 58, Iteration: 39500, Loss: 0.289\n",
            "Epoch: 58, Iteration: 40000, Loss: 0.272\n",
            "Epoch: 58, Iteration: 40500, Loss: 0.213\n",
            "Epoch: 58, Iteration: 41000, Loss: 0.143\n",
            "Epoch: 58, Iteration: 41500, Loss: 0.776\n",
            "Epoch: 58, Iteration: 42000, Loss: 2.186\n",
            "Epoch: 58, Iteration: 42500, Loss: 2.952\n",
            "Epoch: 58, Iteration: 43000, Loss: 0.675\n",
            "Epoch: 58, Iteration: 43500, Loss: 0.134\n",
            "Epoch: 58, Iteration: 44000, Loss: 0.111\n",
            "Epoch: 58, Iteration: 44500, Loss: 2.543\n",
            "Epoch: 58, Iteration: 45000, Loss: 0.975\n",
            "Epoch: 58, Iteration: 45500, Loss: 0.100\n",
            "Epoch: 58, Iteration: 46000, Loss: 0.842\n",
            "Epoch: 58, Iteration: 46500, Loss: 0.112\n",
            "Epoch: 58, Iteration: 47000, Loss: 0.219\n",
            "Epoch: 58, Iteration: 47500, Loss: 0.364\n",
            "Epoch: 58, Iteration: 48000, Loss: 0.151\n",
            "Epoch: 58, Iteration: 48500, Loss: 0.113\n",
            "Epoch: 58, Iteration: 49000, Loss: 0.148\n",
            "Epoch: 58, Iteration: 49500, Loss: 0.115\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.07 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.60 %\n",
            "w(T) = 1.000\n",
            "Epoch: 59, Iteration:     0, Loss: 0.198\n",
            "Epoch: 59, Iteration:   500, Loss: 0.137\n",
            "Epoch: 59, Iteration:  1000, Loss: 0.110\n",
            "Epoch: 59, Iteration:  1500, Loss: 0.716\n",
            "Epoch: 59, Iteration:  2000, Loss: 0.068\n",
            "Epoch: 59, Iteration:  2500, Loss: 1.343\n",
            "Epoch: 59, Iteration:  3000, Loss: 0.393\n",
            "Epoch: 59, Iteration:  3500, Loss: 0.102\n",
            "Epoch: 59, Iteration:  4000, Loss: 0.181\n",
            "Epoch: 59, Iteration:  4500, Loss: 0.191\n",
            "Epoch: 59, Iteration:  5000, Loss: 0.079\n",
            "Epoch: 59, Iteration:  5500, Loss: 1.166\n",
            "Epoch: 59, Iteration:  6000, Loss: 2.575\n",
            "Epoch: 59, Iteration:  6500, Loss: 0.435\n",
            "Epoch: 59, Iteration:  7000, Loss: 0.077\n",
            "Epoch: 59, Iteration:  7500, Loss: 0.423\n",
            "Epoch: 59, Iteration:  8000, Loss: 0.658\n",
            "Epoch: 59, Iteration:  8500, Loss: 1.676\n",
            "Epoch: 59, Iteration:  9000, Loss: 0.115\n",
            "Epoch: 59, Iteration:  9500, Loss: 0.136\n",
            "Epoch: 59, Iteration: 10000, Loss: 0.128\n",
            "Epoch: 59, Iteration: 10500, Loss: 0.185\n",
            "Epoch: 59, Iteration: 11000, Loss: 0.119\n",
            "Epoch: 59, Iteration: 11500, Loss: 0.133\n",
            "Epoch: 59, Iteration: 12000, Loss: 0.143\n",
            "Epoch: 59, Iteration: 12500, Loss: 0.089\n",
            "Epoch: 59, Iteration: 13000, Loss: 0.130\n",
            "Epoch: 59, Iteration: 13500, Loss: 0.106\n",
            "Epoch: 59, Iteration: 14000, Loss: 0.103\n",
            "Epoch: 59, Iteration: 14500, Loss: 0.094\n",
            "Epoch: 59, Iteration: 15000, Loss: 0.088\n",
            "Epoch: 59, Iteration: 15500, Loss: 0.091\n",
            "Epoch: 59, Iteration: 16000, Loss: 0.103\n",
            "Epoch: 59, Iteration: 16500, Loss: 0.089\n",
            "Epoch: 59, Iteration: 17000, Loss: 1.903\n",
            "Epoch: 59, Iteration: 17500, Loss: 0.128\n",
            "Epoch: 59, Iteration: 18000, Loss: 1.496\n",
            "Epoch: 59, Iteration: 18500, Loss: 0.123\n",
            "Epoch: 59, Iteration: 19000, Loss: 0.954\n",
            "Epoch: 59, Iteration: 19500, Loss: 0.087\n",
            "Epoch: 59, Iteration: 20000, Loss: 0.103\n",
            "Epoch: 59, Iteration: 20500, Loss: 0.244\n",
            "Epoch: 59, Iteration: 21000, Loss: 0.083\n",
            "Epoch: 59, Iteration: 21500, Loss: 0.299\n",
            "Epoch: 59, Iteration: 22000, Loss: 0.121\n",
            "Epoch: 59, Iteration: 22500, Loss: 0.177\n",
            "Epoch: 59, Iteration: 23000, Loss: 0.095\n",
            "Epoch: 59, Iteration: 23500, Loss: 0.098\n",
            "Epoch: 59, Iteration: 24000, Loss: 0.085\n",
            "Epoch: 59, Iteration: 24500, Loss: 0.134\n",
            "Epoch: 59, Iteration: 25000, Loss: 0.147\n",
            "Epoch: 59, Iteration: 25500, Loss: 0.156\n",
            "Epoch: 59, Iteration: 26000, Loss: 0.140\n",
            "Epoch: 59, Iteration: 26500, Loss: 0.097\n",
            "Epoch: 59, Iteration: 27000, Loss: 0.126\n",
            "Epoch: 59, Iteration: 27500, Loss: 1.183\n",
            "Epoch: 59, Iteration: 28000, Loss: 0.104\n",
            "Epoch: 59, Iteration: 28500, Loss: 0.111\n",
            "Epoch: 59, Iteration: 29000, Loss: 1.187\n",
            "Epoch: 59, Iteration: 29500, Loss: 0.122\n",
            "Epoch: 59, Iteration: 30000, Loss: 0.097\n",
            "Epoch: 59, Iteration: 30500, Loss: 0.093\n",
            "Epoch: 59, Iteration: 31000, Loss: 0.188\n",
            "Epoch: 59, Iteration: 31500, Loss: 0.097\n",
            "Epoch: 59, Iteration: 32000, Loss: 0.105\n",
            "Epoch: 59, Iteration: 32500, Loss: 1.162\n",
            "Epoch: 59, Iteration: 33000, Loss: 1.469\n",
            "Epoch: 59, Iteration: 33500, Loss: 0.076\n",
            "Epoch: 59, Iteration: 34000, Loss: 0.120\n",
            "Epoch: 59, Iteration: 34500, Loss: 0.385\n",
            "Epoch: 59, Iteration: 35000, Loss: 0.130\n",
            "Epoch: 59, Iteration: 35500, Loss: 1.020\n",
            "Epoch: 59, Iteration: 36000, Loss: 0.304\n",
            "Epoch: 59, Iteration: 36500, Loss: 0.868\n",
            "Epoch: 59, Iteration: 37000, Loss: 2.122\n",
            "Epoch: 59, Iteration: 37500, Loss: 1.138\n",
            "Epoch: 59, Iteration: 38000, Loss: 1.287\n",
            "Epoch: 59, Iteration: 38500, Loss: 0.811\n",
            "Epoch: 59, Iteration: 39000, Loss: 0.315\n",
            "Epoch: 59, Iteration: 39500, Loss: 0.119\n",
            "Epoch: 59, Iteration: 40000, Loss: 0.159\n",
            "Epoch: 59, Iteration: 40500, Loss: 0.147\n",
            "Epoch: 59, Iteration: 41000, Loss: 0.098\n",
            "Epoch: 59, Iteration: 41500, Loss: 0.227\n",
            "Epoch: 59, Iteration: 42000, Loss: 0.357\n",
            "Epoch: 59, Iteration: 42500, Loss: 0.117\n",
            "Epoch: 59, Iteration: 43000, Loss: 0.109\n",
            "Epoch: 59, Iteration: 43500, Loss: 0.136\n",
            "Epoch: 59, Iteration: 44000, Loss: 0.124\n",
            "Epoch: 59, Iteration: 44500, Loss: 0.085\n",
            "Epoch: 59, Iteration: 45000, Loss: 0.822\n",
            "Epoch: 59, Iteration: 45500, Loss: 0.176\n",
            "Epoch: 59, Iteration: 46000, Loss: 0.144\n",
            "Epoch: 59, Iteration: 46500, Loss: 0.098\n",
            "Epoch: 59, Iteration: 47000, Loss: 0.114\n",
            "Epoch: 59, Iteration: 47500, Loss: 0.126\n",
            "Epoch: 59, Iteration: 48000, Loss: 0.602\n",
            "Epoch: 59, Iteration: 48500, Loss: 0.232\n",
            "Epoch: 59, Iteration: 49000, Loss: 0.134\n",
            "Epoch: 59, Iteration: 49500, Loss: 0.278\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.24 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.17 %\n",
            "w(T) = 1.000\n",
            "Epoch: 60, Iteration:     0, Loss: 0.114\n",
            "Epoch: 60, Iteration:   500, Loss: 0.145\n",
            "Epoch: 60, Iteration:  1000, Loss: 1.578\n",
            "Epoch: 60, Iteration:  1500, Loss: 0.098\n",
            "Epoch: 60, Iteration:  2000, Loss: 0.128\n",
            "Epoch: 60, Iteration:  2500, Loss: 0.078\n",
            "Epoch: 60, Iteration:  3000, Loss: 0.222\n",
            "Epoch: 60, Iteration:  3500, Loss: 0.103\n",
            "Epoch: 60, Iteration:  4000, Loss: 0.241\n",
            "Epoch: 60, Iteration:  4500, Loss: 0.552\n",
            "Epoch: 60, Iteration:  5000, Loss: 0.086\n",
            "Epoch: 60, Iteration:  5500, Loss: 1.086\n",
            "Epoch: 60, Iteration:  6000, Loss: 0.173\n",
            "Epoch: 60, Iteration:  6500, Loss: 0.231\n",
            "Epoch: 60, Iteration:  7000, Loss: 0.103\n",
            "Epoch: 60, Iteration:  7500, Loss: 0.186\n",
            "Epoch: 60, Iteration:  8000, Loss: 0.140\n",
            "Epoch: 60, Iteration:  8500, Loss: 0.094\n",
            "Epoch: 60, Iteration:  9000, Loss: 0.356\n",
            "Epoch: 60, Iteration:  9500, Loss: 0.107\n",
            "Epoch: 60, Iteration: 10000, Loss: 0.217\n",
            "Epoch: 60, Iteration: 10500, Loss: 0.082\n",
            "Epoch: 60, Iteration: 11000, Loss: 0.127\n",
            "Epoch: 60, Iteration: 11500, Loss: 0.082\n",
            "Epoch: 60, Iteration: 12000, Loss: 0.919\n",
            "Epoch: 60, Iteration: 12500, Loss: 0.107\n",
            "Epoch: 60, Iteration: 13000, Loss: 0.070\n",
            "Epoch: 60, Iteration: 13500, Loss: 0.070\n",
            "Epoch: 60, Iteration: 14000, Loss: 0.351\n",
            "Epoch: 60, Iteration: 14500, Loss: 0.092\n",
            "Epoch: 60, Iteration: 15000, Loss: 0.273\n",
            "Epoch: 60, Iteration: 15500, Loss: 0.066\n",
            "Epoch: 60, Iteration: 16000, Loss: 0.079\n",
            "Epoch: 60, Iteration: 16500, Loss: 1.255\n",
            "Epoch: 60, Iteration: 17000, Loss: 1.248\n",
            "Epoch: 60, Iteration: 17500, Loss: 0.270\n",
            "Epoch: 60, Iteration: 18000, Loss: 0.109\n",
            "Epoch: 60, Iteration: 18500, Loss: 0.104\n",
            "Epoch: 60, Iteration: 19000, Loss: 0.082\n",
            "Epoch: 60, Iteration: 19500, Loss: 2.096\n",
            "Epoch: 60, Iteration: 20000, Loss: 0.098\n",
            "Epoch: 60, Iteration: 20500, Loss: 0.086\n",
            "Epoch: 60, Iteration: 21000, Loss: 0.623\n",
            "Epoch: 60, Iteration: 21500, Loss: 1.123\n",
            "Epoch: 60, Iteration: 22000, Loss: 0.162\n",
            "Epoch: 60, Iteration: 22500, Loss: 0.144\n",
            "Epoch: 60, Iteration: 23000, Loss: 0.125\n",
            "Epoch: 60, Iteration: 23500, Loss: 0.095\n",
            "Epoch: 60, Iteration: 24000, Loss: 0.205\n",
            "Epoch: 60, Iteration: 24500, Loss: 0.395\n",
            "Epoch: 60, Iteration: 25000, Loss: 0.095\n",
            "Epoch: 60, Iteration: 25500, Loss: 0.469\n",
            "Epoch: 60, Iteration: 26000, Loss: 0.127\n",
            "Epoch: 60, Iteration: 26500, Loss: 0.073\n",
            "Epoch: 60, Iteration: 27000, Loss: 0.097\n",
            "Epoch: 60, Iteration: 27500, Loss: 0.514\n",
            "Epoch: 60, Iteration: 28000, Loss: 0.130\n",
            "Epoch: 60, Iteration: 28500, Loss: 0.133\n",
            "Epoch: 60, Iteration: 29000, Loss: 0.076\n",
            "Epoch: 60, Iteration: 29500, Loss: 0.139\n",
            "Epoch: 60, Iteration: 30000, Loss: 0.088\n",
            "Epoch: 60, Iteration: 30500, Loss: 0.131\n",
            "Epoch: 60, Iteration: 31000, Loss: 1.455\n",
            "Epoch: 60, Iteration: 31500, Loss: 0.098\n",
            "Epoch: 60, Iteration: 32000, Loss: 0.098\n",
            "Epoch: 60, Iteration: 32500, Loss: 0.096\n",
            "Epoch: 60, Iteration: 33000, Loss: 0.080\n",
            "Epoch: 60, Iteration: 33500, Loss: 0.156\n",
            "Epoch: 60, Iteration: 34000, Loss: 0.303\n",
            "Epoch: 60, Iteration: 34500, Loss: 0.113\n",
            "Epoch: 60, Iteration: 35000, Loss: 0.627\n",
            "Epoch: 60, Iteration: 35500, Loss: 0.671\n",
            "Epoch: 60, Iteration: 36000, Loss: 0.107\n",
            "Epoch: 60, Iteration: 36500, Loss: 0.267\n",
            "Epoch: 60, Iteration: 37000, Loss: 0.094\n",
            "Epoch: 60, Iteration: 37500, Loss: 0.094\n",
            "Epoch: 60, Iteration: 38000, Loss: 0.195\n",
            "Epoch: 60, Iteration: 38500, Loss: 1.563\n",
            "Epoch: 60, Iteration: 39000, Loss: 0.364\n",
            "Epoch: 60, Iteration: 39500, Loss: 0.101\n",
            "Epoch: 60, Iteration: 40000, Loss: 0.255\n",
            "Epoch: 60, Iteration: 40500, Loss: 0.218\n",
            "Epoch: 60, Iteration: 41000, Loss: 1.542\n",
            "Epoch: 60, Iteration: 41500, Loss: 0.275\n",
            "Epoch: 60, Iteration: 42000, Loss: 0.121\n",
            "Epoch: 60, Iteration: 42500, Loss: 0.121\n",
            "Epoch: 60, Iteration: 43000, Loss: 0.094\n",
            "Epoch: 60, Iteration: 43500, Loss: 0.295\n",
            "Epoch: 60, Iteration: 44000, Loss: 0.082\n",
            "Epoch: 60, Iteration: 44500, Loss: 0.461\n",
            "Epoch: 60, Iteration: 45000, Loss: 0.330\n",
            "Epoch: 60, Iteration: 45500, Loss: 0.103\n",
            "Epoch: 60, Iteration: 46000, Loss: 0.099\n",
            "Epoch: 60, Iteration: 46500, Loss: 0.489\n",
            "Epoch: 60, Iteration: 47000, Loss: 0.528\n",
            "Epoch: 60, Iteration: 47500, Loss: 0.080\n",
            "Epoch: 60, Iteration: 48000, Loss: 0.086\n",
            "Epoch: 60, Iteration: 48500, Loss: 0.080\n",
            "Epoch: 60, Iteration: 49000, Loss: 0.079\n",
            "Epoch: 60, Iteration: 49500, Loss: 0.700\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.29 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.10 %\n",
            "w(T) = 1.000\n",
            "Epoch: 61, Iteration:     0, Loss: 0.065\n",
            "Epoch: 61, Iteration:   500, Loss: 0.135\n",
            "Epoch: 61, Iteration:  1000, Loss: 0.106\n",
            "Epoch: 61, Iteration:  1500, Loss: 0.093\n",
            "Epoch: 61, Iteration:  2000, Loss: 0.133\n",
            "Epoch: 61, Iteration:  2500, Loss: 0.240\n",
            "Epoch: 61, Iteration:  3000, Loss: 0.092\n",
            "Epoch: 61, Iteration:  3500, Loss: 0.348\n",
            "Epoch: 61, Iteration:  4000, Loss: 1.203\n",
            "Epoch: 61, Iteration:  4500, Loss: 0.088\n",
            "Epoch: 61, Iteration:  5000, Loss: 0.090\n",
            "Epoch: 61, Iteration:  5500, Loss: 0.078\n",
            "Epoch: 61, Iteration:  6000, Loss: 0.082\n",
            "Epoch: 61, Iteration:  6500, Loss: 0.084\n",
            "Epoch: 61, Iteration:  7000, Loss: 0.094\n",
            "Epoch: 61, Iteration:  7500, Loss: 0.122\n",
            "Epoch: 61, Iteration:  8000, Loss: 2.440\n",
            "Epoch: 61, Iteration:  8500, Loss: 0.929\n",
            "Epoch: 61, Iteration:  9000, Loss: 0.135\n",
            "Epoch: 61, Iteration:  9500, Loss: 0.116\n",
            "Epoch: 61, Iteration: 10000, Loss: 1.640\n",
            "Epoch: 61, Iteration: 10500, Loss: 0.154\n",
            "Epoch: 61, Iteration: 11000, Loss: 0.647\n",
            "Epoch: 61, Iteration: 11500, Loss: 0.077\n",
            "Epoch: 61, Iteration: 12000, Loss: 0.086\n",
            "Epoch: 61, Iteration: 12500, Loss: 0.112\n",
            "Epoch: 61, Iteration: 13000, Loss: 0.111\n",
            "Epoch: 61, Iteration: 13500, Loss: 0.086\n",
            "Epoch: 61, Iteration: 14000, Loss: 0.068\n",
            "Epoch: 61, Iteration: 14500, Loss: 0.403\n",
            "Epoch: 61, Iteration: 15000, Loss: 0.618\n",
            "Epoch: 61, Iteration: 15500, Loss: 0.079\n",
            "Epoch: 61, Iteration: 16000, Loss: 0.227\n",
            "Epoch: 61, Iteration: 16500, Loss: 0.156\n",
            "Epoch: 61, Iteration: 17000, Loss: 0.152\n",
            "Epoch: 61, Iteration: 17500, Loss: 0.097\n",
            "Epoch: 61, Iteration: 18000, Loss: 0.214\n",
            "Epoch: 61, Iteration: 18500, Loss: 0.130\n",
            "Epoch: 61, Iteration: 19000, Loss: 0.123\n",
            "Epoch: 61, Iteration: 19500, Loss: 0.769\n",
            "Epoch: 61, Iteration: 20000, Loss: 1.098\n",
            "Epoch: 61, Iteration: 20500, Loss: 1.663\n",
            "Epoch: 61, Iteration: 21000, Loss: 0.372\n",
            "Epoch: 61, Iteration: 21500, Loss: 0.354\n",
            "Epoch: 61, Iteration: 22000, Loss: 0.109\n",
            "Epoch: 61, Iteration: 22500, Loss: 0.108\n",
            "Epoch: 61, Iteration: 23000, Loss: 0.655\n",
            "Epoch: 61, Iteration: 23500, Loss: 0.081\n",
            "Epoch: 61, Iteration: 24000, Loss: 0.918\n",
            "Epoch: 61, Iteration: 24500, Loss: 1.290\n",
            "Epoch: 61, Iteration: 25000, Loss: 0.587\n",
            "Epoch: 61, Iteration: 25500, Loss: 1.229\n",
            "Epoch: 61, Iteration: 26000, Loss: 0.069\n",
            "Epoch: 61, Iteration: 26500, Loss: 0.116\n",
            "Epoch: 61, Iteration: 27000, Loss: 0.078\n",
            "Epoch: 61, Iteration: 27500, Loss: 0.087\n",
            "Epoch: 61, Iteration: 28000, Loss: 0.223\n",
            "Epoch: 61, Iteration: 28500, Loss: 0.114\n",
            "Epoch: 61, Iteration: 29000, Loss: 0.132\n",
            "Epoch: 61, Iteration: 29500, Loss: 0.198\n",
            "Epoch: 61, Iteration: 30000, Loss: 0.470\n",
            "Epoch: 61, Iteration: 30500, Loss: 0.109\n",
            "Epoch: 61, Iteration: 31000, Loss: 0.178\n",
            "Epoch: 61, Iteration: 31500, Loss: 0.118\n",
            "Epoch: 61, Iteration: 32000, Loss: 0.072\n",
            "Epoch: 61, Iteration: 32500, Loss: 0.093\n",
            "Epoch: 61, Iteration: 33000, Loss: 0.585\n",
            "Epoch: 61, Iteration: 33500, Loss: 1.872\n",
            "Epoch: 61, Iteration: 34000, Loss: 0.358\n",
            "Epoch: 61, Iteration: 34500, Loss: 1.555\n",
            "Epoch: 61, Iteration: 35000, Loss: 0.095\n",
            "Epoch: 61, Iteration: 35500, Loss: 0.106\n",
            "Epoch: 61, Iteration: 36000, Loss: 0.155\n",
            "Epoch: 61, Iteration: 36500, Loss: 0.081\n",
            "Epoch: 61, Iteration: 37000, Loss: 0.497\n",
            "Epoch: 61, Iteration: 37500, Loss: 0.127\n",
            "Epoch: 61, Iteration: 38000, Loss: 0.162\n",
            "Epoch: 61, Iteration: 38500, Loss: 0.117\n",
            "Epoch: 61, Iteration: 39000, Loss: 2.487\n",
            "Epoch: 61, Iteration: 39500, Loss: 0.091\n",
            "Epoch: 61, Iteration: 40000, Loss: 0.133\n",
            "Epoch: 61, Iteration: 40500, Loss: 0.995\n",
            "Epoch: 61, Iteration: 41000, Loss: 0.106\n",
            "Epoch: 61, Iteration: 41500, Loss: 0.130\n",
            "Epoch: 61, Iteration: 42000, Loss: 0.090\n",
            "Epoch: 61, Iteration: 42500, Loss: 0.460\n",
            "Epoch: 61, Iteration: 43000, Loss: 0.117\n",
            "Epoch: 61, Iteration: 43500, Loss: 0.105\n",
            "Epoch: 61, Iteration: 44000, Loss: 0.106\n",
            "Epoch: 61, Iteration: 44500, Loss: 0.118\n",
            "Epoch: 61, Iteration: 45000, Loss: 0.102\n",
            "Epoch: 61, Iteration: 45500, Loss: 0.092\n",
            "Epoch: 61, Iteration: 46000, Loss: 0.106\n",
            "Epoch: 61, Iteration: 46500, Loss: 0.720\n",
            "Epoch: 61, Iteration: 47000, Loss: 0.498\n",
            "Epoch: 61, Iteration: 47500, Loss: 0.077\n",
            "Epoch: 61, Iteration: 48000, Loss: 0.168\n",
            "Epoch: 61, Iteration: 48500, Loss: 0.145\n",
            "Epoch: 61, Iteration: 49000, Loss: 0.121\n",
            "Epoch: 61, Iteration: 49500, Loss: 0.136\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.88 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 40.19 %\n",
            "w(T) = 1.000\n",
            "Epoch: 62, Iteration:     0, Loss: 0.156\n",
            "Epoch: 62, Iteration:   500, Loss: 0.156\n",
            "Epoch: 62, Iteration:  1000, Loss: 0.075\n",
            "Epoch: 62, Iteration:  1500, Loss: 0.112\n",
            "Epoch: 62, Iteration:  2000, Loss: 0.109\n",
            "Epoch: 62, Iteration:  2500, Loss: 0.110\n",
            "Epoch: 62, Iteration:  3000, Loss: 0.098\n",
            "Epoch: 62, Iteration:  3500, Loss: 0.091\n",
            "Epoch: 62, Iteration:  4000, Loss: 0.129\n",
            "Epoch: 62, Iteration:  4500, Loss: 0.120\n",
            "Epoch: 62, Iteration:  5000, Loss: 0.459\n",
            "Epoch: 62, Iteration:  5500, Loss: 0.167\n",
            "Epoch: 62, Iteration:  6000, Loss: 0.135\n",
            "Epoch: 62, Iteration:  6500, Loss: 0.662\n",
            "Epoch: 62, Iteration:  7000, Loss: 0.097\n",
            "Epoch: 62, Iteration:  7500, Loss: 0.132\n",
            "Epoch: 62, Iteration:  8000, Loss: 0.272\n",
            "Epoch: 62, Iteration:  8500, Loss: 0.691\n",
            "Epoch: 62, Iteration:  9000, Loss: 0.143\n",
            "Epoch: 62, Iteration:  9500, Loss: 0.126\n",
            "Epoch: 62, Iteration: 10000, Loss: 0.716\n",
            "Epoch: 62, Iteration: 10500, Loss: 0.091\n",
            "Epoch: 62, Iteration: 11000, Loss: 0.093\n",
            "Epoch: 62, Iteration: 11500, Loss: 0.113\n",
            "Epoch: 62, Iteration: 12000, Loss: 0.072\n",
            "Epoch: 62, Iteration: 12500, Loss: 0.116\n",
            "Epoch: 62, Iteration: 13000, Loss: 0.194\n",
            "Epoch: 62, Iteration: 13500, Loss: 0.135\n",
            "Epoch: 62, Iteration: 14000, Loss: 0.089\n",
            "Epoch: 62, Iteration: 14500, Loss: 0.651\n",
            "Epoch: 62, Iteration: 15000, Loss: 0.398\n",
            "Epoch: 62, Iteration: 15500, Loss: 0.160\n",
            "Epoch: 62, Iteration: 16000, Loss: 2.257\n",
            "Epoch: 62, Iteration: 16500, Loss: 0.240\n",
            "Epoch: 62, Iteration: 17000, Loss: 0.177\n",
            "Epoch: 62, Iteration: 17500, Loss: 0.133\n",
            "Epoch: 62, Iteration: 18000, Loss: 0.119\n",
            "Epoch: 62, Iteration: 18500, Loss: 0.264\n",
            "Epoch: 62, Iteration: 19000, Loss: 0.493\n",
            "Epoch: 62, Iteration: 19500, Loss: 0.420\n",
            "Epoch: 62, Iteration: 20000, Loss: 0.423\n",
            "Epoch: 62, Iteration: 20500, Loss: 0.478\n",
            "Epoch: 62, Iteration: 21000, Loss: 0.278\n",
            "Epoch: 62, Iteration: 21500, Loss: 0.124\n",
            "Epoch: 62, Iteration: 22000, Loss: 0.121\n",
            "Epoch: 62, Iteration: 22500, Loss: 0.323\n",
            "Epoch: 62, Iteration: 23000, Loss: 0.128\n",
            "Epoch: 62, Iteration: 23500, Loss: 0.112\n",
            "Epoch: 62, Iteration: 24000, Loss: 0.095\n",
            "Epoch: 62, Iteration: 24500, Loss: 0.079\n",
            "Epoch: 62, Iteration: 25000, Loss: 0.271\n",
            "Epoch: 62, Iteration: 25500, Loss: 0.667\n",
            "Epoch: 62, Iteration: 26000, Loss: 0.749\n",
            "Epoch: 62, Iteration: 26500, Loss: 0.064\n",
            "Epoch: 62, Iteration: 27000, Loss: 0.704\n",
            "Epoch: 62, Iteration: 27500, Loss: 0.124\n",
            "Epoch: 62, Iteration: 28000, Loss: 0.103\n",
            "Epoch: 62, Iteration: 28500, Loss: 0.112\n",
            "Epoch: 62, Iteration: 29000, Loss: 0.126\n",
            "Epoch: 62, Iteration: 29500, Loss: 0.101\n",
            "Epoch: 62, Iteration: 30000, Loss: 0.070\n",
            "Epoch: 62, Iteration: 30500, Loss: 0.061\n",
            "Epoch: 62, Iteration: 31000, Loss: 0.094\n",
            "Epoch: 62, Iteration: 31500, Loss: 0.533\n",
            "Epoch: 62, Iteration: 32000, Loss: 0.070\n",
            "Epoch: 62, Iteration: 32500, Loss: 0.076\n",
            "Epoch: 62, Iteration: 33000, Loss: 0.498\n",
            "Epoch: 62, Iteration: 33500, Loss: 0.206\n",
            "Epoch: 62, Iteration: 34000, Loss: 0.199\n",
            "Epoch: 62, Iteration: 34500, Loss: 1.214\n",
            "Epoch: 62, Iteration: 35000, Loss: 0.113\n",
            "Epoch: 62, Iteration: 35500, Loss: 1.694\n",
            "Epoch: 62, Iteration: 36000, Loss: 0.073\n",
            "Epoch: 62, Iteration: 36500, Loss: 0.193\n",
            "Epoch: 62, Iteration: 37000, Loss: 0.078\n",
            "Epoch: 62, Iteration: 37500, Loss: 0.108\n",
            "Epoch: 62, Iteration: 38000, Loss: 0.143\n",
            "Epoch: 62, Iteration: 38500, Loss: 0.096\n",
            "Epoch: 62, Iteration: 39000, Loss: 3.944\n",
            "Epoch: 62, Iteration: 39500, Loss: 0.973\n",
            "Epoch: 62, Iteration: 40000, Loss: 0.092\n",
            "Epoch: 62, Iteration: 40500, Loss: 0.105\n",
            "Epoch: 62, Iteration: 41000, Loss: 0.101\n",
            "Epoch: 62, Iteration: 41500, Loss: 0.135\n",
            "Epoch: 62, Iteration: 42000, Loss: 0.145\n",
            "Epoch: 62, Iteration: 42500, Loss: 0.147\n",
            "Epoch: 62, Iteration: 43000, Loss: 0.089\n",
            "Epoch: 62, Iteration: 43500, Loss: 0.114\n",
            "Epoch: 62, Iteration: 44000, Loss: 0.277\n",
            "Epoch: 62, Iteration: 44500, Loss: 0.327\n",
            "Epoch: 62, Iteration: 45000, Loss: 0.108\n",
            "Epoch: 62, Iteration: 45500, Loss: 0.096\n",
            "Epoch: 62, Iteration: 46000, Loss: 0.094\n",
            "Epoch: 62, Iteration: 46500, Loss: 0.754\n",
            "Epoch: 62, Iteration: 47000, Loss: 0.866\n",
            "Epoch: 62, Iteration: 47500, Loss: 0.116\n",
            "Epoch: 62, Iteration: 48000, Loss: 0.114\n",
            "Epoch: 62, Iteration: 48500, Loss: 0.070\n",
            "Epoch: 62, Iteration: 49000, Loss: 0.099\n",
            "Epoch: 62, Iteration: 49500, Loss: 0.083\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.87 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.35 %\n",
            "w(T) = 1.000\n",
            "Epoch: 63, Iteration:     0, Loss: 0.096\n",
            "Epoch: 63, Iteration:   500, Loss: 0.094\n",
            "Epoch: 63, Iteration:  1000, Loss: 0.106\n",
            "Epoch: 63, Iteration:  1500, Loss: 0.111\n",
            "Epoch: 63, Iteration:  2000, Loss: 0.467\n",
            "Epoch: 63, Iteration:  2500, Loss: 0.685\n",
            "Epoch: 63, Iteration:  3000, Loss: 0.084\n",
            "Epoch: 63, Iteration:  3500, Loss: 0.085\n",
            "Epoch: 63, Iteration:  4000, Loss: 0.157\n",
            "Epoch: 63, Iteration:  4500, Loss: 0.088\n",
            "Epoch: 63, Iteration:  5000, Loss: 0.381\n",
            "Epoch: 63, Iteration:  5500, Loss: 0.081\n",
            "Epoch: 63, Iteration:  6000, Loss: 0.119\n",
            "Epoch: 63, Iteration:  6500, Loss: 0.113\n",
            "Epoch: 63, Iteration:  7000, Loss: 0.506\n",
            "Epoch: 63, Iteration:  7500, Loss: 0.990\n",
            "Epoch: 63, Iteration:  8000, Loss: 0.104\n",
            "Epoch: 63, Iteration:  8500, Loss: 0.132\n",
            "Epoch: 63, Iteration:  9000, Loss: 1.834\n",
            "Epoch: 63, Iteration:  9500, Loss: 0.071\n",
            "Epoch: 63, Iteration: 10000, Loss: 0.186\n",
            "Epoch: 63, Iteration: 10500, Loss: 2.305\n",
            "Epoch: 63, Iteration: 11000, Loss: 0.726\n",
            "Epoch: 63, Iteration: 11500, Loss: 0.082\n",
            "Epoch: 63, Iteration: 12000, Loss: 0.079\n",
            "Epoch: 63, Iteration: 12500, Loss: 0.085\n",
            "Epoch: 63, Iteration: 13000, Loss: 0.089\n",
            "Epoch: 63, Iteration: 13500, Loss: 0.099\n",
            "Epoch: 63, Iteration: 14000, Loss: 0.101\n",
            "Epoch: 63, Iteration: 14500, Loss: 0.105\n",
            "Epoch: 63, Iteration: 15000, Loss: 0.104\n",
            "Epoch: 63, Iteration: 15500, Loss: 0.195\n",
            "Epoch: 63, Iteration: 16000, Loss: 0.099\n",
            "Epoch: 63, Iteration: 16500, Loss: 0.109\n",
            "Epoch: 63, Iteration: 17000, Loss: 0.118\n",
            "Epoch: 63, Iteration: 17500, Loss: 0.532\n",
            "Epoch: 63, Iteration: 18000, Loss: 0.333\n",
            "Epoch: 63, Iteration: 18500, Loss: 0.333\n",
            "Epoch: 63, Iteration: 19000, Loss: 0.099\n",
            "Epoch: 63, Iteration: 19500, Loss: 0.081\n",
            "Epoch: 63, Iteration: 20000, Loss: 0.069\n",
            "Epoch: 63, Iteration: 20500, Loss: 0.091\n",
            "Epoch: 63, Iteration: 21000, Loss: 0.097\n",
            "Epoch: 63, Iteration: 21500, Loss: 0.071\n",
            "Epoch: 63, Iteration: 22000, Loss: 0.079\n",
            "Epoch: 63, Iteration: 22500, Loss: 0.322\n",
            "Epoch: 63, Iteration: 23000, Loss: 0.095\n",
            "Epoch: 63, Iteration: 23500, Loss: 0.087\n",
            "Epoch: 63, Iteration: 24000, Loss: 0.100\n",
            "Epoch: 63, Iteration: 24500, Loss: 0.256\n",
            "Epoch: 63, Iteration: 25000, Loss: 0.091\n",
            "Epoch: 63, Iteration: 25500, Loss: 0.091\n",
            "Epoch: 63, Iteration: 26000, Loss: 0.091\n",
            "Epoch: 63, Iteration: 26500, Loss: 0.103\n",
            "Epoch: 63, Iteration: 27000, Loss: 0.120\n",
            "Epoch: 63, Iteration: 27500, Loss: 0.638\n",
            "Epoch: 63, Iteration: 28000, Loss: 0.327\n",
            "Epoch: 63, Iteration: 28500, Loss: 0.066\n",
            "Epoch: 63, Iteration: 29000, Loss: 0.106\n",
            "Epoch: 63, Iteration: 29500, Loss: 0.101\n",
            "Epoch: 63, Iteration: 30000, Loss: 0.887\n",
            "Epoch: 63, Iteration: 30500, Loss: 0.155\n",
            "Epoch: 63, Iteration: 31000, Loss: 0.683\n",
            "Epoch: 63, Iteration: 31500, Loss: 1.259\n",
            "Epoch: 63, Iteration: 32000, Loss: 0.085\n",
            "Epoch: 63, Iteration: 32500, Loss: 0.206\n",
            "Epoch: 63, Iteration: 33000, Loss: 0.062\n",
            "Epoch: 63, Iteration: 33500, Loss: 0.074\n",
            "Epoch: 63, Iteration: 34000, Loss: 0.086\n",
            "Epoch: 63, Iteration: 34500, Loss: 0.833\n",
            "Epoch: 63, Iteration: 35000, Loss: 0.728\n",
            "Epoch: 63, Iteration: 35500, Loss: 0.075\n",
            "Epoch: 63, Iteration: 36000, Loss: 0.179\n",
            "Epoch: 63, Iteration: 36500, Loss: 0.118\n",
            "Epoch: 63, Iteration: 37000, Loss: 0.069\n",
            "Epoch: 63, Iteration: 37500, Loss: 0.290\n",
            "Epoch: 63, Iteration: 38000, Loss: 0.073\n",
            "Epoch: 63, Iteration: 38500, Loss: 0.063\n",
            "Epoch: 63, Iteration: 39000, Loss: 0.181\n",
            "Epoch: 63, Iteration: 39500, Loss: 0.233\n",
            "Epoch: 63, Iteration: 40000, Loss: 0.078\n",
            "Epoch: 63, Iteration: 40500, Loss: 0.091\n",
            "Epoch: 63, Iteration: 41000, Loss: 0.159\n",
            "Epoch: 63, Iteration: 41500, Loss: 0.074\n",
            "Epoch: 63, Iteration: 42000, Loss: 0.122\n",
            "Epoch: 63, Iteration: 42500, Loss: 0.059\n",
            "Epoch: 63, Iteration: 43000, Loss: 0.057\n",
            "Epoch: 63, Iteration: 43500, Loss: 0.498\n",
            "Epoch: 63, Iteration: 44000, Loss: 0.070\n",
            "Epoch: 63, Iteration: 44500, Loss: 0.111\n",
            "Epoch: 63, Iteration: 45000, Loss: 0.107\n",
            "Epoch: 63, Iteration: 45500, Loss: 0.067\n",
            "Epoch: 63, Iteration: 46000, Loss: 0.112\n",
            "Epoch: 63, Iteration: 46500, Loss: 2.504\n",
            "Epoch: 63, Iteration: 47000, Loss: 0.192\n",
            "Epoch: 63, Iteration: 47500, Loss: 0.128\n",
            "Epoch: 63, Iteration: 48000, Loss: 0.084\n",
            "Epoch: 63, Iteration: 48500, Loss: 0.155\n",
            "Epoch: 63, Iteration: 49000, Loss: 0.320\n",
            "Epoch: 63, Iteration: 49500, Loss: 0.275\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.47 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.84 %\n",
            "w(T) = 1.000\n",
            "Epoch: 64, Iteration:     0, Loss: 0.107\n",
            "Epoch: 64, Iteration:   500, Loss: 0.102\n",
            "Epoch: 64, Iteration:  1000, Loss: 0.081\n",
            "Epoch: 64, Iteration:  1500, Loss: 0.229\n",
            "Epoch: 64, Iteration:  2000, Loss: 2.054\n",
            "Epoch: 64, Iteration:  2500, Loss: 0.087\n",
            "Epoch: 64, Iteration:  3000, Loss: 0.386\n",
            "Epoch: 64, Iteration:  3500, Loss: 0.076\n",
            "Epoch: 64, Iteration:  4000, Loss: 0.122\n",
            "Epoch: 64, Iteration:  4500, Loss: 0.080\n",
            "Epoch: 64, Iteration:  5000, Loss: 0.106\n",
            "Epoch: 64, Iteration:  5500, Loss: 0.175\n",
            "Epoch: 64, Iteration:  6000, Loss: 0.084\n",
            "Epoch: 64, Iteration:  6500, Loss: 0.103\n",
            "Epoch: 64, Iteration:  7000, Loss: 0.083\n",
            "Epoch: 64, Iteration:  7500, Loss: 0.097\n",
            "Epoch: 64, Iteration:  8000, Loss: 0.093\n",
            "Epoch: 64, Iteration:  8500, Loss: 0.246\n",
            "Epoch: 64, Iteration:  9000, Loss: 0.076\n",
            "Epoch: 64, Iteration:  9500, Loss: 0.372\n",
            "Epoch: 64, Iteration: 10000, Loss: 0.104\n",
            "Epoch: 64, Iteration: 10500, Loss: 0.995\n",
            "Epoch: 64, Iteration: 11000, Loss: 0.066\n",
            "Epoch: 64, Iteration: 11500, Loss: 0.295\n",
            "Epoch: 64, Iteration: 12000, Loss: 0.067\n",
            "Epoch: 64, Iteration: 12500, Loss: 0.109\n",
            "Epoch: 64, Iteration: 13000, Loss: 1.116\n",
            "Epoch: 64, Iteration: 13500, Loss: 0.974\n",
            "Epoch: 64, Iteration: 14000, Loss: 0.103\n",
            "Epoch: 64, Iteration: 14500, Loss: 0.095\n",
            "Epoch: 64, Iteration: 15000, Loss: 0.088\n",
            "Epoch: 64, Iteration: 15500, Loss: 0.186\n",
            "Epoch: 64, Iteration: 16000, Loss: 0.129\n",
            "Epoch: 64, Iteration: 16500, Loss: 0.088\n",
            "Epoch: 64, Iteration: 17000, Loss: 0.085\n",
            "Epoch: 64, Iteration: 17500, Loss: 0.103\n",
            "Epoch: 64, Iteration: 18000, Loss: 0.099\n",
            "Epoch: 64, Iteration: 18500, Loss: 0.112\n",
            "Epoch: 64, Iteration: 19000, Loss: 0.080\n",
            "Epoch: 64, Iteration: 19500, Loss: 0.156\n",
            "Epoch: 64, Iteration: 20000, Loss: 0.354\n",
            "Epoch: 64, Iteration: 20500, Loss: 0.097\n",
            "Epoch: 64, Iteration: 21000, Loss: 0.059\n",
            "Epoch: 64, Iteration: 21500, Loss: 0.075\n",
            "Epoch: 64, Iteration: 22000, Loss: 0.208\n",
            "Epoch: 64, Iteration: 22500, Loss: 0.222\n",
            "Epoch: 64, Iteration: 23000, Loss: 0.111\n",
            "Epoch: 64, Iteration: 23500, Loss: 0.164\n",
            "Epoch: 64, Iteration: 24000, Loss: 0.124\n",
            "Epoch: 64, Iteration: 24500, Loss: 0.100\n",
            "Epoch: 64, Iteration: 25000, Loss: 0.127\n",
            "Epoch: 64, Iteration: 25500, Loss: 0.278\n",
            "Epoch: 64, Iteration: 26000, Loss: 0.097\n",
            "Epoch: 64, Iteration: 26500, Loss: 0.314\n",
            "Epoch: 64, Iteration: 27000, Loss: 0.422\n",
            "Epoch: 64, Iteration: 27500, Loss: 0.090\n",
            "Epoch: 64, Iteration: 28000, Loss: 0.125\n",
            "Epoch: 64, Iteration: 28500, Loss: 0.097\n",
            "Epoch: 64, Iteration: 29000, Loss: 0.937\n",
            "Epoch: 64, Iteration: 29500, Loss: 0.115\n",
            "Epoch: 64, Iteration: 30000, Loss: 0.194\n",
            "Epoch: 64, Iteration: 30500, Loss: 0.056\n",
            "Epoch: 64, Iteration: 31000, Loss: 0.071\n",
            "Epoch: 64, Iteration: 31500, Loss: 0.169\n",
            "Epoch: 64, Iteration: 32000, Loss: 0.522\n",
            "Epoch: 64, Iteration: 32500, Loss: 0.108\n",
            "Epoch: 64, Iteration: 33000, Loss: 0.086\n",
            "Epoch: 64, Iteration: 33500, Loss: 0.121\n",
            "Epoch: 64, Iteration: 34000, Loss: 0.098\n",
            "Epoch: 64, Iteration: 34500, Loss: 0.087\n",
            "Epoch: 64, Iteration: 35000, Loss: 0.350\n",
            "Epoch: 64, Iteration: 35500, Loss: 0.090\n",
            "Epoch: 64, Iteration: 36000, Loss: 0.070\n",
            "Epoch: 64, Iteration: 36500, Loss: 0.063\n",
            "Epoch: 64, Iteration: 37000, Loss: 0.452\n",
            "Epoch: 64, Iteration: 37500, Loss: 0.078\n",
            "Epoch: 64, Iteration: 38000, Loss: 0.083\n",
            "Epoch: 64, Iteration: 38500, Loss: 0.074\n",
            "Epoch: 64, Iteration: 39000, Loss: 0.106\n",
            "Epoch: 64, Iteration: 39500, Loss: 0.137\n",
            "Epoch: 64, Iteration: 40000, Loss: 0.079\n",
            "Epoch: 64, Iteration: 40500, Loss: 0.056\n",
            "Epoch: 64, Iteration: 41000, Loss: 0.059\n",
            "Epoch: 64, Iteration: 41500, Loss: 0.405\n",
            "Epoch: 64, Iteration: 42000, Loss: 0.073\n",
            "Epoch: 64, Iteration: 42500, Loss: 0.103\n",
            "Epoch: 64, Iteration: 43000, Loss: 0.092\n",
            "Epoch: 64, Iteration: 43500, Loss: 0.097\n",
            "Epoch: 64, Iteration: 44000, Loss: 0.166\n",
            "Epoch: 64, Iteration: 44500, Loss: 0.136\n",
            "Epoch: 64, Iteration: 45000, Loss: 0.096\n",
            "Epoch: 64, Iteration: 45500, Loss: 0.099\n",
            "Epoch: 64, Iteration: 46000, Loss: 0.138\n",
            "Epoch: 64, Iteration: 46500, Loss: 0.251\n",
            "Epoch: 64, Iteration: 47000, Loss: 0.128\n",
            "Epoch: 64, Iteration: 47500, Loss: 0.110\n",
            "Epoch: 64, Iteration: 48000, Loss: 0.101\n",
            "Epoch: 64, Iteration: 48500, Loss: 0.098\n",
            "Epoch: 64, Iteration: 49000, Loss: 0.298\n",
            "Epoch: 64, Iteration: 49500, Loss: 0.133\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.02 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.09 %\n",
            "w(T) = 1.000\n",
            "Epoch: 65, Iteration:     0, Loss: 1.087\n",
            "Epoch: 65, Iteration:   500, Loss: 0.106\n",
            "Epoch: 65, Iteration:  1000, Loss: 0.118\n",
            "Epoch: 65, Iteration:  1500, Loss: 0.188\n",
            "Epoch: 65, Iteration:  2000, Loss: 0.066\n",
            "Epoch: 65, Iteration:  2500, Loss: 0.133\n",
            "Epoch: 65, Iteration:  3000, Loss: 0.124\n",
            "Epoch: 65, Iteration:  3500, Loss: 0.341\n",
            "Epoch: 65, Iteration:  4000, Loss: 0.362\n",
            "Epoch: 65, Iteration:  4500, Loss: 0.707\n",
            "Epoch: 65, Iteration:  5000, Loss: 0.895\n",
            "Epoch: 65, Iteration:  5500, Loss: 0.069\n",
            "Epoch: 65, Iteration:  6000, Loss: 0.096\n",
            "Epoch: 65, Iteration:  6500, Loss: 0.095\n",
            "Epoch: 65, Iteration:  7000, Loss: 0.107\n",
            "Epoch: 65, Iteration:  7500, Loss: 0.075\n",
            "Epoch: 65, Iteration:  8000, Loss: 0.072\n",
            "Epoch: 65, Iteration:  8500, Loss: 0.386\n",
            "Epoch: 65, Iteration:  9000, Loss: 0.430\n",
            "Epoch: 65, Iteration:  9500, Loss: 0.130\n",
            "Epoch: 65, Iteration: 10000, Loss: 0.121\n",
            "Epoch: 65, Iteration: 10500, Loss: 0.425\n",
            "Epoch: 65, Iteration: 11000, Loss: 0.103\n",
            "Epoch: 65, Iteration: 11500, Loss: 0.069\n",
            "Epoch: 65, Iteration: 12000, Loss: 0.126\n",
            "Epoch: 65, Iteration: 12500, Loss: 0.099\n",
            "Epoch: 65, Iteration: 13000, Loss: 0.222\n",
            "Epoch: 65, Iteration: 13500, Loss: 0.082\n",
            "Epoch: 65, Iteration: 14000, Loss: 0.276\n",
            "Epoch: 65, Iteration: 14500, Loss: 0.086\n",
            "Epoch: 65, Iteration: 15000, Loss: 0.090\n",
            "Epoch: 65, Iteration: 15500, Loss: 0.128\n",
            "Epoch: 65, Iteration: 16000, Loss: 0.071\n",
            "Epoch: 65, Iteration: 16500, Loss: 0.103\n",
            "Epoch: 65, Iteration: 17000, Loss: 1.070\n",
            "Epoch: 65, Iteration: 17500, Loss: 0.538\n",
            "Epoch: 65, Iteration: 18000, Loss: 0.137\n",
            "Epoch: 65, Iteration: 18500, Loss: 0.135\n",
            "Epoch: 65, Iteration: 19000, Loss: 0.084\n",
            "Epoch: 65, Iteration: 19500, Loss: 0.080\n",
            "Epoch: 65, Iteration: 20000, Loss: 0.075\n",
            "Epoch: 65, Iteration: 20500, Loss: 0.082\n",
            "Epoch: 65, Iteration: 21000, Loss: 0.094\n",
            "Epoch: 65, Iteration: 21500, Loss: 0.113\n",
            "Epoch: 65, Iteration: 22000, Loss: 0.095\n",
            "Epoch: 65, Iteration: 22500, Loss: 0.617\n",
            "Epoch: 65, Iteration: 23000, Loss: 0.192\n",
            "Epoch: 65, Iteration: 23500, Loss: 0.093\n",
            "Epoch: 65, Iteration: 24000, Loss: 0.080\n",
            "Epoch: 65, Iteration: 24500, Loss: 0.090\n",
            "Epoch: 65, Iteration: 25000, Loss: 0.071\n",
            "Epoch: 65, Iteration: 25500, Loss: 0.113\n",
            "Epoch: 65, Iteration: 26000, Loss: 0.093\n",
            "Epoch: 65, Iteration: 26500, Loss: 0.104\n",
            "Epoch: 65, Iteration: 27000, Loss: 0.099\n",
            "Epoch: 65, Iteration: 27500, Loss: 0.169\n",
            "Epoch: 65, Iteration: 28000, Loss: 0.098\n",
            "Epoch: 65, Iteration: 28500, Loss: 0.081\n",
            "Epoch: 65, Iteration: 29000, Loss: 0.119\n",
            "Epoch: 65, Iteration: 29500, Loss: 0.096\n",
            "Epoch: 65, Iteration: 30000, Loss: 1.729\n",
            "Epoch: 65, Iteration: 30500, Loss: 0.233\n",
            "Epoch: 65, Iteration: 31000, Loss: 0.093\n",
            "Epoch: 65, Iteration: 31500, Loss: 0.070\n",
            "Epoch: 65, Iteration: 32000, Loss: 0.087\n",
            "Epoch: 65, Iteration: 32500, Loss: 0.058\n",
            "Epoch: 65, Iteration: 33000, Loss: 0.089\n",
            "Epoch: 65, Iteration: 33500, Loss: 0.712\n",
            "Epoch: 65, Iteration: 34000, Loss: 0.069\n",
            "Epoch: 65, Iteration: 34500, Loss: 1.089\n",
            "Epoch: 65, Iteration: 35000, Loss: 0.196\n",
            "Epoch: 65, Iteration: 35500, Loss: 0.137\n",
            "Epoch: 65, Iteration: 36000, Loss: 0.062\n",
            "Epoch: 65, Iteration: 36500, Loss: 0.067\n",
            "Epoch: 65, Iteration: 37000, Loss: 0.135\n",
            "Epoch: 65, Iteration: 37500, Loss: 0.073\n",
            "Epoch: 65, Iteration: 38000, Loss: 0.131\n",
            "Epoch: 65, Iteration: 38500, Loss: 0.072\n",
            "Epoch: 65, Iteration: 39000, Loss: 0.076\n",
            "Epoch: 65, Iteration: 39500, Loss: 0.136\n",
            "Epoch: 65, Iteration: 40000, Loss: 0.092\n",
            "Epoch: 65, Iteration: 40500, Loss: 0.219\n",
            "Epoch: 65, Iteration: 41000, Loss: 0.089\n",
            "Epoch: 65, Iteration: 41500, Loss: 0.233\n",
            "Epoch: 65, Iteration: 42000, Loss: 0.251\n",
            "Epoch: 65, Iteration: 42500, Loss: 0.107\n",
            "Epoch: 65, Iteration: 43000, Loss: 0.065\n",
            "Epoch: 65, Iteration: 43500, Loss: 0.079\n",
            "Epoch: 65, Iteration: 44000, Loss: 0.086\n",
            "Epoch: 65, Iteration: 44500, Loss: 0.071\n",
            "Epoch: 65, Iteration: 45000, Loss: 0.086\n",
            "Epoch: 65, Iteration: 45500, Loss: 0.128\n",
            "Epoch: 65, Iteration: 46000, Loss: 0.084\n",
            "Epoch: 65, Iteration: 46500, Loss: 0.104\n",
            "Epoch: 65, Iteration: 47000, Loss: 0.099\n",
            "Epoch: 65, Iteration: 47500, Loss: 0.284\n",
            "Epoch: 65, Iteration: 48000, Loss: 0.066\n",
            "Epoch: 65, Iteration: 48500, Loss: 0.068\n",
            "Epoch: 65, Iteration: 49000, Loss: 0.083\n",
            "Epoch: 65, Iteration: 49500, Loss: 0.101\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.19 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 41.42 %\n",
            "w(T) = 1.000\n",
            "Epoch: 66, Iteration:     0, Loss: 0.109\n",
            "Epoch: 66, Iteration:   500, Loss: 0.401\n",
            "Epoch: 66, Iteration:  1000, Loss: 0.069\n",
            "Epoch: 66, Iteration:  1500, Loss: 0.110\n",
            "Epoch: 66, Iteration:  2000, Loss: 0.388\n",
            "Epoch: 66, Iteration:  2500, Loss: 0.369\n",
            "Epoch: 66, Iteration:  3000, Loss: 1.703\n",
            "Epoch: 66, Iteration:  3500, Loss: 0.674\n",
            "Epoch: 66, Iteration:  4000, Loss: 0.081\n",
            "Epoch: 66, Iteration:  4500, Loss: 0.115\n",
            "Epoch: 66, Iteration:  5000, Loss: 0.099\n",
            "Epoch: 66, Iteration:  5500, Loss: 0.199\n",
            "Epoch: 66, Iteration:  6000, Loss: 0.124\n",
            "Epoch: 66, Iteration:  6500, Loss: 0.101\n",
            "Epoch: 66, Iteration:  7000, Loss: 0.191\n",
            "Epoch: 66, Iteration:  7500, Loss: 0.098\n",
            "Epoch: 66, Iteration:  8000, Loss: 0.085\n",
            "Epoch: 66, Iteration:  8500, Loss: 0.095\n",
            "Epoch: 66, Iteration:  9000, Loss: 0.115\n",
            "Epoch: 66, Iteration:  9500, Loss: 0.387\n",
            "Epoch: 66, Iteration: 10000, Loss: 0.122\n",
            "Epoch: 66, Iteration: 10500, Loss: 0.097\n",
            "Epoch: 66, Iteration: 11000, Loss: 0.183\n",
            "Epoch: 66, Iteration: 11500, Loss: 0.113\n",
            "Epoch: 66, Iteration: 12000, Loss: 0.105\n",
            "Epoch: 66, Iteration: 12500, Loss: 0.091\n",
            "Epoch: 66, Iteration: 13000, Loss: 0.122\n",
            "Epoch: 66, Iteration: 13500, Loss: 0.095\n",
            "Epoch: 66, Iteration: 14000, Loss: 0.087\n",
            "Epoch: 66, Iteration: 14500, Loss: 0.166\n",
            "Epoch: 66, Iteration: 15000, Loss: 0.125\n",
            "Epoch: 66, Iteration: 15500, Loss: 0.085\n",
            "Epoch: 66, Iteration: 16000, Loss: 0.067\n",
            "Epoch: 66, Iteration: 16500, Loss: 0.412\n",
            "Epoch: 66, Iteration: 17000, Loss: 0.124\n",
            "Epoch: 66, Iteration: 17500, Loss: 0.072\n",
            "Epoch: 66, Iteration: 18000, Loss: 0.078\n",
            "Epoch: 66, Iteration: 18500, Loss: 0.084\n",
            "Epoch: 66, Iteration: 19000, Loss: 0.116\n",
            "Epoch: 66, Iteration: 19500, Loss: 0.827\n",
            "Epoch: 66, Iteration: 20000, Loss: 0.138\n",
            "Epoch: 66, Iteration: 20500, Loss: 0.056\n",
            "Epoch: 66, Iteration: 21000, Loss: 0.476\n",
            "Epoch: 66, Iteration: 21500, Loss: 0.085\n",
            "Epoch: 66, Iteration: 22000, Loss: 0.122\n",
            "Epoch: 66, Iteration: 22500, Loss: 0.104\n",
            "Epoch: 66, Iteration: 23000, Loss: 0.147\n",
            "Epoch: 66, Iteration: 23500, Loss: 0.090\n",
            "Epoch: 66, Iteration: 24000, Loss: 1.112\n",
            "Epoch: 66, Iteration: 24500, Loss: 0.087\n",
            "Epoch: 66, Iteration: 25000, Loss: 0.152\n",
            "Epoch: 66, Iteration: 25500, Loss: 0.196\n",
            "Epoch: 66, Iteration: 26000, Loss: 0.090\n",
            "Epoch: 66, Iteration: 26500, Loss: 0.221\n",
            "Epoch: 66, Iteration: 27000, Loss: 0.168\n",
            "Epoch: 66, Iteration: 27500, Loss: 3.218\n",
            "Epoch: 66, Iteration: 28000, Loss: 0.114\n",
            "Epoch: 66, Iteration: 28500, Loss: 0.176\n",
            "Epoch: 66, Iteration: 29000, Loss: 0.142\n",
            "Epoch: 66, Iteration: 29500, Loss: 0.087\n",
            "Epoch: 66, Iteration: 30000, Loss: 0.083\n",
            "Epoch: 66, Iteration: 30500, Loss: 0.099\n",
            "Epoch: 66, Iteration: 31000, Loss: 0.085\n",
            "Epoch: 66, Iteration: 31500, Loss: 0.094\n",
            "Epoch: 66, Iteration: 32000, Loss: 0.164\n",
            "Epoch: 66, Iteration: 32500, Loss: 0.075\n",
            "Epoch: 66, Iteration: 33000, Loss: 0.084\n",
            "Epoch: 66, Iteration: 33500, Loss: 0.582\n",
            "Epoch: 66, Iteration: 34000, Loss: 0.088\n",
            "Epoch: 66, Iteration: 34500, Loss: 0.997\n",
            "Epoch: 66, Iteration: 35000, Loss: 0.120\n",
            "Epoch: 66, Iteration: 35500, Loss: 0.112\n",
            "Epoch: 66, Iteration: 36000, Loss: 0.164\n",
            "Epoch: 66, Iteration: 36500, Loss: 0.128\n",
            "Epoch: 66, Iteration: 37000, Loss: 0.200\n",
            "Epoch: 66, Iteration: 37500, Loss: 0.142\n",
            "Epoch: 66, Iteration: 38000, Loss: 0.190\n",
            "Epoch: 66, Iteration: 38500, Loss: 0.095\n",
            "Epoch: 66, Iteration: 39000, Loss: 0.088\n",
            "Epoch: 66, Iteration: 39500, Loss: 0.086\n",
            "Epoch: 66, Iteration: 40000, Loss: 0.124\n",
            "Epoch: 66, Iteration: 40500, Loss: 0.539\n",
            "Epoch: 66, Iteration: 41000, Loss: 0.078\n",
            "Epoch: 66, Iteration: 41500, Loss: 0.104\n",
            "Epoch: 66, Iteration: 42000, Loss: 0.260\n",
            "Epoch: 66, Iteration: 42500, Loss: 0.067\n",
            "Epoch: 66, Iteration: 43000, Loss: 0.204\n",
            "Epoch: 66, Iteration: 43500, Loss: 0.089\n",
            "Epoch: 66, Iteration: 44000, Loss: 0.067\n",
            "Epoch: 66, Iteration: 44500, Loss: 0.105\n",
            "Epoch: 66, Iteration: 45000, Loss: 0.094\n",
            "Epoch: 66, Iteration: 45500, Loss: 0.129\n",
            "Epoch: 66, Iteration: 46000, Loss: 0.120\n",
            "Epoch: 66, Iteration: 46500, Loss: 0.547\n",
            "Epoch: 66, Iteration: 47000, Loss: 0.311\n",
            "Epoch: 66, Iteration: 47500, Loss: 0.094\n",
            "Epoch: 66, Iteration: 48000, Loss: 0.063\n",
            "Epoch: 66, Iteration: 48500, Loss: 0.569\n",
            "Epoch: 66, Iteration: 49000, Loss: 0.095\n",
            "Epoch: 66, Iteration: 49500, Loss: 0.129\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.89 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.43 %\n",
            "w(T) = 1.000\n",
            "Epoch: 67, Iteration:     0, Loss: 0.087\n",
            "Epoch: 67, Iteration:   500, Loss: 0.050\n",
            "Epoch: 67, Iteration:  1000, Loss: 0.142\n",
            "Epoch: 67, Iteration:  1500, Loss: 0.267\n",
            "Epoch: 67, Iteration:  2000, Loss: 0.062\n",
            "Epoch: 67, Iteration:  2500, Loss: 0.143\n",
            "Epoch: 67, Iteration:  3000, Loss: 1.244\n",
            "Epoch: 67, Iteration:  3500, Loss: 0.143\n",
            "Epoch: 67, Iteration:  4000, Loss: 0.068\n",
            "Epoch: 67, Iteration:  4500, Loss: 1.397\n",
            "Epoch: 67, Iteration:  5000, Loss: 0.068\n",
            "Epoch: 67, Iteration:  5500, Loss: 0.277\n",
            "Epoch: 67, Iteration:  6000, Loss: 3.092\n",
            "Epoch: 67, Iteration:  6500, Loss: 0.279\n",
            "Epoch: 67, Iteration:  7000, Loss: 0.076\n",
            "Epoch: 67, Iteration:  7500, Loss: 0.234\n",
            "Epoch: 67, Iteration:  8000, Loss: 0.084\n",
            "Epoch: 67, Iteration:  8500, Loss: 0.062\n",
            "Epoch: 67, Iteration:  9000, Loss: 0.092\n",
            "Epoch: 67, Iteration:  9500, Loss: 0.115\n",
            "Epoch: 67, Iteration: 10000, Loss: 0.062\n",
            "Epoch: 67, Iteration: 10500, Loss: 0.104\n",
            "Epoch: 67, Iteration: 11000, Loss: 0.110\n",
            "Epoch: 67, Iteration: 11500, Loss: 0.079\n",
            "Epoch: 67, Iteration: 12000, Loss: 0.061\n",
            "Epoch: 67, Iteration: 12500, Loss: 0.077\n",
            "Epoch: 67, Iteration: 13000, Loss: 0.071\n",
            "Epoch: 67, Iteration: 13500, Loss: 0.067\n",
            "Epoch: 67, Iteration: 14000, Loss: 0.074\n",
            "Epoch: 67, Iteration: 14500, Loss: 0.235\n",
            "Epoch: 67, Iteration: 15000, Loss: 0.084\n",
            "Epoch: 67, Iteration: 15500, Loss: 0.341\n",
            "Epoch: 67, Iteration: 16000, Loss: 0.067\n",
            "Epoch: 67, Iteration: 16500, Loss: 0.086\n",
            "Epoch: 67, Iteration: 17000, Loss: 0.246\n",
            "Epoch: 67, Iteration: 17500, Loss: 0.074\n",
            "Epoch: 67, Iteration: 18000, Loss: 0.083\n",
            "Epoch: 67, Iteration: 18500, Loss: 0.084\n",
            "Epoch: 67, Iteration: 19000, Loss: 0.062\n",
            "Epoch: 67, Iteration: 19500, Loss: 0.072\n",
            "Epoch: 67, Iteration: 20000, Loss: 0.110\n",
            "Epoch: 67, Iteration: 20500, Loss: 0.096\n",
            "Epoch: 67, Iteration: 21000, Loss: 0.097\n",
            "Epoch: 67, Iteration: 21500, Loss: 0.085\n",
            "Epoch: 67, Iteration: 22000, Loss: 0.068\n",
            "Epoch: 67, Iteration: 22500, Loss: 0.193\n",
            "Epoch: 67, Iteration: 23000, Loss: 0.118\n",
            "Epoch: 67, Iteration: 23500, Loss: 0.250\n",
            "Epoch: 67, Iteration: 24000, Loss: 0.106\n",
            "Epoch: 67, Iteration: 24500, Loss: 0.090\n",
            "Epoch: 67, Iteration: 25000, Loss: 0.070\n",
            "Epoch: 67, Iteration: 25500, Loss: 0.106\n",
            "Epoch: 67, Iteration: 26000, Loss: 0.066\n",
            "Epoch: 67, Iteration: 26500, Loss: 0.068\n",
            "Epoch: 67, Iteration: 27000, Loss: 0.050\n",
            "Epoch: 67, Iteration: 27500, Loss: 0.315\n",
            "Epoch: 67, Iteration: 28000, Loss: 0.059\n",
            "Epoch: 67, Iteration: 28500, Loss: 2.339\n",
            "Epoch: 67, Iteration: 29000, Loss: 0.135\n",
            "Epoch: 67, Iteration: 29500, Loss: 0.063\n",
            "Epoch: 67, Iteration: 30000, Loss: 0.475\n",
            "Epoch: 67, Iteration: 30500, Loss: 0.115\n",
            "Epoch: 67, Iteration: 31000, Loss: 0.319\n",
            "Epoch: 67, Iteration: 31500, Loss: 0.426\n",
            "Epoch: 67, Iteration: 32000, Loss: 0.059\n",
            "Epoch: 67, Iteration: 32500, Loss: 0.082\n",
            "Epoch: 67, Iteration: 33000, Loss: 0.084\n",
            "Epoch: 67, Iteration: 33500, Loss: 0.295\n",
            "Epoch: 67, Iteration: 34000, Loss: 0.097\n",
            "Epoch: 67, Iteration: 34500, Loss: 0.091\n",
            "Epoch: 67, Iteration: 35000, Loss: 0.201\n",
            "Epoch: 67, Iteration: 35500, Loss: 0.095\n",
            "Epoch: 67, Iteration: 36000, Loss: 0.081\n",
            "Epoch: 67, Iteration: 36500, Loss: 0.070\n",
            "Epoch: 67, Iteration: 37000, Loss: 0.088\n",
            "Epoch: 67, Iteration: 37500, Loss: 0.038\n",
            "Epoch: 67, Iteration: 38000, Loss: 0.073\n",
            "Epoch: 67, Iteration: 38500, Loss: 0.073\n",
            "Epoch: 67, Iteration: 39000, Loss: 0.084\n",
            "Epoch: 67, Iteration: 39500, Loss: 0.069\n",
            "Epoch: 67, Iteration: 40000, Loss: 0.072\n",
            "Epoch: 67, Iteration: 40500, Loss: 0.091\n",
            "Epoch: 67, Iteration: 41000, Loss: 0.104\n",
            "Epoch: 67, Iteration: 41500, Loss: 0.113\n",
            "Epoch: 67, Iteration: 42000, Loss: 0.257\n",
            "Epoch: 67, Iteration: 42500, Loss: 0.084\n",
            "Epoch: 67, Iteration: 43000, Loss: 0.081\n",
            "Epoch: 67, Iteration: 43500, Loss: 0.069\n",
            "Epoch: 67, Iteration: 44000, Loss: 0.105\n",
            "Epoch: 67, Iteration: 44500, Loss: 0.073\n",
            "Epoch: 67, Iteration: 45000, Loss: 0.066\n",
            "Epoch: 67, Iteration: 45500, Loss: 0.235\n",
            "Epoch: 67, Iteration: 46000, Loss: 0.095\n",
            "Epoch: 67, Iteration: 46500, Loss: 0.081\n",
            "Epoch: 67, Iteration: 47000, Loss: 0.062\n",
            "Epoch: 67, Iteration: 47500, Loss: 0.077\n",
            "Epoch: 67, Iteration: 48000, Loss: 0.067\n",
            "Epoch: 67, Iteration: 48500, Loss: 0.058\n",
            "Epoch: 67, Iteration: 49000, Loss: 0.057\n",
            "Epoch: 67, Iteration: 49500, Loss: 0.204\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.69 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.26 %\n",
            "w(T) = 1.000\n",
            "Epoch: 68, Iteration:     0, Loss: 0.067\n",
            "Epoch: 68, Iteration:   500, Loss: 0.127\n",
            "Epoch: 68, Iteration:  1000, Loss: 0.068\n",
            "Epoch: 68, Iteration:  1500, Loss: 0.178\n",
            "Epoch: 68, Iteration:  2000, Loss: 0.065\n",
            "Epoch: 68, Iteration:  2500, Loss: 0.419\n",
            "Epoch: 68, Iteration:  3000, Loss: 0.070\n",
            "Epoch: 68, Iteration:  3500, Loss: 0.061\n",
            "Epoch: 68, Iteration:  4000, Loss: 0.067\n",
            "Epoch: 68, Iteration:  4500, Loss: 0.300\n",
            "Epoch: 68, Iteration:  5000, Loss: 0.073\n",
            "Epoch: 68, Iteration:  5500, Loss: 0.075\n",
            "Epoch: 68, Iteration:  6000, Loss: 0.079\n",
            "Epoch: 68, Iteration:  6500, Loss: 0.084\n",
            "Epoch: 68, Iteration:  7000, Loss: 0.475\n",
            "Epoch: 68, Iteration:  7500, Loss: 0.087\n",
            "Epoch: 68, Iteration:  8000, Loss: 0.056\n",
            "Epoch: 68, Iteration:  8500, Loss: 0.314\n",
            "Epoch: 68, Iteration:  9000, Loss: 0.126\n",
            "Epoch: 68, Iteration:  9500, Loss: 0.056\n",
            "Epoch: 68, Iteration: 10000, Loss: 0.073\n",
            "Epoch: 68, Iteration: 10500, Loss: 0.494\n",
            "Epoch: 68, Iteration: 11000, Loss: 0.075\n",
            "Epoch: 68, Iteration: 11500, Loss: 0.060\n",
            "Epoch: 68, Iteration: 12000, Loss: 0.071\n",
            "Epoch: 68, Iteration: 12500, Loss: 0.285\n",
            "Epoch: 68, Iteration: 13000, Loss: 0.065\n",
            "Epoch: 68, Iteration: 13500, Loss: 0.145\n",
            "Epoch: 68, Iteration: 14000, Loss: 0.061\n",
            "Epoch: 68, Iteration: 14500, Loss: 0.054\n",
            "Epoch: 68, Iteration: 15000, Loss: 0.595\n",
            "Epoch: 68, Iteration: 15500, Loss: 0.062\n",
            "Epoch: 68, Iteration: 16000, Loss: 0.046\n",
            "Epoch: 68, Iteration: 16500, Loss: 0.075\n",
            "Epoch: 68, Iteration: 17000, Loss: 0.660\n",
            "Epoch: 68, Iteration: 17500, Loss: 0.068\n",
            "Epoch: 68, Iteration: 18000, Loss: 0.099\n",
            "Epoch: 68, Iteration: 18500, Loss: 0.079\n",
            "Epoch: 68, Iteration: 19000, Loss: 0.067\n",
            "Epoch: 68, Iteration: 19500, Loss: 0.060\n",
            "Epoch: 68, Iteration: 20000, Loss: 0.071\n",
            "Epoch: 68, Iteration: 20500, Loss: 0.208\n",
            "Epoch: 68, Iteration: 21000, Loss: 0.179\n",
            "Epoch: 68, Iteration: 21500, Loss: 0.120\n",
            "Epoch: 68, Iteration: 22000, Loss: 0.069\n",
            "Epoch: 68, Iteration: 22500, Loss: 0.223\n",
            "Epoch: 68, Iteration: 23000, Loss: 0.051\n",
            "Epoch: 68, Iteration: 23500, Loss: 0.074\n",
            "Epoch: 68, Iteration: 24000, Loss: 0.081\n",
            "Epoch: 68, Iteration: 24500, Loss: 0.188\n",
            "Epoch: 68, Iteration: 25000, Loss: 0.050\n",
            "Epoch: 68, Iteration: 25500, Loss: 0.084\n",
            "Epoch: 68, Iteration: 26000, Loss: 0.089\n",
            "Epoch: 68, Iteration: 26500, Loss: 0.062\n",
            "Epoch: 68, Iteration: 27000, Loss: 0.250\n",
            "Epoch: 68, Iteration: 27500, Loss: 0.139\n",
            "Epoch: 68, Iteration: 28000, Loss: 0.104\n",
            "Epoch: 68, Iteration: 28500, Loss: 0.065\n",
            "Epoch: 68, Iteration: 29000, Loss: 0.063\n",
            "Epoch: 68, Iteration: 29500, Loss: 0.083\n",
            "Epoch: 68, Iteration: 30000, Loss: 0.171\n",
            "Epoch: 68, Iteration: 30500, Loss: 0.080\n",
            "Epoch: 68, Iteration: 31000, Loss: 0.051\n",
            "Epoch: 68, Iteration: 31500, Loss: 0.123\n",
            "Epoch: 68, Iteration: 32000, Loss: 0.120\n",
            "Epoch: 68, Iteration: 32500, Loss: 0.069\n",
            "Epoch: 68, Iteration: 33000, Loss: 0.065\n",
            "Epoch: 68, Iteration: 33500, Loss: 0.621\n",
            "Epoch: 68, Iteration: 34000, Loss: 0.076\n",
            "Epoch: 68, Iteration: 34500, Loss: 0.089\n",
            "Epoch: 68, Iteration: 35000, Loss: 0.079\n",
            "Epoch: 68, Iteration: 35500, Loss: 2.310\n",
            "Epoch: 68, Iteration: 36000, Loss: 0.071\n",
            "Epoch: 68, Iteration: 36500, Loss: 0.072\n",
            "Epoch: 68, Iteration: 37000, Loss: 0.093\n",
            "Epoch: 68, Iteration: 37500, Loss: 0.106\n",
            "Epoch: 68, Iteration: 38000, Loss: 0.082\n",
            "Epoch: 68, Iteration: 38500, Loss: 0.135\n",
            "Epoch: 68, Iteration: 39000, Loss: 0.151\n",
            "Epoch: 68, Iteration: 39500, Loss: 1.184\n",
            "Epoch: 68, Iteration: 40000, Loss: 0.092\n",
            "Epoch: 68, Iteration: 40500, Loss: 0.078\n",
            "Epoch: 68, Iteration: 41000, Loss: 0.082\n",
            "Epoch: 68, Iteration: 41500, Loss: 0.055\n",
            "Epoch: 68, Iteration: 42000, Loss: 0.079\n",
            "Epoch: 68, Iteration: 42500, Loss: 0.945\n",
            "Epoch: 68, Iteration: 43000, Loss: 0.784\n",
            "Epoch: 68, Iteration: 43500, Loss: 0.082\n",
            "Epoch: 68, Iteration: 44000, Loss: 0.360\n",
            "Epoch: 68, Iteration: 44500, Loss: 0.905\n",
            "Epoch: 68, Iteration: 45000, Loss: 0.497\n",
            "Epoch: 68, Iteration: 45500, Loss: 0.192\n",
            "Epoch: 68, Iteration: 46000, Loss: 0.079\n",
            "Epoch: 68, Iteration: 46500, Loss: 0.070\n",
            "Epoch: 68, Iteration: 47000, Loss: 0.066\n",
            "Epoch: 68, Iteration: 47500, Loss: 0.078\n",
            "Epoch: 68, Iteration: 48000, Loss: 0.086\n",
            "Epoch: 68, Iteration: 48500, Loss: 0.061\n",
            "Epoch: 68, Iteration: 49000, Loss: 0.087\n",
            "Epoch: 68, Iteration: 49500, Loss: 0.116\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.59 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.44 %\n",
            "w(T) = 1.000\n",
            "Epoch: 69, Iteration:     0, Loss: 0.077\n",
            "Epoch: 69, Iteration:   500, Loss: 0.626\n",
            "Epoch: 69, Iteration:  1000, Loss: 0.415\n",
            "Epoch: 69, Iteration:  1500, Loss: 0.114\n",
            "Epoch: 69, Iteration:  2000, Loss: 0.103\n",
            "Epoch: 69, Iteration:  2500, Loss: 0.158\n",
            "Epoch: 69, Iteration:  3000, Loss: 0.916\n",
            "Epoch: 69, Iteration:  3500, Loss: 0.073\n",
            "Epoch: 69, Iteration:  4000, Loss: 0.145\n",
            "Epoch: 69, Iteration:  4500, Loss: 0.094\n",
            "Epoch: 69, Iteration:  5000, Loss: 0.239\n",
            "Epoch: 69, Iteration:  5500, Loss: 0.094\n",
            "Epoch: 69, Iteration:  6000, Loss: 0.081\n",
            "Epoch: 69, Iteration:  6500, Loss: 0.100\n",
            "Epoch: 69, Iteration:  7000, Loss: 0.059\n",
            "Epoch: 69, Iteration:  7500, Loss: 0.082\n",
            "Epoch: 69, Iteration:  8000, Loss: 0.071\n",
            "Epoch: 69, Iteration:  8500, Loss: 0.422\n",
            "Epoch: 69, Iteration:  9000, Loss: 0.064\n",
            "Epoch: 69, Iteration:  9500, Loss: 0.065\n",
            "Epoch: 69, Iteration: 10000, Loss: 0.075\n",
            "Epoch: 69, Iteration: 10500, Loss: 0.061\n",
            "Epoch: 69, Iteration: 11000, Loss: 0.111\n",
            "Epoch: 69, Iteration: 11500, Loss: 0.063\n",
            "Epoch: 69, Iteration: 12000, Loss: 0.072\n",
            "Epoch: 69, Iteration: 12500, Loss: 0.072\n",
            "Epoch: 69, Iteration: 13000, Loss: 0.065\n",
            "Epoch: 69, Iteration: 13500, Loss: 0.227\n",
            "Epoch: 69, Iteration: 14000, Loss: 0.094\n",
            "Epoch: 69, Iteration: 14500, Loss: 0.111\n",
            "Epoch: 69, Iteration: 15000, Loss: 0.055\n",
            "Epoch: 69, Iteration: 15500, Loss: 0.065\n",
            "Epoch: 69, Iteration: 16000, Loss: 0.059\n",
            "Epoch: 69, Iteration: 16500, Loss: 0.170\n",
            "Epoch: 69, Iteration: 17000, Loss: 0.708\n",
            "Epoch: 69, Iteration: 17500, Loss: 0.054\n",
            "Epoch: 69, Iteration: 18000, Loss: 0.058\n",
            "Epoch: 69, Iteration: 18500, Loss: 0.087\n",
            "Epoch: 69, Iteration: 19000, Loss: 0.137\n",
            "Epoch: 69, Iteration: 19500, Loss: 0.071\n",
            "Epoch: 69, Iteration: 20000, Loss: 0.074\n",
            "Epoch: 69, Iteration: 20500, Loss: 0.188\n",
            "Epoch: 69, Iteration: 21000, Loss: 0.077\n",
            "Epoch: 69, Iteration: 21500, Loss: 0.153\n",
            "Epoch: 69, Iteration: 22000, Loss: 0.147\n",
            "Epoch: 69, Iteration: 22500, Loss: 0.363\n",
            "Epoch: 69, Iteration: 23000, Loss: 0.090\n",
            "Epoch: 69, Iteration: 23500, Loss: 0.272\n",
            "Epoch: 69, Iteration: 24000, Loss: 0.087\n",
            "Epoch: 69, Iteration: 24500, Loss: 0.063\n",
            "Epoch: 69, Iteration: 25000, Loss: 0.090\n",
            "Epoch: 69, Iteration: 25500, Loss: 0.069\n",
            "Epoch: 69, Iteration: 26000, Loss: 0.318\n",
            "Epoch: 69, Iteration: 26500, Loss: 0.087\n",
            "Epoch: 69, Iteration: 27000, Loss: 0.105\n",
            "Epoch: 69, Iteration: 27500, Loss: 0.058\n",
            "Epoch: 69, Iteration: 28000, Loss: 0.053\n",
            "Epoch: 69, Iteration: 28500, Loss: 0.063\n",
            "Epoch: 69, Iteration: 29000, Loss: 0.084\n",
            "Epoch: 69, Iteration: 29500, Loss: 0.072\n",
            "Epoch: 69, Iteration: 30000, Loss: 0.373\n",
            "Epoch: 69, Iteration: 30500, Loss: 0.224\n",
            "Epoch: 69, Iteration: 31000, Loss: 0.398\n",
            "Epoch: 69, Iteration: 31500, Loss: 0.095\n",
            "Epoch: 69, Iteration: 32000, Loss: 0.058\n",
            "Epoch: 69, Iteration: 32500, Loss: 0.125\n",
            "Epoch: 69, Iteration: 33000, Loss: 1.176\n",
            "Epoch: 69, Iteration: 33500, Loss: 0.411\n",
            "Epoch: 69, Iteration: 34000, Loss: 0.055\n",
            "Epoch: 69, Iteration: 34500, Loss: 0.093\n",
            "Epoch: 69, Iteration: 35000, Loss: 0.056\n",
            "Epoch: 69, Iteration: 35500, Loss: 0.489\n",
            "Epoch: 69, Iteration: 36000, Loss: 0.058\n",
            "Epoch: 69, Iteration: 36500, Loss: 0.060\n",
            "Epoch: 69, Iteration: 37000, Loss: 0.070\n",
            "Epoch: 69, Iteration: 37500, Loss: 0.522\n",
            "Epoch: 69, Iteration: 38000, Loss: 0.324\n",
            "Epoch: 69, Iteration: 38500, Loss: 0.079\n",
            "Epoch: 69, Iteration: 39000, Loss: 0.174\n",
            "Epoch: 69, Iteration: 39500, Loss: 0.139\n",
            "Epoch: 69, Iteration: 40000, Loss: 0.069\n",
            "Epoch: 69, Iteration: 40500, Loss: 0.067\n",
            "Epoch: 69, Iteration: 41000, Loss: 0.081\n",
            "Epoch: 69, Iteration: 41500, Loss: 0.097\n",
            "Epoch: 69, Iteration: 42000, Loss: 0.087\n",
            "Epoch: 69, Iteration: 42500, Loss: 0.115\n",
            "Epoch: 69, Iteration: 43000, Loss: 0.108\n",
            "Epoch: 69, Iteration: 43500, Loss: 0.048\n",
            "Epoch: 69, Iteration: 44000, Loss: 0.060\n",
            "Epoch: 69, Iteration: 44500, Loss: 0.098\n",
            "Epoch: 69, Iteration: 45000, Loss: 0.083\n",
            "Epoch: 69, Iteration: 45500, Loss: 0.071\n",
            "Epoch: 69, Iteration: 46000, Loss: 0.082\n",
            "Epoch: 69, Iteration: 46500, Loss: 0.053\n",
            "Epoch: 69, Iteration: 47000, Loss: 0.124\n",
            "Epoch: 69, Iteration: 47500, Loss: 0.084\n",
            "Epoch: 69, Iteration: 48000, Loss: 0.356\n",
            "Epoch: 69, Iteration: 48500, Loss: 0.111\n",
            "Epoch: 69, Iteration: 49000, Loss: 0.089\n",
            "Epoch: 69, Iteration: 49500, Loss: 0.086\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.23 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.62 %\n",
            "w(T) = 1.000\n",
            "Epoch: 70, Iteration:     0, Loss: 0.121\n",
            "Epoch: 70, Iteration:   500, Loss: 0.072\n",
            "Epoch: 70, Iteration:  1000, Loss: 0.237\n",
            "Epoch: 70, Iteration:  1500, Loss: 0.073\n",
            "Epoch: 70, Iteration:  2000, Loss: 0.056\n",
            "Epoch: 70, Iteration:  2500, Loss: 0.091\n",
            "Epoch: 70, Iteration:  3000, Loss: 0.082\n",
            "Epoch: 70, Iteration:  3500, Loss: 0.062\n",
            "Epoch: 70, Iteration:  4000, Loss: 0.068\n",
            "Epoch: 70, Iteration:  4500, Loss: 0.094\n",
            "Epoch: 70, Iteration:  5000, Loss: 0.089\n",
            "Epoch: 70, Iteration:  5500, Loss: 0.063\n",
            "Epoch: 70, Iteration:  6000, Loss: 0.051\n",
            "Epoch: 70, Iteration:  6500, Loss: 0.390\n",
            "Epoch: 70, Iteration:  7000, Loss: 0.061\n",
            "Epoch: 70, Iteration:  7500, Loss: 0.369\n",
            "Epoch: 70, Iteration:  8000, Loss: 0.053\n",
            "Epoch: 70, Iteration:  8500, Loss: 0.064\n",
            "Epoch: 70, Iteration:  9000, Loss: 0.110\n",
            "Epoch: 70, Iteration:  9500, Loss: 0.104\n",
            "Epoch: 70, Iteration: 10000, Loss: 0.098\n",
            "Epoch: 70, Iteration: 10500, Loss: 0.059\n",
            "Epoch: 70, Iteration: 11000, Loss: 0.075\n",
            "Epoch: 70, Iteration: 11500, Loss: 0.061\n",
            "Epoch: 70, Iteration: 12000, Loss: 0.134\n",
            "Epoch: 70, Iteration: 12500, Loss: 0.363\n",
            "Epoch: 70, Iteration: 13000, Loss: 0.096\n",
            "Epoch: 70, Iteration: 13500, Loss: 0.085\n",
            "Epoch: 70, Iteration: 14000, Loss: 0.081\n",
            "Epoch: 70, Iteration: 14500, Loss: 1.549\n",
            "Epoch: 70, Iteration: 15000, Loss: 0.528\n",
            "Epoch: 70, Iteration: 15500, Loss: 0.094\n",
            "Epoch: 70, Iteration: 16000, Loss: 0.089\n",
            "Epoch: 70, Iteration: 16500, Loss: 0.152\n",
            "Epoch: 70, Iteration: 17000, Loss: 0.743\n",
            "Epoch: 70, Iteration: 17500, Loss: 0.490\n",
            "Epoch: 70, Iteration: 18000, Loss: 0.096\n",
            "Epoch: 70, Iteration: 18500, Loss: 0.076\n",
            "Epoch: 70, Iteration: 19000, Loss: 0.066\n",
            "Epoch: 70, Iteration: 19500, Loss: 0.059\n",
            "Epoch: 70, Iteration: 20000, Loss: 0.100\n",
            "Epoch: 70, Iteration: 20500, Loss: 0.592\n",
            "Epoch: 70, Iteration: 21000, Loss: 0.084\n",
            "Epoch: 70, Iteration: 21500, Loss: 0.614\n",
            "Epoch: 70, Iteration: 22000, Loss: 0.089\n",
            "Epoch: 70, Iteration: 22500, Loss: 0.078\n",
            "Epoch: 70, Iteration: 23000, Loss: 0.393\n",
            "Epoch: 70, Iteration: 23500, Loss: 0.080\n",
            "Epoch: 70, Iteration: 24000, Loss: 0.073\n",
            "Epoch: 70, Iteration: 24500, Loss: 0.075\n",
            "Epoch: 70, Iteration: 25000, Loss: 0.108\n",
            "Epoch: 70, Iteration: 25500, Loss: 0.065\n",
            "Epoch: 70, Iteration: 26000, Loss: 0.074\n",
            "Epoch: 70, Iteration: 26500, Loss: 0.564\n",
            "Epoch: 70, Iteration: 27000, Loss: 0.046\n",
            "Epoch: 70, Iteration: 27500, Loss: 0.145\n",
            "Epoch: 70, Iteration: 28000, Loss: 0.091\n",
            "Epoch: 70, Iteration: 28500, Loss: 0.092\n",
            "Epoch: 70, Iteration: 29000, Loss: 0.093\n",
            "Epoch: 70, Iteration: 29500, Loss: 0.150\n",
            "Epoch: 70, Iteration: 30000, Loss: 0.066\n",
            "Epoch: 70, Iteration: 30500, Loss: 0.086\n",
            "Epoch: 70, Iteration: 31000, Loss: 0.107\n",
            "Epoch: 70, Iteration: 31500, Loss: 0.194\n",
            "Epoch: 70, Iteration: 32000, Loss: 0.367\n",
            "Epoch: 70, Iteration: 32500, Loss: 0.045\n",
            "Epoch: 70, Iteration: 33000, Loss: 0.082\n",
            "Epoch: 70, Iteration: 33500, Loss: 0.056\n",
            "Epoch: 70, Iteration: 34000, Loss: 0.065\n",
            "Epoch: 70, Iteration: 34500, Loss: 2.498\n",
            "Epoch: 70, Iteration: 35000, Loss: 0.047\n",
            "Epoch: 70, Iteration: 35500, Loss: 0.864\n",
            "Epoch: 70, Iteration: 36000, Loss: 0.199\n",
            "Epoch: 70, Iteration: 36500, Loss: 0.079\n",
            "Epoch: 70, Iteration: 37000, Loss: 0.048\n",
            "Epoch: 70, Iteration: 37500, Loss: 0.295\n",
            "Epoch: 70, Iteration: 38000, Loss: 0.130\n",
            "Epoch: 70, Iteration: 38500, Loss: 0.070\n",
            "Epoch: 70, Iteration: 39000, Loss: 0.080\n",
            "Epoch: 70, Iteration: 39500, Loss: 0.137\n",
            "Epoch: 70, Iteration: 40000, Loss: 0.088\n",
            "Epoch: 70, Iteration: 40500, Loss: 0.187\n",
            "Epoch: 70, Iteration: 41000, Loss: 0.065\n",
            "Epoch: 70, Iteration: 41500, Loss: 0.102\n",
            "Epoch: 70, Iteration: 42000, Loss: 0.052\n",
            "Epoch: 70, Iteration: 42500, Loss: 0.065\n",
            "Epoch: 70, Iteration: 43000, Loss: 0.077\n",
            "Epoch: 70, Iteration: 43500, Loss: 0.084\n",
            "Epoch: 70, Iteration: 44000, Loss: 0.069\n",
            "Epoch: 70, Iteration: 44500, Loss: 0.130\n",
            "Epoch: 70, Iteration: 45000, Loss: 0.078\n",
            "Epoch: 70, Iteration: 45500, Loss: 0.060\n",
            "Epoch: 70, Iteration: 46000, Loss: 0.111\n",
            "Epoch: 70, Iteration: 46500, Loss: 0.046\n",
            "Epoch: 70, Iteration: 47000, Loss: 0.054\n",
            "Epoch: 70, Iteration: 47500, Loss: 0.083\n",
            "Epoch: 70, Iteration: 48000, Loss: 0.083\n",
            "Epoch: 70, Iteration: 48500, Loss: 0.099\n",
            "Epoch: 70, Iteration: 49000, Loss: 0.100\n",
            "Epoch: 70, Iteration: 49500, Loss: 0.124\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.35 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.95 %\n",
            "w(T) = 1.000\n",
            "Epoch: 71, Iteration:     0, Loss: 0.070\n",
            "Epoch: 71, Iteration:   500, Loss: 0.068\n",
            "Epoch: 71, Iteration:  1000, Loss: 0.055\n",
            "Epoch: 71, Iteration:  1500, Loss: 0.058\n",
            "Epoch: 71, Iteration:  2000, Loss: 0.791\n",
            "Epoch: 71, Iteration:  2500, Loss: 0.274\n",
            "Epoch: 71, Iteration:  3000, Loss: 0.049\n",
            "Epoch: 71, Iteration:  3500, Loss: 0.058\n",
            "Epoch: 71, Iteration:  4000, Loss: 0.086\n",
            "Epoch: 71, Iteration:  4500, Loss: 0.104\n",
            "Epoch: 71, Iteration:  5000, Loss: 0.083\n",
            "Epoch: 71, Iteration:  5500, Loss: 0.071\n",
            "Epoch: 71, Iteration:  6000, Loss: 0.075\n",
            "Epoch: 71, Iteration:  6500, Loss: 0.224\n",
            "Epoch: 71, Iteration:  7000, Loss: 0.073\n",
            "Epoch: 71, Iteration:  7500, Loss: 0.158\n",
            "Epoch: 71, Iteration:  8000, Loss: 0.067\n",
            "Epoch: 71, Iteration:  8500, Loss: 0.062\n",
            "Epoch: 71, Iteration:  9000, Loss: 0.086\n",
            "Epoch: 71, Iteration:  9500, Loss: 0.127\n",
            "Epoch: 71, Iteration: 10000, Loss: 0.055\n",
            "Epoch: 71, Iteration: 10500, Loss: 0.058\n",
            "Epoch: 71, Iteration: 11000, Loss: 0.168\n",
            "Epoch: 71, Iteration: 11500, Loss: 0.227\n",
            "Epoch: 71, Iteration: 12000, Loss: 0.080\n",
            "Epoch: 71, Iteration: 12500, Loss: 0.073\n",
            "Epoch: 71, Iteration: 13000, Loss: 0.061\n",
            "Epoch: 71, Iteration: 13500, Loss: 0.090\n",
            "Epoch: 71, Iteration: 14000, Loss: 0.062\n",
            "Epoch: 71, Iteration: 14500, Loss: 0.080\n",
            "Epoch: 71, Iteration: 15000, Loss: 0.074\n",
            "Epoch: 71, Iteration: 15500, Loss: 0.106\n",
            "Epoch: 71, Iteration: 16000, Loss: 0.072\n",
            "Epoch: 71, Iteration: 16500, Loss: 0.160\n",
            "Epoch: 71, Iteration: 17000, Loss: 0.274\n",
            "Epoch: 71, Iteration: 17500, Loss: 0.056\n",
            "Epoch: 71, Iteration: 18000, Loss: 0.074\n",
            "Epoch: 71, Iteration: 18500, Loss: 0.073\n",
            "Epoch: 71, Iteration: 19000, Loss: 0.072\n",
            "Epoch: 71, Iteration: 19500, Loss: 0.118\n",
            "Epoch: 71, Iteration: 20000, Loss: 0.285\n",
            "Epoch: 71, Iteration: 20500, Loss: 0.051\n",
            "Epoch: 71, Iteration: 21000, Loss: 0.085\n",
            "Epoch: 71, Iteration: 21500, Loss: 0.074\n",
            "Epoch: 71, Iteration: 22000, Loss: 0.055\n",
            "Epoch: 71, Iteration: 22500, Loss: 0.072\n",
            "Epoch: 71, Iteration: 23000, Loss: 0.063\n",
            "Epoch: 71, Iteration: 23500, Loss: 0.312\n",
            "Epoch: 71, Iteration: 24000, Loss: 0.305\n",
            "Epoch: 71, Iteration: 24500, Loss: 0.083\n",
            "Epoch: 71, Iteration: 25000, Loss: 0.080\n",
            "Epoch: 71, Iteration: 25500, Loss: 0.071\n",
            "Epoch: 71, Iteration: 26000, Loss: 0.074\n",
            "Epoch: 71, Iteration: 26500, Loss: 0.053\n",
            "Epoch: 71, Iteration: 27000, Loss: 0.078\n",
            "Epoch: 71, Iteration: 27500, Loss: 0.085\n",
            "Epoch: 71, Iteration: 28000, Loss: 0.215\n",
            "Epoch: 71, Iteration: 28500, Loss: 0.083\n",
            "Epoch: 71, Iteration: 29000, Loss: 0.079\n",
            "Epoch: 71, Iteration: 29500, Loss: 0.075\n",
            "Epoch: 71, Iteration: 30000, Loss: 0.105\n",
            "Epoch: 71, Iteration: 30500, Loss: 0.121\n",
            "Epoch: 71, Iteration: 31000, Loss: 0.065\n",
            "Epoch: 71, Iteration: 31500, Loss: 0.084\n",
            "Epoch: 71, Iteration: 32000, Loss: 0.074\n",
            "Epoch: 71, Iteration: 32500, Loss: 0.082\n",
            "Epoch: 71, Iteration: 33000, Loss: 0.051\n",
            "Epoch: 71, Iteration: 33500, Loss: 0.089\n",
            "Epoch: 71, Iteration: 34000, Loss: 0.103\n",
            "Epoch: 71, Iteration: 34500, Loss: 0.046\n",
            "Epoch: 71, Iteration: 35000, Loss: 0.062\n",
            "Epoch: 71, Iteration: 35500, Loss: 0.070\n",
            "Epoch: 71, Iteration: 36000, Loss: 0.060\n",
            "Epoch: 71, Iteration: 36500, Loss: 0.083\n",
            "Epoch: 71, Iteration: 37000, Loss: 0.591\n",
            "Epoch: 71, Iteration: 37500, Loss: 0.059\n",
            "Epoch: 71, Iteration: 38000, Loss: 0.087\n",
            "Epoch: 71, Iteration: 38500, Loss: 0.050\n",
            "Epoch: 71, Iteration: 39000, Loss: 0.099\n",
            "Epoch: 71, Iteration: 39500, Loss: 0.153\n",
            "Epoch: 71, Iteration: 40000, Loss: 1.202\n",
            "Epoch: 71, Iteration: 40500, Loss: 0.089\n",
            "Epoch: 71, Iteration: 41000, Loss: 0.112\n",
            "Epoch: 71, Iteration: 41500, Loss: 0.085\n",
            "Epoch: 71, Iteration: 42000, Loss: 0.074\n",
            "Epoch: 71, Iteration: 42500, Loss: 0.064\n",
            "Epoch: 71, Iteration: 43000, Loss: 0.096\n",
            "Epoch: 71, Iteration: 43500, Loss: 0.083\n",
            "Epoch: 71, Iteration: 44000, Loss: 0.234\n",
            "Epoch: 71, Iteration: 44500, Loss: 0.091\n",
            "Epoch: 71, Iteration: 45000, Loss: 0.089\n",
            "Epoch: 71, Iteration: 45500, Loss: 0.079\n",
            "Epoch: 71, Iteration: 46000, Loss: 0.301\n",
            "Epoch: 71, Iteration: 46500, Loss: 0.107\n",
            "Epoch: 71, Iteration: 47000, Loss: 0.071\n",
            "Epoch: 71, Iteration: 47500, Loss: 0.099\n",
            "Epoch: 71, Iteration: 48000, Loss: 0.063\n",
            "Epoch: 71, Iteration: 48500, Loss: 0.170\n",
            "Epoch: 71, Iteration: 49000, Loss: 0.062\n",
            "Epoch: 71, Iteration: 49500, Loss: 0.072\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.72 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.26 %\n",
            "w(T) = 1.000\n",
            "Epoch: 72, Iteration:     0, Loss: 0.095\n",
            "Epoch: 72, Iteration:   500, Loss: 0.061\n",
            "Epoch: 72, Iteration:  1000, Loss: 0.092\n",
            "Epoch: 72, Iteration:  1500, Loss: 0.075\n",
            "Epoch: 72, Iteration:  2000, Loss: 0.058\n",
            "Epoch: 72, Iteration:  2500, Loss: 0.036\n",
            "Epoch: 72, Iteration:  3000, Loss: 0.086\n",
            "Epoch: 72, Iteration:  3500, Loss: 0.057\n",
            "Epoch: 72, Iteration:  4000, Loss: 0.095\n",
            "Epoch: 72, Iteration:  4500, Loss: 0.039\n",
            "Epoch: 72, Iteration:  5000, Loss: 0.200\n",
            "Epoch: 72, Iteration:  5500, Loss: 0.185\n",
            "Epoch: 72, Iteration:  6000, Loss: 0.519\n",
            "Epoch: 72, Iteration:  6500, Loss: 0.086\n",
            "Epoch: 72, Iteration:  7000, Loss: 0.041\n",
            "Epoch: 72, Iteration:  7500, Loss: 0.058\n",
            "Epoch: 72, Iteration:  8000, Loss: 0.075\n",
            "Epoch: 72, Iteration:  8500, Loss: 1.610\n",
            "Epoch: 72, Iteration:  9000, Loss: 0.061\n",
            "Epoch: 72, Iteration:  9500, Loss: 0.266\n",
            "Epoch: 72, Iteration: 10000, Loss: 0.062\n",
            "Epoch: 72, Iteration: 10500, Loss: 0.053\n",
            "Epoch: 72, Iteration: 11000, Loss: 0.098\n",
            "Epoch: 72, Iteration: 11500, Loss: 0.435\n",
            "Epoch: 72, Iteration: 12000, Loss: 0.077\n",
            "Epoch: 72, Iteration: 12500, Loss: 0.125\n",
            "Epoch: 72, Iteration: 13000, Loss: 0.058\n",
            "Epoch: 72, Iteration: 13500, Loss: 0.055\n",
            "Epoch: 72, Iteration: 14000, Loss: 1.359\n",
            "Epoch: 72, Iteration: 14500, Loss: 0.049\n",
            "Epoch: 72, Iteration: 15000, Loss: 0.239\n",
            "Epoch: 72, Iteration: 15500, Loss: 0.053\n",
            "Epoch: 72, Iteration: 16000, Loss: 0.064\n",
            "Epoch: 72, Iteration: 16500, Loss: 0.085\n",
            "Epoch: 72, Iteration: 17000, Loss: 0.053\n",
            "Epoch: 72, Iteration: 17500, Loss: 0.115\n",
            "Epoch: 72, Iteration: 18000, Loss: 0.058\n",
            "Epoch: 72, Iteration: 18500, Loss: 0.077\n",
            "Epoch: 72, Iteration: 19000, Loss: 0.072\n",
            "Epoch: 72, Iteration: 19500, Loss: 0.044\n",
            "Epoch: 72, Iteration: 20000, Loss: 0.317\n",
            "Epoch: 72, Iteration: 20500, Loss: 0.091\n",
            "Epoch: 72, Iteration: 21000, Loss: 0.046\n",
            "Epoch: 72, Iteration: 21500, Loss: 0.069\n",
            "Epoch: 72, Iteration: 22000, Loss: 0.721\n",
            "Epoch: 72, Iteration: 22500, Loss: 0.057\n",
            "Epoch: 72, Iteration: 23000, Loss: 0.183\n",
            "Epoch: 72, Iteration: 23500, Loss: 0.240\n",
            "Epoch: 72, Iteration: 24000, Loss: 0.071\n",
            "Epoch: 72, Iteration: 24500, Loss: 0.063\n",
            "Epoch: 72, Iteration: 25000, Loss: 0.065\n",
            "Epoch: 72, Iteration: 25500, Loss: 0.077\n",
            "Epoch: 72, Iteration: 26000, Loss: 0.087\n",
            "Epoch: 72, Iteration: 26500, Loss: 0.112\n",
            "Epoch: 72, Iteration: 27000, Loss: 0.565\n",
            "Epoch: 72, Iteration: 27500, Loss: 0.069\n",
            "Epoch: 72, Iteration: 28000, Loss: 0.056\n",
            "Epoch: 72, Iteration: 28500, Loss: 0.077\n",
            "Epoch: 72, Iteration: 29000, Loss: 0.063\n",
            "Epoch: 72, Iteration: 29500, Loss: 0.066\n",
            "Epoch: 72, Iteration: 30000, Loss: 0.042\n",
            "Epoch: 72, Iteration: 30500, Loss: 1.061\n",
            "Epoch: 72, Iteration: 31000, Loss: 0.066\n",
            "Epoch: 72, Iteration: 31500, Loss: 0.051\n",
            "Epoch: 72, Iteration: 32000, Loss: 0.295\n",
            "Epoch: 72, Iteration: 32500, Loss: 0.109\n",
            "Epoch: 72, Iteration: 33000, Loss: 0.215\n",
            "Epoch: 72, Iteration: 33500, Loss: 0.096\n",
            "Epoch: 72, Iteration: 34000, Loss: 0.068\n",
            "Epoch: 72, Iteration: 34500, Loss: 0.084\n",
            "Epoch: 72, Iteration: 35000, Loss: 0.212\n",
            "Epoch: 72, Iteration: 35500, Loss: 0.111\n",
            "Epoch: 72, Iteration: 36000, Loss: 0.073\n",
            "Epoch: 72, Iteration: 36500, Loss: 0.065\n",
            "Epoch: 72, Iteration: 37000, Loss: 0.063\n",
            "Epoch: 72, Iteration: 37500, Loss: 0.090\n",
            "Epoch: 72, Iteration: 38000, Loss: 0.181\n",
            "Epoch: 72, Iteration: 38500, Loss: 0.061\n",
            "Epoch: 72, Iteration: 39000, Loss: 0.306\n",
            "Epoch: 72, Iteration: 39500, Loss: 0.093\n",
            "Epoch: 72, Iteration: 40000, Loss: 0.090\n",
            "Epoch: 72, Iteration: 40500, Loss: 0.068\n",
            "Epoch: 72, Iteration: 41000, Loss: 0.196\n",
            "Epoch: 72, Iteration: 41500, Loss: 0.264\n",
            "Epoch: 72, Iteration: 42000, Loss: 0.095\n",
            "Epoch: 72, Iteration: 42500, Loss: 0.209\n",
            "Epoch: 72, Iteration: 43000, Loss: 0.071\n",
            "Epoch: 72, Iteration: 43500, Loss: 0.092\n",
            "Epoch: 72, Iteration: 44000, Loss: 0.174\n",
            "Epoch: 72, Iteration: 44500, Loss: 0.092\n",
            "Epoch: 72, Iteration: 45000, Loss: 0.189\n",
            "Epoch: 72, Iteration: 45500, Loss: 0.081\n",
            "Epoch: 72, Iteration: 46000, Loss: 0.098\n",
            "Epoch: 72, Iteration: 46500, Loss: 0.054\n",
            "Epoch: 72, Iteration: 47000, Loss: 0.068\n",
            "Epoch: 72, Iteration: 47500, Loss: 0.064\n",
            "Epoch: 72, Iteration: 48000, Loss: 0.477\n",
            "Epoch: 72, Iteration: 48500, Loss: 0.104\n",
            "Epoch: 72, Iteration: 49000, Loss: 0.074\n",
            "Epoch: 72, Iteration: 49500, Loss: 0.384\n",
            "Accuracy of the neural network on CIFAR_10 is: 45.01 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.75 %\n",
            "w(T) = 1.000\n",
            "Epoch: 73, Iteration:     0, Loss: 0.088\n",
            "Epoch: 73, Iteration:   500, Loss: 0.125\n",
            "Epoch: 73, Iteration:  1000, Loss: 0.074\n",
            "Epoch: 73, Iteration:  1500, Loss: 0.095\n",
            "Epoch: 73, Iteration:  2000, Loss: 0.301\n",
            "Epoch: 73, Iteration:  2500, Loss: 0.052\n",
            "Epoch: 73, Iteration:  3000, Loss: 0.070\n",
            "Epoch: 73, Iteration:  3500, Loss: 0.751\n",
            "Epoch: 73, Iteration:  4000, Loss: 0.136\n",
            "Epoch: 73, Iteration:  4500, Loss: 0.271\n",
            "Epoch: 73, Iteration:  5000, Loss: 0.076\n",
            "Epoch: 73, Iteration:  5500, Loss: 0.068\n",
            "Epoch: 73, Iteration:  6000, Loss: 0.090\n",
            "Epoch: 73, Iteration:  6500, Loss: 0.772\n",
            "Epoch: 73, Iteration:  7000, Loss: 0.074\n",
            "Epoch: 73, Iteration:  7500, Loss: 0.065\n",
            "Epoch: 73, Iteration:  8000, Loss: 0.093\n",
            "Epoch: 73, Iteration:  8500, Loss: 0.087\n",
            "Epoch: 73, Iteration:  9000, Loss: 0.117\n",
            "Epoch: 73, Iteration:  9500, Loss: 0.074\n",
            "Epoch: 73, Iteration: 10000, Loss: 0.058\n",
            "Epoch: 73, Iteration: 10500, Loss: 0.072\n",
            "Epoch: 73, Iteration: 11000, Loss: 0.108\n",
            "Epoch: 73, Iteration: 11500, Loss: 0.075\n",
            "Epoch: 73, Iteration: 12000, Loss: 0.056\n",
            "Epoch: 73, Iteration: 12500, Loss: 0.063\n",
            "Epoch: 73, Iteration: 13000, Loss: 0.045\n",
            "Epoch: 73, Iteration: 13500, Loss: 0.076\n",
            "Epoch: 73, Iteration: 14000, Loss: 0.105\n",
            "Epoch: 73, Iteration: 14500, Loss: 0.248\n",
            "Epoch: 73, Iteration: 15000, Loss: 0.067\n",
            "Epoch: 73, Iteration: 15500, Loss: 0.082\n",
            "Epoch: 73, Iteration: 16000, Loss: 0.049\n",
            "Epoch: 73, Iteration: 16500, Loss: 0.059\n",
            "Epoch: 73, Iteration: 17000, Loss: 0.048\n",
            "Epoch: 73, Iteration: 17500, Loss: 0.186\n",
            "Epoch: 73, Iteration: 18000, Loss: 0.078\n",
            "Epoch: 73, Iteration: 18500, Loss: 0.061\n",
            "Epoch: 73, Iteration: 19000, Loss: 0.074\n",
            "Epoch: 73, Iteration: 19500, Loss: 0.057\n",
            "Epoch: 73, Iteration: 20000, Loss: 2.287\n",
            "Epoch: 73, Iteration: 20500, Loss: 0.309\n",
            "Epoch: 73, Iteration: 21000, Loss: 0.085\n",
            "Epoch: 73, Iteration: 21500, Loss: 0.091\n",
            "Epoch: 73, Iteration: 22000, Loss: 0.050\n",
            "Epoch: 73, Iteration: 22500, Loss: 0.117\n",
            "Epoch: 73, Iteration: 23000, Loss: 0.078\n",
            "Epoch: 73, Iteration: 23500, Loss: 0.462\n",
            "Epoch: 73, Iteration: 24000, Loss: 0.076\n",
            "Epoch: 73, Iteration: 24500, Loss: 0.061\n",
            "Epoch: 73, Iteration: 25000, Loss: 0.076\n",
            "Epoch: 73, Iteration: 25500, Loss: 0.067\n",
            "Epoch: 73, Iteration: 26000, Loss: 0.064\n",
            "Epoch: 73, Iteration: 26500, Loss: 0.065\n",
            "Epoch: 73, Iteration: 27000, Loss: 0.091\n",
            "Epoch: 73, Iteration: 27500, Loss: 0.205\n",
            "Epoch: 73, Iteration: 28000, Loss: 0.061\n",
            "Epoch: 73, Iteration: 28500, Loss: 0.058\n",
            "Epoch: 73, Iteration: 29000, Loss: 0.073\n",
            "Epoch: 73, Iteration: 29500, Loss: 0.057\n",
            "Epoch: 73, Iteration: 30000, Loss: 0.069\n",
            "Epoch: 73, Iteration: 30500, Loss: 0.066\n",
            "Epoch: 73, Iteration: 31000, Loss: 0.085\n",
            "Epoch: 73, Iteration: 31500, Loss: 0.322\n",
            "Epoch: 73, Iteration: 32000, Loss: 0.066\n",
            "Epoch: 73, Iteration: 32500, Loss: 0.100\n",
            "Epoch: 73, Iteration: 33000, Loss: 0.056\n",
            "Epoch: 73, Iteration: 33500, Loss: 0.069\n",
            "Epoch: 73, Iteration: 34000, Loss: 0.050\n",
            "Epoch: 73, Iteration: 34500, Loss: 0.078\n",
            "Epoch: 73, Iteration: 35000, Loss: 0.051\n",
            "Epoch: 73, Iteration: 35500, Loss: 0.085\n",
            "Epoch: 73, Iteration: 36000, Loss: 0.089\n",
            "Epoch: 73, Iteration: 36500, Loss: 0.271\n",
            "Epoch: 73, Iteration: 37000, Loss: 0.109\n",
            "Epoch: 73, Iteration: 37500, Loss: 0.196\n",
            "Epoch: 73, Iteration: 38000, Loss: 0.177\n",
            "Epoch: 73, Iteration: 38500, Loss: 1.674\n",
            "Epoch: 73, Iteration: 39000, Loss: 0.123\n",
            "Epoch: 73, Iteration: 39500, Loss: 0.092\n",
            "Epoch: 73, Iteration: 40000, Loss: 0.146\n",
            "Epoch: 73, Iteration: 40500, Loss: 0.096\n",
            "Epoch: 73, Iteration: 41000, Loss: 0.070\n",
            "Epoch: 73, Iteration: 41500, Loss: 0.474\n",
            "Epoch: 73, Iteration: 42000, Loss: 0.205\n",
            "Epoch: 73, Iteration: 42500, Loss: 0.061\n",
            "Epoch: 73, Iteration: 43000, Loss: 0.051\n",
            "Epoch: 73, Iteration: 43500, Loss: 0.142\n",
            "Epoch: 73, Iteration: 44000, Loss: 0.038\n",
            "Epoch: 73, Iteration: 44500, Loss: 0.061\n",
            "Epoch: 73, Iteration: 45000, Loss: 0.085\n",
            "Epoch: 73, Iteration: 45500, Loss: 0.515\n",
            "Epoch: 73, Iteration: 46000, Loss: 0.849\n",
            "Epoch: 73, Iteration: 46500, Loss: 0.069\n",
            "Epoch: 73, Iteration: 47000, Loss: 0.080\n",
            "Epoch: 73, Iteration: 47500, Loss: 0.142\n",
            "Epoch: 73, Iteration: 48000, Loss: 0.058\n",
            "Epoch: 73, Iteration: 48500, Loss: 0.098\n",
            "Epoch: 73, Iteration: 49000, Loss: 0.054\n",
            "Epoch: 73, Iteration: 49500, Loss: 0.240\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.83 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.38 %\n",
            "w(T) = 1.000\n",
            "Epoch: 74, Iteration:     0, Loss: 0.053\n",
            "Epoch: 74, Iteration:   500, Loss: 0.085\n",
            "Epoch: 74, Iteration:  1000, Loss: 0.049\n",
            "Epoch: 74, Iteration:  1500, Loss: 0.068\n",
            "Epoch: 74, Iteration:  2000, Loss: 0.279\n",
            "Epoch: 74, Iteration:  2500, Loss: 0.056\n",
            "Epoch: 74, Iteration:  3000, Loss: 0.060\n",
            "Epoch: 74, Iteration:  3500, Loss: 0.106\n",
            "Epoch: 74, Iteration:  4000, Loss: 0.076\n",
            "Epoch: 74, Iteration:  4500, Loss: 0.083\n",
            "Epoch: 74, Iteration:  5000, Loss: 0.072\n",
            "Epoch: 74, Iteration:  5500, Loss: 0.051\n",
            "Epoch: 74, Iteration:  6000, Loss: 0.044\n",
            "Epoch: 74, Iteration:  6500, Loss: 0.335\n",
            "Epoch: 74, Iteration:  7000, Loss: 0.077\n",
            "Epoch: 74, Iteration:  7500, Loss: 0.067\n",
            "Epoch: 74, Iteration:  8000, Loss: 0.063\n",
            "Epoch: 74, Iteration:  8500, Loss: 0.094\n",
            "Epoch: 74, Iteration:  9000, Loss: 0.066\n",
            "Epoch: 74, Iteration:  9500, Loss: 0.075\n",
            "Epoch: 74, Iteration: 10000, Loss: 0.054\n",
            "Epoch: 74, Iteration: 10500, Loss: 0.103\n",
            "Epoch: 74, Iteration: 11000, Loss: 0.061\n",
            "Epoch: 74, Iteration: 11500, Loss: 0.059\n",
            "Epoch: 74, Iteration: 12000, Loss: 0.328\n",
            "Epoch: 74, Iteration: 12500, Loss: 0.053\n",
            "Epoch: 74, Iteration: 13000, Loss: 0.062\n",
            "Epoch: 74, Iteration: 13500, Loss: 0.108\n",
            "Epoch: 74, Iteration: 14000, Loss: 0.073\n",
            "Epoch: 74, Iteration: 14500, Loss: 0.049\n",
            "Epoch: 74, Iteration: 15000, Loss: 0.069\n",
            "Epoch: 74, Iteration: 15500, Loss: 0.155\n",
            "Epoch: 74, Iteration: 16000, Loss: 0.055\n",
            "Epoch: 74, Iteration: 16500, Loss: 0.047\n",
            "Epoch: 74, Iteration: 17000, Loss: 0.089\n",
            "Epoch: 74, Iteration: 17500, Loss: 0.060\n",
            "Epoch: 74, Iteration: 18000, Loss: 0.055\n",
            "Epoch: 74, Iteration: 18500, Loss: 0.044\n",
            "Epoch: 74, Iteration: 19000, Loss: 0.365\n",
            "Epoch: 74, Iteration: 19500, Loss: 0.293\n",
            "Epoch: 74, Iteration: 20000, Loss: 0.105\n",
            "Epoch: 74, Iteration: 20500, Loss: 0.076\n",
            "Epoch: 74, Iteration: 21000, Loss: 0.075\n",
            "Epoch: 74, Iteration: 21500, Loss: 0.070\n",
            "Epoch: 74, Iteration: 22000, Loss: 0.065\n",
            "Epoch: 74, Iteration: 22500, Loss: 0.063\n",
            "Epoch: 74, Iteration: 23000, Loss: 0.060\n",
            "Epoch: 74, Iteration: 23500, Loss: 0.082\n",
            "Epoch: 74, Iteration: 24000, Loss: 0.055\n",
            "Epoch: 74, Iteration: 24500, Loss: 0.082\n",
            "Epoch: 74, Iteration: 25000, Loss: 0.433\n",
            "Epoch: 74, Iteration: 25500, Loss: 0.071\n",
            "Epoch: 74, Iteration: 26000, Loss: 0.067\n",
            "Epoch: 74, Iteration: 26500, Loss: 0.154\n",
            "Epoch: 74, Iteration: 27000, Loss: 0.042\n",
            "Epoch: 74, Iteration: 27500, Loss: 0.059\n",
            "Epoch: 74, Iteration: 28000, Loss: 0.178\n",
            "Epoch: 74, Iteration: 28500, Loss: 0.583\n",
            "Epoch: 74, Iteration: 29000, Loss: 0.190\n",
            "Epoch: 74, Iteration: 29500, Loss: 0.075\n",
            "Epoch: 74, Iteration: 30000, Loss: 0.102\n",
            "Epoch: 74, Iteration: 30500, Loss: 0.391\n",
            "Epoch: 74, Iteration: 31000, Loss: 0.068\n",
            "Epoch: 74, Iteration: 31500, Loss: 0.084\n",
            "Epoch: 74, Iteration: 32000, Loss: 0.058\n",
            "Epoch: 74, Iteration: 32500, Loss: 0.132\n",
            "Epoch: 74, Iteration: 33000, Loss: 2.211\n",
            "Epoch: 74, Iteration: 33500, Loss: 0.486\n",
            "Epoch: 74, Iteration: 34000, Loss: 0.112\n",
            "Epoch: 74, Iteration: 34500, Loss: 0.070\n",
            "Epoch: 74, Iteration: 35000, Loss: 0.064\n",
            "Epoch: 74, Iteration: 35500, Loss: 0.072\n",
            "Epoch: 74, Iteration: 36000, Loss: 0.080\n",
            "Epoch: 74, Iteration: 36500, Loss: 0.056\n",
            "Epoch: 74, Iteration: 37000, Loss: 0.063\n",
            "Epoch: 74, Iteration: 37500, Loss: 0.064\n",
            "Epoch: 74, Iteration: 38000, Loss: 0.110\n",
            "Epoch: 74, Iteration: 38500, Loss: 0.051\n",
            "Epoch: 74, Iteration: 39000, Loss: 0.088\n",
            "Epoch: 74, Iteration: 39500, Loss: 0.091\n",
            "Epoch: 74, Iteration: 40000, Loss: 0.056\n",
            "Epoch: 74, Iteration: 40500, Loss: 0.152\n",
            "Epoch: 74, Iteration: 41000, Loss: 0.043\n",
            "Epoch: 74, Iteration: 41500, Loss: 0.074\n",
            "Epoch: 74, Iteration: 42000, Loss: 0.068\n",
            "Epoch: 74, Iteration: 42500, Loss: 0.197\n",
            "Epoch: 74, Iteration: 43000, Loss: 0.293\n",
            "Epoch: 74, Iteration: 43500, Loss: 0.085\n",
            "Epoch: 74, Iteration: 44000, Loss: 0.214\n",
            "Epoch: 74, Iteration: 44500, Loss: 0.328\n",
            "Epoch: 74, Iteration: 45000, Loss: 0.112\n",
            "Epoch: 74, Iteration: 45500, Loss: 0.050\n",
            "Epoch: 74, Iteration: 46000, Loss: 0.049\n",
            "Epoch: 74, Iteration: 46500, Loss: 0.059\n",
            "Epoch: 74, Iteration: 47000, Loss: 0.058\n",
            "Epoch: 74, Iteration: 47500, Loss: 0.043\n",
            "Epoch: 74, Iteration: 48000, Loss: 0.093\n",
            "Epoch: 74, Iteration: 48500, Loss: 0.302\n",
            "Epoch: 74, Iteration: 49000, Loss: 0.158\n",
            "Epoch: 74, Iteration: 49500, Loss: 0.053\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.71 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 42.59 %\n",
            "w(T) = 1.000\n",
            "Epoch: 75, Iteration:     0, Loss: 0.078\n",
            "Epoch: 75, Iteration:   500, Loss: 1.066\n",
            "Epoch: 75, Iteration:  1000, Loss: 0.062\n",
            "Epoch: 75, Iteration:  1500, Loss: 0.105\n",
            "Epoch: 75, Iteration:  2000, Loss: 0.157\n",
            "Epoch: 75, Iteration:  2500, Loss: 0.345\n",
            "Epoch: 75, Iteration:  3000, Loss: 0.065\n",
            "Epoch: 75, Iteration:  3500, Loss: 0.072\n",
            "Epoch: 75, Iteration:  4000, Loss: 0.075\n",
            "Epoch: 75, Iteration:  4500, Loss: 0.059\n",
            "Epoch: 75, Iteration:  5000, Loss: 0.281\n",
            "Epoch: 75, Iteration:  5500, Loss: 0.075\n",
            "Epoch: 75, Iteration:  6000, Loss: 0.054\n",
            "Epoch: 75, Iteration:  6500, Loss: 0.052\n",
            "Epoch: 75, Iteration:  7000, Loss: 0.050\n",
            "Epoch: 75, Iteration:  7500, Loss: 0.054\n",
            "Epoch: 75, Iteration:  8000, Loss: 0.058\n",
            "Epoch: 75, Iteration:  8500, Loss: 0.035\n",
            "Epoch: 75, Iteration:  9000, Loss: 0.045\n",
            "Epoch: 75, Iteration:  9500, Loss: 0.275\n",
            "Epoch: 75, Iteration: 10000, Loss: 0.049\n",
            "Epoch: 75, Iteration: 10500, Loss: 0.069\n",
            "Epoch: 75, Iteration: 11000, Loss: 0.058\n",
            "Epoch: 75, Iteration: 11500, Loss: 0.060\n",
            "Epoch: 75, Iteration: 12000, Loss: 0.101\n",
            "Epoch: 75, Iteration: 12500, Loss: 0.056\n",
            "Epoch: 75, Iteration: 13000, Loss: 0.044\n",
            "Epoch: 75, Iteration: 13500, Loss: 0.062\n",
            "Epoch: 75, Iteration: 14000, Loss: 0.057\n",
            "Epoch: 75, Iteration: 14500, Loss: 0.058\n",
            "Epoch: 75, Iteration: 15000, Loss: 0.051\n",
            "Epoch: 75, Iteration: 15500, Loss: 0.097\n",
            "Epoch: 75, Iteration: 16000, Loss: 0.052\n",
            "Epoch: 75, Iteration: 16500, Loss: 0.065\n",
            "Epoch: 75, Iteration: 17000, Loss: 0.115\n",
            "Epoch: 75, Iteration: 17500, Loss: 0.037\n",
            "Epoch: 75, Iteration: 18000, Loss: 0.046\n",
            "Epoch: 75, Iteration: 18500, Loss: 0.054\n",
            "Epoch: 75, Iteration: 19000, Loss: 0.038\n",
            "Epoch: 75, Iteration: 19500, Loss: 0.048\n",
            "Epoch: 75, Iteration: 20000, Loss: 0.071\n",
            "Epoch: 75, Iteration: 20500, Loss: 0.060\n",
            "Epoch: 75, Iteration: 21000, Loss: 0.078\n",
            "Epoch: 75, Iteration: 21500, Loss: 0.081\n",
            "Epoch: 75, Iteration: 22000, Loss: 0.105\n",
            "Epoch: 75, Iteration: 22500, Loss: 0.168\n",
            "Epoch: 75, Iteration: 23000, Loss: 0.088\n",
            "Epoch: 75, Iteration: 23500, Loss: 0.062\n",
            "Epoch: 75, Iteration: 24000, Loss: 0.062\n",
            "Epoch: 75, Iteration: 24500, Loss: 0.052\n",
            "Epoch: 75, Iteration: 25000, Loss: 0.081\n",
            "Epoch: 75, Iteration: 25500, Loss: 0.060\n",
            "Epoch: 75, Iteration: 26000, Loss: 0.066\n",
            "Epoch: 75, Iteration: 26500, Loss: 0.056\n",
            "Epoch: 75, Iteration: 27000, Loss: 0.047\n",
            "Epoch: 75, Iteration: 27500, Loss: 0.066\n",
            "Epoch: 75, Iteration: 28000, Loss: 0.061\n",
            "Epoch: 75, Iteration: 28500, Loss: 0.130\n",
            "Epoch: 75, Iteration: 29000, Loss: 0.141\n",
            "Epoch: 75, Iteration: 29500, Loss: 0.061\n",
            "Epoch: 75, Iteration: 30000, Loss: 0.040\n",
            "Epoch: 75, Iteration: 30500, Loss: 0.111\n",
            "Epoch: 75, Iteration: 31000, Loss: 0.048\n",
            "Epoch: 75, Iteration: 31500, Loss: 0.061\n",
            "Epoch: 75, Iteration: 32000, Loss: 0.071\n",
            "Epoch: 75, Iteration: 32500, Loss: 0.063\n",
            "Epoch: 75, Iteration: 33000, Loss: 0.060\n",
            "Epoch: 75, Iteration: 33500, Loss: 0.072\n",
            "Epoch: 75, Iteration: 34000, Loss: 0.238\n",
            "Epoch: 75, Iteration: 34500, Loss: 0.059\n",
            "Epoch: 75, Iteration: 35000, Loss: 0.066\n",
            "Epoch: 75, Iteration: 35500, Loss: 0.046\n",
            "Epoch: 75, Iteration: 36000, Loss: 0.055\n",
            "Epoch: 75, Iteration: 36500, Loss: 0.059\n",
            "Epoch: 75, Iteration: 37000, Loss: 0.045\n",
            "Epoch: 75, Iteration: 37500, Loss: 0.045\n",
            "Epoch: 75, Iteration: 38000, Loss: 0.060\n",
            "Epoch: 75, Iteration: 38500, Loss: 0.058\n",
            "Epoch: 75, Iteration: 39000, Loss: 0.226\n",
            "Epoch: 75, Iteration: 39500, Loss: 0.057\n",
            "Epoch: 75, Iteration: 40000, Loss: 0.662\n",
            "Epoch: 75, Iteration: 40500, Loss: 0.069\n",
            "Epoch: 75, Iteration: 41000, Loss: 0.045\n",
            "Epoch: 75, Iteration: 41500, Loss: 0.057\n",
            "Epoch: 75, Iteration: 42000, Loss: 0.040\n",
            "Epoch: 75, Iteration: 42500, Loss: 0.058\n",
            "Epoch: 75, Iteration: 43000, Loss: 0.130\n",
            "Epoch: 75, Iteration: 43500, Loss: 0.173\n",
            "Epoch: 75, Iteration: 44000, Loss: 0.370\n",
            "Epoch: 75, Iteration: 44500, Loss: 0.096\n",
            "Epoch: 75, Iteration: 45000, Loss: 0.046\n",
            "Epoch: 75, Iteration: 45500, Loss: 0.096\n",
            "Epoch: 75, Iteration: 46000, Loss: 0.066\n",
            "Epoch: 75, Iteration: 46500, Loss: 0.088\n",
            "Epoch: 75, Iteration: 47000, Loss: 0.070\n",
            "Epoch: 75, Iteration: 47500, Loss: 0.074\n",
            "Epoch: 75, Iteration: 48000, Loss: 0.076\n",
            "Epoch: 75, Iteration: 48500, Loss: 0.045\n",
            "Epoch: 75, Iteration: 49000, Loss: 0.045\n",
            "Epoch: 75, Iteration: 49500, Loss: 0.049\n",
            "Accuracy of the neural network on CIFAR_10 is: 45.02 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.76 %\n",
            "w(T) = 1.000\n",
            "Epoch: 76, Iteration:     0, Loss: 0.048\n",
            "Epoch: 76, Iteration:   500, Loss: 0.231\n",
            "Epoch: 76, Iteration:  1000, Loss: 0.051\n",
            "Epoch: 76, Iteration:  1500, Loss: 0.050\n",
            "Epoch: 76, Iteration:  2000, Loss: 0.070\n",
            "Epoch: 76, Iteration:  2500, Loss: 0.064\n",
            "Epoch: 76, Iteration:  3000, Loss: 0.062\n",
            "Epoch: 76, Iteration:  3500, Loss: 0.065\n",
            "Epoch: 76, Iteration:  4000, Loss: 0.735\n",
            "Epoch: 76, Iteration:  4500, Loss: 0.051\n",
            "Epoch: 76, Iteration:  5000, Loss: 0.249\n",
            "Epoch: 76, Iteration:  5500, Loss: 0.543\n",
            "Epoch: 76, Iteration:  6000, Loss: 0.066\n",
            "Epoch: 76, Iteration:  6500, Loss: 0.103\n",
            "Epoch: 76, Iteration:  7000, Loss: 0.159\n",
            "Epoch: 76, Iteration:  7500, Loss: 0.218\n",
            "Epoch: 76, Iteration:  8000, Loss: 0.103\n",
            "Epoch: 76, Iteration:  8500, Loss: 0.081\n",
            "Epoch: 76, Iteration:  9000, Loss: 0.090\n",
            "Epoch: 76, Iteration:  9500, Loss: 0.280\n",
            "Epoch: 76, Iteration: 10000, Loss: 0.176\n",
            "Epoch: 76, Iteration: 10500, Loss: 0.151\n",
            "Epoch: 76, Iteration: 11000, Loss: 0.059\n",
            "Epoch: 76, Iteration: 11500, Loss: 0.111\n",
            "Epoch: 76, Iteration: 12000, Loss: 0.195\n",
            "Epoch: 76, Iteration: 12500, Loss: 0.090\n",
            "Epoch: 76, Iteration: 13000, Loss: 0.080\n",
            "Epoch: 76, Iteration: 13500, Loss: 0.055\n",
            "Epoch: 76, Iteration: 14000, Loss: 0.055\n",
            "Epoch: 76, Iteration: 14500, Loss: 0.220\n",
            "Epoch: 76, Iteration: 15000, Loss: 0.070\n",
            "Epoch: 76, Iteration: 15500, Loss: 0.089\n",
            "Epoch: 76, Iteration: 16000, Loss: 0.167\n",
            "Epoch: 76, Iteration: 16500, Loss: 0.035\n",
            "Epoch: 76, Iteration: 17000, Loss: 0.076\n",
            "Epoch: 76, Iteration: 17500, Loss: 0.048\n",
            "Epoch: 76, Iteration: 18000, Loss: 0.053\n",
            "Epoch: 76, Iteration: 18500, Loss: 1.055\n",
            "Epoch: 76, Iteration: 19000, Loss: 0.059\n",
            "Epoch: 76, Iteration: 19500, Loss: 0.061\n",
            "Epoch: 76, Iteration: 20000, Loss: 0.047\n",
            "Epoch: 76, Iteration: 20500, Loss: 0.107\n",
            "Epoch: 76, Iteration: 21000, Loss: 0.053\n",
            "Epoch: 76, Iteration: 21500, Loss: 0.071\n",
            "Epoch: 76, Iteration: 22000, Loss: 0.054\n",
            "Epoch: 76, Iteration: 22500, Loss: 0.070\n",
            "Epoch: 76, Iteration: 23000, Loss: 0.057\n",
            "Epoch: 76, Iteration: 23500, Loss: 0.059\n",
            "Epoch: 76, Iteration: 24000, Loss: 0.052\n",
            "Epoch: 76, Iteration: 24500, Loss: 0.056\n",
            "Epoch: 76, Iteration: 25000, Loss: 0.044\n",
            "Epoch: 76, Iteration: 25500, Loss: 0.146\n",
            "Epoch: 76, Iteration: 26000, Loss: 0.063\n",
            "Epoch: 76, Iteration: 26500, Loss: 0.073\n",
            "Epoch: 76, Iteration: 27000, Loss: 0.060\n",
            "Epoch: 76, Iteration: 27500, Loss: 0.053\n",
            "Epoch: 76, Iteration: 28000, Loss: 0.048\n",
            "Epoch: 76, Iteration: 28500, Loss: 0.046\n",
            "Epoch: 76, Iteration: 29000, Loss: 0.034\n",
            "Epoch: 76, Iteration: 29500, Loss: 0.059\n",
            "Epoch: 76, Iteration: 30000, Loss: 0.203\n",
            "Epoch: 76, Iteration: 30500, Loss: 0.074\n",
            "Epoch: 76, Iteration: 31000, Loss: 0.873\n",
            "Epoch: 76, Iteration: 31500, Loss: 0.098\n",
            "Epoch: 76, Iteration: 32000, Loss: 0.051\n",
            "Epoch: 76, Iteration: 32500, Loss: 0.082\n",
            "Epoch: 76, Iteration: 33000, Loss: 0.063\n",
            "Epoch: 76, Iteration: 33500, Loss: 0.050\n",
            "Epoch: 76, Iteration: 34000, Loss: 0.089\n",
            "Epoch: 76, Iteration: 34500, Loss: 0.056\n",
            "Epoch: 76, Iteration: 35000, Loss: 0.125\n",
            "Epoch: 76, Iteration: 35500, Loss: 0.076\n",
            "Epoch: 76, Iteration: 36000, Loss: 0.082\n",
            "Epoch: 76, Iteration: 36500, Loss: 0.105\n",
            "Epoch: 76, Iteration: 37000, Loss: 0.053\n",
            "Epoch: 76, Iteration: 37500, Loss: 0.082\n",
            "Epoch: 76, Iteration: 38000, Loss: 0.606\n",
            "Epoch: 76, Iteration: 38500, Loss: 0.067\n",
            "Epoch: 76, Iteration: 39000, Loss: 0.049\n",
            "Epoch: 76, Iteration: 39500, Loss: 0.073\n",
            "Epoch: 76, Iteration: 40000, Loss: 0.062\n",
            "Epoch: 76, Iteration: 40500, Loss: 0.079\n",
            "Epoch: 76, Iteration: 41000, Loss: 0.053\n",
            "Epoch: 76, Iteration: 41500, Loss: 0.095\n",
            "Epoch: 76, Iteration: 42000, Loss: 0.048\n",
            "Epoch: 76, Iteration: 42500, Loss: 0.051\n",
            "Epoch: 76, Iteration: 43000, Loss: 0.271\n",
            "Epoch: 76, Iteration: 43500, Loss: 0.253\n",
            "Epoch: 76, Iteration: 44000, Loss: 0.050\n",
            "Epoch: 76, Iteration: 44500, Loss: 0.060\n",
            "Epoch: 76, Iteration: 45000, Loss: 0.067\n",
            "Epoch: 76, Iteration: 45500, Loss: 0.048\n",
            "Epoch: 76, Iteration: 46000, Loss: 0.069\n",
            "Epoch: 76, Iteration: 46500, Loss: 0.052\n",
            "Epoch: 76, Iteration: 47000, Loss: 0.042\n",
            "Epoch: 76, Iteration: 47500, Loss: 0.042\n",
            "Epoch: 76, Iteration: 48000, Loss: 0.052\n",
            "Epoch: 76, Iteration: 48500, Loss: 0.070\n",
            "Epoch: 76, Iteration: 49000, Loss: 0.143\n",
            "Epoch: 76, Iteration: 49500, Loss: 0.069\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.74 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.61 %\n",
            "w(T) = 1.000\n",
            "Epoch: 77, Iteration:     0, Loss: 0.058\n",
            "Epoch: 77, Iteration:   500, Loss: 0.071\n",
            "Epoch: 77, Iteration:  1000, Loss: 0.062\n",
            "Epoch: 77, Iteration:  1500, Loss: 0.048\n",
            "Epoch: 77, Iteration:  2000, Loss: 0.430\n",
            "Epoch: 77, Iteration:  2500, Loss: 0.045\n",
            "Epoch: 77, Iteration:  3000, Loss: 0.137\n",
            "Epoch: 77, Iteration:  3500, Loss: 0.067\n",
            "Epoch: 77, Iteration:  4000, Loss: 0.074\n",
            "Epoch: 77, Iteration:  4500, Loss: 1.337\n",
            "Epoch: 77, Iteration:  5000, Loss: 0.085\n",
            "Epoch: 77, Iteration:  5500, Loss: 0.066\n",
            "Epoch: 77, Iteration:  6000, Loss: 0.073\n",
            "Epoch: 77, Iteration:  6500, Loss: 0.048\n",
            "Epoch: 77, Iteration:  7000, Loss: 0.065\n",
            "Epoch: 77, Iteration:  7500, Loss: 0.064\n",
            "Epoch: 77, Iteration:  8000, Loss: 0.077\n",
            "Epoch: 77, Iteration:  8500, Loss: 0.055\n",
            "Epoch: 77, Iteration:  9000, Loss: 0.062\n",
            "Epoch: 77, Iteration:  9500, Loss: 0.053\n",
            "Epoch: 77, Iteration: 10000, Loss: 0.035\n",
            "Epoch: 77, Iteration: 10500, Loss: 0.060\n",
            "Epoch: 77, Iteration: 11000, Loss: 0.044\n",
            "Epoch: 77, Iteration: 11500, Loss: 0.043\n",
            "Epoch: 77, Iteration: 12000, Loss: 0.082\n",
            "Epoch: 77, Iteration: 12500, Loss: 0.039\n",
            "Epoch: 77, Iteration: 13000, Loss: 0.051\n",
            "Epoch: 77, Iteration: 13500, Loss: 0.109\n",
            "Epoch: 77, Iteration: 14000, Loss: 0.068\n",
            "Epoch: 77, Iteration: 14500, Loss: 0.055\n",
            "Epoch: 77, Iteration: 15000, Loss: 0.115\n",
            "Epoch: 77, Iteration: 15500, Loss: 0.045\n",
            "Epoch: 77, Iteration: 16000, Loss: 0.053\n",
            "Epoch: 77, Iteration: 16500, Loss: 0.048\n",
            "Epoch: 77, Iteration: 17000, Loss: 0.036\n",
            "Epoch: 77, Iteration: 17500, Loss: 0.105\n",
            "Epoch: 77, Iteration: 18000, Loss: 0.061\n",
            "Epoch: 77, Iteration: 18500, Loss: 0.088\n",
            "Epoch: 77, Iteration: 19000, Loss: 0.062\n",
            "Epoch: 77, Iteration: 19500, Loss: 0.062\n",
            "Epoch: 77, Iteration: 20000, Loss: 0.051\n",
            "Epoch: 77, Iteration: 20500, Loss: 0.084\n",
            "Epoch: 77, Iteration: 21000, Loss: 0.067\n",
            "Epoch: 77, Iteration: 21500, Loss: 0.114\n",
            "Epoch: 77, Iteration: 22000, Loss: 0.057\n",
            "Epoch: 77, Iteration: 22500, Loss: 0.247\n",
            "Epoch: 77, Iteration: 23000, Loss: 0.048\n",
            "Epoch: 77, Iteration: 23500, Loss: 0.084\n",
            "Epoch: 77, Iteration: 24000, Loss: 0.073\n",
            "Epoch: 77, Iteration: 24500, Loss: 0.056\n",
            "Epoch: 77, Iteration: 25000, Loss: 0.052\n",
            "Epoch: 77, Iteration: 25500, Loss: 0.048\n",
            "Epoch: 77, Iteration: 26000, Loss: 0.061\n",
            "Epoch: 77, Iteration: 26500, Loss: 0.066\n",
            "Epoch: 77, Iteration: 27000, Loss: 0.033\n",
            "Epoch: 77, Iteration: 27500, Loss: 0.044\n",
            "Epoch: 77, Iteration: 28000, Loss: 0.040\n",
            "Epoch: 77, Iteration: 28500, Loss: 0.066\n",
            "Epoch: 77, Iteration: 29000, Loss: 0.042\n",
            "Epoch: 77, Iteration: 29500, Loss: 0.104\n",
            "Epoch: 77, Iteration: 30000, Loss: 0.036\n",
            "Epoch: 77, Iteration: 30500, Loss: 0.528\n",
            "Epoch: 77, Iteration: 31000, Loss: 0.044\n",
            "Epoch: 77, Iteration: 31500, Loss: 0.075\n",
            "Epoch: 77, Iteration: 32000, Loss: 0.043\n",
            "Epoch: 77, Iteration: 32500, Loss: 0.047\n",
            "Epoch: 77, Iteration: 33000, Loss: 0.082\n",
            "Epoch: 77, Iteration: 33500, Loss: 0.054\n",
            "Epoch: 77, Iteration: 34000, Loss: 0.053\n",
            "Epoch: 77, Iteration: 34500, Loss: 1.014\n",
            "Epoch: 77, Iteration: 35000, Loss: 0.341\n",
            "Epoch: 77, Iteration: 35500, Loss: 0.078\n",
            "Epoch: 77, Iteration: 36000, Loss: 0.781\n",
            "Epoch: 77, Iteration: 36500, Loss: 0.055\n",
            "Epoch: 77, Iteration: 37000, Loss: 0.051\n",
            "Epoch: 77, Iteration: 37500, Loss: 0.045\n",
            "Epoch: 77, Iteration: 38000, Loss: 0.047\n",
            "Epoch: 77, Iteration: 38500, Loss: 0.057\n",
            "Epoch: 77, Iteration: 39000, Loss: 0.071\n",
            "Epoch: 77, Iteration: 39500, Loss: 0.102\n",
            "Epoch: 77, Iteration: 40000, Loss: 0.107\n",
            "Epoch: 77, Iteration: 40500, Loss: 0.064\n",
            "Epoch: 77, Iteration: 41000, Loss: 0.842\n",
            "Epoch: 77, Iteration: 41500, Loss: 0.237\n",
            "Epoch: 77, Iteration: 42000, Loss: 0.077\n",
            "Epoch: 77, Iteration: 42500, Loss: 0.044\n",
            "Epoch: 77, Iteration: 43000, Loss: 0.050\n",
            "Epoch: 77, Iteration: 43500, Loss: 0.222\n",
            "Epoch: 77, Iteration: 44000, Loss: 0.051\n",
            "Epoch: 77, Iteration: 44500, Loss: 0.059\n",
            "Epoch: 77, Iteration: 45000, Loss: 0.074\n",
            "Epoch: 77, Iteration: 45500, Loss: 0.066\n",
            "Epoch: 77, Iteration: 46000, Loss: 0.065\n",
            "Epoch: 77, Iteration: 46500, Loss: 0.070\n",
            "Epoch: 77, Iteration: 47000, Loss: 0.140\n",
            "Epoch: 77, Iteration: 47500, Loss: 0.054\n",
            "Epoch: 77, Iteration: 48000, Loss: 0.050\n",
            "Epoch: 77, Iteration: 48500, Loss: 0.039\n",
            "Epoch: 77, Iteration: 49000, Loss: 0.054\n",
            "Epoch: 77, Iteration: 49500, Loss: 0.047\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.54 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.15 %\n",
            "w(T) = 1.000\n",
            "Epoch: 78, Iteration:     0, Loss: 0.036\n",
            "Epoch: 78, Iteration:   500, Loss: 0.053\n",
            "Epoch: 78, Iteration:  1000, Loss: 0.233\n",
            "Epoch: 78, Iteration:  1500, Loss: 0.052\n",
            "Epoch: 78, Iteration:  2000, Loss: 0.056\n",
            "Epoch: 78, Iteration:  2500, Loss: 0.073\n",
            "Epoch: 78, Iteration:  3000, Loss: 0.073\n",
            "Epoch: 78, Iteration:  3500, Loss: 0.058\n",
            "Epoch: 78, Iteration:  4000, Loss: 0.046\n",
            "Epoch: 78, Iteration:  4500, Loss: 0.080\n",
            "Epoch: 78, Iteration:  5000, Loss: 0.047\n",
            "Epoch: 78, Iteration:  5500, Loss: 0.151\n",
            "Epoch: 78, Iteration:  6000, Loss: 0.200\n",
            "Epoch: 78, Iteration:  6500, Loss: 0.056\n",
            "Epoch: 78, Iteration:  7000, Loss: 0.082\n",
            "Epoch: 78, Iteration:  7500, Loss: 0.045\n",
            "Epoch: 78, Iteration:  8000, Loss: 0.050\n",
            "Epoch: 78, Iteration:  8500, Loss: 0.043\n",
            "Epoch: 78, Iteration:  9000, Loss: 0.135\n",
            "Epoch: 78, Iteration:  9500, Loss: 0.075\n",
            "Epoch: 78, Iteration: 10000, Loss: 0.047\n",
            "Epoch: 78, Iteration: 10500, Loss: 0.047\n",
            "Epoch: 78, Iteration: 11000, Loss: 0.044\n",
            "Epoch: 78, Iteration: 11500, Loss: 0.048\n",
            "Epoch: 78, Iteration: 12000, Loss: 0.045\n",
            "Epoch: 78, Iteration: 12500, Loss: 0.185\n",
            "Epoch: 78, Iteration: 13000, Loss: 0.037\n",
            "Epoch: 78, Iteration: 13500, Loss: 0.085\n",
            "Epoch: 78, Iteration: 14000, Loss: 0.061\n",
            "Epoch: 78, Iteration: 14500, Loss: 0.602\n",
            "Epoch: 78, Iteration: 15000, Loss: 0.035\n",
            "Epoch: 78, Iteration: 15500, Loss: 0.039\n",
            "Epoch: 78, Iteration: 16000, Loss: 0.056\n",
            "Epoch: 78, Iteration: 16500, Loss: 0.197\n",
            "Epoch: 78, Iteration: 17000, Loss: 0.094\n",
            "Epoch: 78, Iteration: 17500, Loss: 0.092\n",
            "Epoch: 78, Iteration: 18000, Loss: 0.040\n",
            "Epoch: 78, Iteration: 18500, Loss: 0.045\n",
            "Epoch: 78, Iteration: 19000, Loss: 0.059\n",
            "Epoch: 78, Iteration: 19500, Loss: 0.392\n",
            "Epoch: 78, Iteration: 20000, Loss: 0.426\n",
            "Epoch: 78, Iteration: 20500, Loss: 0.125\n",
            "Epoch: 78, Iteration: 21000, Loss: 0.043\n",
            "Epoch: 78, Iteration: 21500, Loss: 0.052\n",
            "Epoch: 78, Iteration: 22000, Loss: 0.057\n",
            "Epoch: 78, Iteration: 22500, Loss: 0.042\n",
            "Epoch: 78, Iteration: 23000, Loss: 0.209\n",
            "Epoch: 78, Iteration: 23500, Loss: 0.594\n",
            "Epoch: 78, Iteration: 24000, Loss: 0.054\n",
            "Epoch: 78, Iteration: 24500, Loss: 0.059\n",
            "Epoch: 78, Iteration: 25000, Loss: 0.256\n",
            "Epoch: 78, Iteration: 25500, Loss: 0.071\n",
            "Epoch: 78, Iteration: 26000, Loss: 0.096\n",
            "Epoch: 78, Iteration: 26500, Loss: 0.063\n",
            "Epoch: 78, Iteration: 27000, Loss: 0.090\n",
            "Epoch: 78, Iteration: 27500, Loss: 0.107\n",
            "Epoch: 78, Iteration: 28000, Loss: 0.050\n",
            "Epoch: 78, Iteration: 28500, Loss: 0.061\n",
            "Epoch: 78, Iteration: 29000, Loss: 0.031\n",
            "Epoch: 78, Iteration: 29500, Loss: 0.058\n",
            "Epoch: 78, Iteration: 30000, Loss: 0.032\n",
            "Epoch: 78, Iteration: 30500, Loss: 0.053\n",
            "Epoch: 78, Iteration: 31000, Loss: 0.074\n",
            "Epoch: 78, Iteration: 31500, Loss: 0.058\n",
            "Epoch: 78, Iteration: 32000, Loss: 0.324\n",
            "Epoch: 78, Iteration: 32500, Loss: 0.040\n",
            "Epoch: 78, Iteration: 33000, Loss: 0.050\n",
            "Epoch: 78, Iteration: 33500, Loss: 0.349\n",
            "Epoch: 78, Iteration: 34000, Loss: 0.076\n",
            "Epoch: 78, Iteration: 34500, Loss: 0.050\n",
            "Epoch: 78, Iteration: 35000, Loss: 0.063\n",
            "Epoch: 78, Iteration: 35500, Loss: 0.072\n",
            "Epoch: 78, Iteration: 36000, Loss: 0.059\n",
            "Epoch: 78, Iteration: 36500, Loss: 0.072\n",
            "Epoch: 78, Iteration: 37000, Loss: 0.052\n",
            "Epoch: 78, Iteration: 37500, Loss: 0.053\n",
            "Epoch: 78, Iteration: 38000, Loss: 0.043\n",
            "Epoch: 78, Iteration: 38500, Loss: 0.093\n",
            "Epoch: 78, Iteration: 39000, Loss: 0.053\n",
            "Epoch: 78, Iteration: 39500, Loss: 0.065\n",
            "Epoch: 78, Iteration: 40000, Loss: 0.059\n",
            "Epoch: 78, Iteration: 40500, Loss: 0.053\n",
            "Epoch: 78, Iteration: 41000, Loss: 1.943\n",
            "Epoch: 78, Iteration: 41500, Loss: 0.068\n",
            "Epoch: 78, Iteration: 42000, Loss: 0.055\n",
            "Epoch: 78, Iteration: 42500, Loss: 1.727\n",
            "Epoch: 78, Iteration: 43000, Loss: 0.288\n",
            "Epoch: 78, Iteration: 43500, Loss: 0.050\n",
            "Epoch: 78, Iteration: 44000, Loss: 0.050\n",
            "Epoch: 78, Iteration: 44500, Loss: 0.051\n",
            "Epoch: 78, Iteration: 45000, Loss: 0.065\n",
            "Epoch: 78, Iteration: 45500, Loss: 0.073\n",
            "Epoch: 78, Iteration: 46000, Loss: 0.080\n",
            "Epoch: 78, Iteration: 46500, Loss: 0.061\n",
            "Epoch: 78, Iteration: 47000, Loss: 0.109\n",
            "Epoch: 78, Iteration: 47500, Loss: 0.077\n",
            "Epoch: 78, Iteration: 48000, Loss: 0.081\n",
            "Epoch: 78, Iteration: 48500, Loss: 0.049\n",
            "Epoch: 78, Iteration: 49000, Loss: 0.051\n",
            "Epoch: 78, Iteration: 49500, Loss: 0.091\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.70 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.87 %\n",
            "w(T) = 1.000\n",
            "Epoch: 79, Iteration:     0, Loss: 0.137\n",
            "Epoch: 79, Iteration:   500, Loss: 0.077\n",
            "Epoch: 79, Iteration:  1000, Loss: 0.051\n",
            "Epoch: 79, Iteration:  1500, Loss: 0.053\n",
            "Epoch: 79, Iteration:  2000, Loss: 0.067\n",
            "Epoch: 79, Iteration:  2500, Loss: 0.049\n",
            "Epoch: 79, Iteration:  3000, Loss: 0.202\n",
            "Epoch: 79, Iteration:  3500, Loss: 0.045\n",
            "Epoch: 79, Iteration:  4000, Loss: 0.036\n",
            "Epoch: 79, Iteration:  4500, Loss: 0.049\n",
            "Epoch: 79, Iteration:  5000, Loss: 0.065\n",
            "Epoch: 79, Iteration:  5500, Loss: 0.038\n",
            "Epoch: 79, Iteration:  6000, Loss: 0.046\n",
            "Epoch: 79, Iteration:  6500, Loss: 0.036\n",
            "Epoch: 79, Iteration:  7000, Loss: 0.054\n",
            "Epoch: 79, Iteration:  7500, Loss: 0.094\n",
            "Epoch: 79, Iteration:  8000, Loss: 0.053\n",
            "Epoch: 79, Iteration:  8500, Loss: 0.075\n",
            "Epoch: 79, Iteration:  9000, Loss: 0.281\n",
            "Epoch: 79, Iteration:  9500, Loss: 0.068\n",
            "Epoch: 79, Iteration: 10000, Loss: 0.047\n",
            "Epoch: 79, Iteration: 10500, Loss: 0.048\n",
            "Epoch: 79, Iteration: 11000, Loss: 0.381\n",
            "Epoch: 79, Iteration: 11500, Loss: 0.047\n",
            "Epoch: 79, Iteration: 12000, Loss: 0.066\n",
            "Epoch: 79, Iteration: 12500, Loss: 0.057\n",
            "Epoch: 79, Iteration: 13000, Loss: 0.052\n",
            "Epoch: 79, Iteration: 13500, Loss: 0.065\n",
            "Epoch: 79, Iteration: 14000, Loss: 0.041\n",
            "Epoch: 79, Iteration: 14500, Loss: 0.063\n",
            "Epoch: 79, Iteration: 15000, Loss: 0.039\n",
            "Epoch: 79, Iteration: 15500, Loss: 0.214\n",
            "Epoch: 79, Iteration: 16000, Loss: 0.152\n",
            "Epoch: 79, Iteration: 16500, Loss: 0.051\n",
            "Epoch: 79, Iteration: 17000, Loss: 0.081\n",
            "Epoch: 79, Iteration: 17500, Loss: 0.068\n",
            "Epoch: 79, Iteration: 18000, Loss: 0.080\n",
            "Epoch: 79, Iteration: 18500, Loss: 0.056\n",
            "Epoch: 79, Iteration: 19000, Loss: 0.050\n",
            "Epoch: 79, Iteration: 19500, Loss: 0.180\n",
            "Epoch: 79, Iteration: 20000, Loss: 0.059\n",
            "Epoch: 79, Iteration: 20500, Loss: 0.069\n",
            "Epoch: 79, Iteration: 21000, Loss: 0.203\n",
            "Epoch: 79, Iteration: 21500, Loss: 0.054\n",
            "Epoch: 79, Iteration: 22000, Loss: 0.046\n",
            "Epoch: 79, Iteration: 22500, Loss: 0.096\n",
            "Epoch: 79, Iteration: 23000, Loss: 0.073\n",
            "Epoch: 79, Iteration: 23500, Loss: 0.063\n",
            "Epoch: 79, Iteration: 24000, Loss: 0.145\n",
            "Epoch: 79, Iteration: 24500, Loss: 0.065\n",
            "Epoch: 79, Iteration: 25000, Loss: 0.059\n",
            "Epoch: 79, Iteration: 25500, Loss: 0.037\n",
            "Epoch: 79, Iteration: 26000, Loss: 0.068\n",
            "Epoch: 79, Iteration: 26500, Loss: 0.034\n",
            "Epoch: 79, Iteration: 27000, Loss: 0.088\n",
            "Epoch: 79, Iteration: 27500, Loss: 0.057\n",
            "Epoch: 79, Iteration: 28000, Loss: 0.100\n",
            "Epoch: 79, Iteration: 28500, Loss: 0.053\n",
            "Epoch: 79, Iteration: 29000, Loss: 0.052\n",
            "Epoch: 79, Iteration: 29500, Loss: 0.218\n",
            "Epoch: 79, Iteration: 30000, Loss: 0.053\n",
            "Epoch: 79, Iteration: 30500, Loss: 0.144\n",
            "Epoch: 79, Iteration: 31000, Loss: 0.040\n",
            "Epoch: 79, Iteration: 31500, Loss: 0.411\n",
            "Epoch: 79, Iteration: 32000, Loss: 0.049\n",
            "Epoch: 79, Iteration: 32500, Loss: 0.060\n",
            "Epoch: 79, Iteration: 33000, Loss: 0.048\n",
            "Epoch: 79, Iteration: 33500, Loss: 0.130\n",
            "Epoch: 79, Iteration: 34000, Loss: 0.091\n",
            "Epoch: 79, Iteration: 34500, Loss: 0.055\n",
            "Epoch: 79, Iteration: 35000, Loss: 0.039\n",
            "Epoch: 79, Iteration: 35500, Loss: 0.045\n",
            "Epoch: 79, Iteration: 36000, Loss: 0.035\n",
            "Epoch: 79, Iteration: 36500, Loss: 0.041\n",
            "Epoch: 79, Iteration: 37000, Loss: 0.059\n",
            "Epoch: 79, Iteration: 37500, Loss: 0.049\n",
            "Epoch: 79, Iteration: 38000, Loss: 0.059\n",
            "Epoch: 79, Iteration: 38500, Loss: 0.036\n",
            "Epoch: 79, Iteration: 39000, Loss: 0.106\n",
            "Epoch: 79, Iteration: 39500, Loss: 0.055\n",
            "Epoch: 79, Iteration: 40000, Loss: 0.041\n",
            "Epoch: 79, Iteration: 40500, Loss: 0.107\n",
            "Epoch: 79, Iteration: 41000, Loss: 0.042\n",
            "Epoch: 79, Iteration: 41500, Loss: 0.074\n",
            "Epoch: 79, Iteration: 42000, Loss: 0.052\n",
            "Epoch: 79, Iteration: 42500, Loss: 0.061\n",
            "Epoch: 79, Iteration: 43000, Loss: 0.043\n",
            "Epoch: 79, Iteration: 43500, Loss: 0.050\n",
            "Epoch: 79, Iteration: 44000, Loss: 0.079\n",
            "Epoch: 79, Iteration: 44500, Loss: 0.186\n",
            "Epoch: 79, Iteration: 45000, Loss: 0.094\n",
            "Epoch: 79, Iteration: 45500, Loss: 0.044\n",
            "Epoch: 79, Iteration: 46000, Loss: 0.358\n",
            "Epoch: 79, Iteration: 46500, Loss: 0.049\n",
            "Epoch: 79, Iteration: 47000, Loss: 1.006\n",
            "Epoch: 79, Iteration: 47500, Loss: 0.062\n",
            "Epoch: 79, Iteration: 48000, Loss: 0.068\n",
            "Epoch: 79, Iteration: 48500, Loss: 0.085\n",
            "Epoch: 79, Iteration: 49000, Loss: 0.068\n",
            "Epoch: 79, Iteration: 49500, Loss: 0.038\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.49 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.05 %\n",
            "w(T) = 1.000\n",
            "Epoch: 80, Iteration:     0, Loss: 0.046\n",
            "Epoch: 80, Iteration:   500, Loss: 0.046\n",
            "Epoch: 80, Iteration:  1000, Loss: 0.040\n",
            "Epoch: 80, Iteration:  1500, Loss: 0.040\n",
            "Epoch: 80, Iteration:  2000, Loss: 0.026\n",
            "Epoch: 80, Iteration:  2500, Loss: 0.321\n",
            "Epoch: 80, Iteration:  3000, Loss: 0.043\n",
            "Epoch: 80, Iteration:  3500, Loss: 0.040\n",
            "Epoch: 80, Iteration:  4000, Loss: 0.116\n",
            "Epoch: 80, Iteration:  4500, Loss: 0.032\n",
            "Epoch: 80, Iteration:  5000, Loss: 0.048\n",
            "Epoch: 80, Iteration:  5500, Loss: 0.072\n",
            "Epoch: 80, Iteration:  6000, Loss: 0.046\n",
            "Epoch: 80, Iteration:  6500, Loss: 0.033\n",
            "Epoch: 80, Iteration:  7000, Loss: 0.051\n",
            "Epoch: 80, Iteration:  7500, Loss: 0.041\n",
            "Epoch: 80, Iteration:  8000, Loss: 0.049\n",
            "Epoch: 80, Iteration:  8500, Loss: 0.048\n",
            "Epoch: 80, Iteration:  9000, Loss: 0.037\n",
            "Epoch: 80, Iteration:  9500, Loss: 0.193\n",
            "Epoch: 80, Iteration: 10000, Loss: 0.035\n",
            "Epoch: 80, Iteration: 10500, Loss: 0.048\n",
            "Epoch: 80, Iteration: 11000, Loss: 0.053\n",
            "Epoch: 80, Iteration: 11500, Loss: 0.035\n",
            "Epoch: 80, Iteration: 12000, Loss: 0.030\n",
            "Epoch: 80, Iteration: 12500, Loss: 0.066\n",
            "Epoch: 80, Iteration: 13000, Loss: 0.038\n",
            "Epoch: 80, Iteration: 13500, Loss: 0.100\n",
            "Epoch: 80, Iteration: 14000, Loss: 0.036\n",
            "Epoch: 80, Iteration: 14500, Loss: 0.038\n",
            "Epoch: 80, Iteration: 15000, Loss: 0.047\n",
            "Epoch: 80, Iteration: 15500, Loss: 0.085\n",
            "Epoch: 80, Iteration: 16000, Loss: 0.055\n",
            "Epoch: 80, Iteration: 16500, Loss: 0.055\n",
            "Epoch: 80, Iteration: 17000, Loss: 0.043\n",
            "Epoch: 80, Iteration: 17500, Loss: 0.053\n",
            "Epoch: 80, Iteration: 18000, Loss: 0.046\n",
            "Epoch: 80, Iteration: 18500, Loss: 0.046\n",
            "Epoch: 80, Iteration: 19000, Loss: 0.049\n",
            "Epoch: 80, Iteration: 19500, Loss: 0.050\n",
            "Epoch: 80, Iteration: 20000, Loss: 0.200\n",
            "Epoch: 80, Iteration: 20500, Loss: 0.044\n",
            "Epoch: 80, Iteration: 21000, Loss: 0.031\n",
            "Epoch: 80, Iteration: 21500, Loss: 0.057\n",
            "Epoch: 80, Iteration: 22000, Loss: 0.065\n",
            "Epoch: 80, Iteration: 22500, Loss: 0.067\n",
            "Epoch: 80, Iteration: 23000, Loss: 0.074\n",
            "Epoch: 80, Iteration: 23500, Loss: 0.044\n",
            "Epoch: 80, Iteration: 24000, Loss: 0.031\n",
            "Epoch: 80, Iteration: 24500, Loss: 0.046\n",
            "Epoch: 80, Iteration: 25000, Loss: 0.049\n",
            "Epoch: 80, Iteration: 25500, Loss: 0.052\n",
            "Epoch: 80, Iteration: 26000, Loss: 0.036\n",
            "Epoch: 80, Iteration: 26500, Loss: 0.072\n",
            "Epoch: 80, Iteration: 27000, Loss: 0.061\n",
            "Epoch: 80, Iteration: 27500, Loss: 0.049\n",
            "Epoch: 80, Iteration: 28000, Loss: 0.045\n",
            "Epoch: 80, Iteration: 28500, Loss: 0.075\n",
            "Epoch: 80, Iteration: 29000, Loss: 0.034\n",
            "Epoch: 80, Iteration: 29500, Loss: 0.032\n",
            "Epoch: 80, Iteration: 30000, Loss: 0.043\n",
            "Epoch: 80, Iteration: 30500, Loss: 0.032\n",
            "Epoch: 80, Iteration: 31000, Loss: 0.047\n",
            "Epoch: 80, Iteration: 31500, Loss: 0.040\n",
            "Epoch: 80, Iteration: 32000, Loss: 0.906\n",
            "Epoch: 80, Iteration: 32500, Loss: 0.033\n",
            "Epoch: 80, Iteration: 33000, Loss: 0.061\n",
            "Epoch: 80, Iteration: 33500, Loss: 0.054\n",
            "Epoch: 80, Iteration: 34000, Loss: 0.062\n",
            "Epoch: 80, Iteration: 34500, Loss: 0.053\n",
            "Epoch: 80, Iteration: 35000, Loss: 0.061\n",
            "Epoch: 80, Iteration: 35500, Loss: 0.112\n",
            "Epoch: 80, Iteration: 36000, Loss: 0.172\n",
            "Epoch: 80, Iteration: 36500, Loss: 0.047\n",
            "Epoch: 80, Iteration: 37000, Loss: 0.562\n",
            "Epoch: 80, Iteration: 37500, Loss: 0.293\n",
            "Epoch: 80, Iteration: 38000, Loss: 0.141\n",
            "Epoch: 80, Iteration: 38500, Loss: 0.046\n",
            "Epoch: 80, Iteration: 39000, Loss: 0.073\n",
            "Epoch: 80, Iteration: 39500, Loss: 0.053\n",
            "Epoch: 80, Iteration: 40000, Loss: 0.043\n",
            "Epoch: 80, Iteration: 40500, Loss: 0.049\n",
            "Epoch: 80, Iteration: 41000, Loss: 0.040\n",
            "Epoch: 80, Iteration: 41500, Loss: 0.046\n",
            "Epoch: 80, Iteration: 42000, Loss: 0.103\n",
            "Epoch: 80, Iteration: 42500, Loss: 0.053\n",
            "Epoch: 80, Iteration: 43000, Loss: 0.065\n",
            "Epoch: 80, Iteration: 43500, Loss: 0.069\n",
            "Epoch: 80, Iteration: 44000, Loss: 0.097\n",
            "Epoch: 80, Iteration: 44500, Loss: 0.043\n",
            "Epoch: 80, Iteration: 45000, Loss: 0.066\n",
            "Epoch: 80, Iteration: 45500, Loss: 0.103\n",
            "Epoch: 80, Iteration: 46000, Loss: 0.040\n",
            "Epoch: 80, Iteration: 46500, Loss: 0.198\n",
            "Epoch: 80, Iteration: 47000, Loss: 0.639\n",
            "Epoch: 80, Iteration: 47500, Loss: 0.043\n",
            "Epoch: 80, Iteration: 48000, Loss: 0.041\n",
            "Epoch: 80, Iteration: 48500, Loss: 0.042\n",
            "Epoch: 80, Iteration: 49000, Loss: 0.103\n",
            "Epoch: 80, Iteration: 49500, Loss: 0.070\n",
            "Accuracy of the neural network on CIFAR_10 is: 44.45 %\n",
            "Accuracy of the neural network on CIFAR_10 is: 43.24 %\n",
            "w(T) = 1.000\n",
            "Plotting in:  /content/drive/MyDrive/plots/training_plot1000.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}